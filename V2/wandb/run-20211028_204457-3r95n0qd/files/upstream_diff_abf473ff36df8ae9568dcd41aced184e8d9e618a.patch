diff --git a/.gitignore b/.gitignore
index 8a5948b..7553a10 100644
--- a/.gitignore
+++ b/.gitignore
@@ -168,3 +168,11 @@ V2/output/test_coco_format.json
 V2/box.jpg
 V2/crop.jpg
 V2/output.png
+V2/test_imgs/WhatsApp Image 2021-10-19 at 21.27.06.jpeg
+V2/test_imgs/WhatsApp Image 2021-10-19 at 21.27.07 (1).jpeg
+V2/test_imgs/WhatsApp Image 2021-10-19 at 21.27.07.jpeg
+V2/test_imgs/WhatsApp Image 2021-10-19 at 21.27.08 (1).jpeg
+V2/test_imgs/WhatsApp Image 2021-10-19 at 21.27.08.jpeg
+V2/test_imgs/WhatsApp Image 2021-10-19 at 21.27.09 (1).jpeg
+V2/test_imgs/WhatsApp Image 2021-10-19 at 21.27.09 (2).jpeg
+V2/test_imgs/WhatsApp Image 2021-10-19 at 21.27.09.jpeg
diff --git a/V2/= b/V2/=
new file mode 100644
index 0000000..36f6a85
--- /dev/null
+++ b/V2/=
@@ -0,0 +1,2 @@
+Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com
+Requirement already satisfied: torchvision in /media/indika/Sync/anaconda3/envs/detectron2/lib/python3.8/site-packages (0.10.0+cu111)
diff --git a/V2/=0.7 b/V2/=0.7
new file mode 100644
index 0000000..2d65a1b
--- /dev/null
+++ b/V2/=0.7
@@ -0,0 +1,5 @@
+Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com
+Requirement already satisfied: torchvision in /media/indika/Sync/anaconda3/envs/detectron2/lib/python3.8/site-packages (0.10.0+cu111)
+Requirement already satisfied: numpy in /home/indika/.local/lib/python3.8/site-packages (from torchvision) (1.19.5)
+Collecting torch==1.9.0
+  Downloading torch-1.9.0-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)
diff --git a/V2/data.npy b/V2/data.npy
new file mode 100644
index 0000000..c196f72
Binary files /dev/null and b/V2/data.npy differ
diff --git a/V2/output.png b/V2/output.png
index ab7d89c..24f7c5a 100644
Binary files a/V2/output.png and b/V2/output.png differ
diff --git a/V2/param-tunning.ipynb b/V2/param-tunning.ipynb
index 62c7a8a..0fa614a 100644
--- a/V2/param-tunning.ipynb
+++ b/V2/param-tunning.ipynb
@@ -64,7 +64,55 @@
     {
      "data": {
       "text/plain": [
-       "True"
+       "array([[[144, 141, 137],\n",
+       "        [138, 135, 131],\n",
+       "        [139, 136, 132],\n",
+       "        ...,\n",
+       "        [ 48,  24,   4],\n",
+       "        [ 48,  24,   4],\n",
+       "        [ 51,  27,   7]],\n",
+       "\n",
+       "       [[149, 146, 142],\n",
+       "        [145, 142, 138],\n",
+       "        [145, 142, 138],\n",
+       "        ...,\n",
+       "        [ 49,  25,   5],\n",
+       "        [ 48,  24,   4],\n",
+       "        [ 50,  26,   6]],\n",
+       "\n",
+       "       [[150, 147, 143],\n",
+       "        [148, 145, 141],\n",
+       "        [148, 145, 141],\n",
+       "        ...,\n",
+       "        [ 49,  25,   5],\n",
+       "        [ 48,  24,   4],\n",
+       "        [ 49,  25,   5]],\n",
+       "\n",
+       "       ...,\n",
+       "\n",
+       "       [[222, 214, 201],\n",
+       "        [222, 214, 201],\n",
+       "        [222, 214, 201],\n",
+       "        ...,\n",
+       "        [107, 127, 138],\n",
+       "        [108, 128, 139],\n",
+       "        [108, 128, 139]],\n",
+       "\n",
+       "       [[222, 214, 201],\n",
+       "        [222, 214, 201],\n",
+       "        [222, 214, 201],\n",
+       "        ...,\n",
+       "        [105, 125, 136],\n",
+       "        [106, 126, 137],\n",
+       "        [107, 127, 138]],\n",
+       "\n",
+       "       [[222, 214, 201],\n",
+       "        [222, 214, 201],\n",
+       "        [222, 214, 201],\n",
+       "        ...,\n",
+       "        [103, 123, 134],\n",
+       "        [102, 122, 133],\n",
+       "        [103, 123, 134]]], dtype=uint8)"
       ]
      },
      "execution_count": 4,
@@ -134,7 +182,7 @@
     "        record[\"annotations\"] = objs\n",
     "        new_data.append(record)\n",
     "    np.random.shuffle(new_data)\n",
-    "#     np.save(\"data.npy\", new_data)\n",
+    "    np.save(\"data.npy\", new_data)\n",
     "    return new_data"
    ]
   },
@@ -214,7 +262,7 @@
     "MAX_ITER = 500\n",
     "EVAL_PERIOD = 500\n",
     "IMS_PER_BATCH = 2\n",
-    "BATCH_SIZE_PER_IMAGE = 16\n",
+    "BATCH_SIZE_PER_IMAGE = 128\n",
     "SCORE_THRESH_TEST = 0.625\n",
     "model = f\"COCO-Detection/\" + \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\""
    ]
@@ -231,7 +279,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 11,
    "id": "6a2539e4-017c-4bbd-99bd-439f1712a127",
    "metadata": {},
    "outputs": [
@@ -242,14 +290,14 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mranuga-d\u001b[0m (use `wandb login --relogin` to force relogin)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
-      "2021-10-28 20:11:09.084698: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
+      "2021-10-28 20:30:44.451795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
      ]
     },
     {
      "data": {
       "text/html": [
        "\n",
-       "                    Syncing run <strong><a href=\"https://wandb.ai/ranuga-d/Find-Card/runs/2jukfznr\" target=\"_blank\">test</a></strong> to <a href=\"https://wandb.ai/ranuga-d/Find-Card\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
+       "                    Syncing run <strong><a href=\"https://wandb.ai/ranuga-d/Find-Card/runs/1dqs4kie\" target=\"_blank\">test</a></strong> to <a href=\"https://wandb.ai/ranuga-d/Find-Card\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
        "\n",
        "                "
       ],
@@ -264,7 +312,7 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "\u001b[32m[10/28 20:11:17 d2.engine.defaults]: \u001b[0mModel:\n",
+      "\u001b[32m[10/28 20:30:54 d2.engine.defaults]: \u001b[0mModel:\n",
       "GeneralizedRCNN(\n",
       "  (backbone): FPN(\n",
       "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
@@ -812,7 +860,164 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      " 18%|███████▎                                | 341/1853 [00:21<00:54, 27.76it/s]"
+      "100%|███████████████████████████████████████| 1853/1853 [01:52<00:00, 16.43it/s]"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[32m[10/28 20:32:47 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1853 images left.\n",
+      "\u001b[32m[10/28 20:32:47 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
+      "\u001b[36m|  category  | #instances   |\n",
+      "|:----------:|:-------------|\n",
+      "|    Card    | 1853         |\n",
+      "|            |              |\u001b[0m\n",
+      "\u001b[32m[10/28 20:32:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
+      "\u001b[32m[10/28 20:32:47 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
+      "\u001b[32m[10/28 20:32:47 d2.data.common]: \u001b[0mSerializing 1853 elements to byte tensors and concatenating them all ...\n",
+      "\u001b[32m[10/28 20:32:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\n",
+      "2021-10-28 20:32:47.839812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
+      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
+      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
+      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
+      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
+      "Some model parameters or buffers are not found in the checkpoint:\n",
+      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
+      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
+      "The checkpoint state_dict contains keys that are not used by the model:\n",
+      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[32m[10/28 20:32:51 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/media/indika/Sync/anaconda3/envs/detectron2/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
+      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
+      "  return torch.floor_divide(self, other)\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[32m[10/28 20:33:12 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 19  total_loss: 1  loss_cls: 0.693  loss_box_reg: 0.2271  loss_rpn_cls: 0.05657  loss_rpn_loc: 0.009185  time: 0.9780  data_time: 0.0345  lr: 9.7405e-06  max_mem: 5664M\n",
+      "\u001b[32m[10/28 20:33:33 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 39  total_loss: 1.019  loss_cls: 0.6176  loss_box_reg: 0.3415  loss_rpn_cls: 0.02472  loss_rpn_loc: 0.008081  time: 1.0285  data_time: 0.0026  lr: 1.9731e-05  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:33:54 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 59  total_loss: 0.818  loss_cls: 0.42  loss_box_reg: 0.3191  loss_rpn_cls: 0.02792  loss_rpn_loc: 0.007938  time: 1.0272  data_time: 0.0024  lr: 2.972e-05  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:34:15 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 79  total_loss: 0.757  loss_cls: 0.3468  loss_box_reg: 0.3653  loss_rpn_cls: 0.01293  loss_rpn_loc: 0.004778  time: 1.0383  data_time: 0.0024  lr: 3.9711e-05  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:34:35 d2.utils.events]: \u001b[0m eta: 0:06:34  iter: 99  total_loss: 0.7258  loss_cls: 0.3038  loss_box_reg: 0.3705  loss_rpn_cls: 0.03467  loss_rpn_loc: 0.008464  time: 1.0290  data_time: 0.0025  lr: 4.9701e-05  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:34:56 d2.utils.events]: \u001b[0m eta: 0:06:14  iter: 119  total_loss: 0.58  loss_cls: 0.2552  loss_box_reg: 0.2856  loss_rpn_cls: 0.03111  loss_rpn_loc: 0.004531  time: 1.0317  data_time: 0.0028  lr: 5.9691e-05  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:35:17 d2.utils.events]: \u001b[0m eta: 0:05:54  iter: 139  total_loss: 0.5809  loss_cls: 0.2429  loss_box_reg: 0.3057  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.01377  time: 1.0375  data_time: 0.0025  lr: 6.9681e-05  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:35:39 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 159  total_loss: 0.6457  loss_cls: 0.2468  loss_box_reg: 0.3148  loss_rpn_cls: 0.01726  loss_rpn_loc: 0.005631  time: 1.0453  data_time: 0.0024  lr: 7.9671e-05  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:36:01 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 179  total_loss: 0.5904  loss_cls: 0.2329  loss_box_reg: 0.3105  loss_rpn_cls: 0.01975  loss_rpn_loc: 0.005262  time: 1.0481  data_time: 0.0025  lr: 8.966e-05  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:36:22 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 199  total_loss: 0.6827  loss_cls: 0.2715  loss_box_reg: 0.3727  loss_rpn_cls: 0.02775  loss_rpn_loc: 0.006949  time: 1.0480  data_time: 0.0025  lr: 9.9651e-05  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:36:42 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 219  total_loss: 0.5566  loss_cls: 0.23  loss_box_reg: 0.3097  loss_rpn_cls: 0.03435  loss_rpn_loc: 0.008049  time: 1.0465  data_time: 0.0026  lr: 0.00010964  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:37:02 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 239  total_loss: 0.5715  loss_cls: 0.2155  loss_box_reg: 0.3557  loss_rpn_cls: 0.02275  loss_rpn_loc: 0.00753  time: 1.0421  data_time: 0.0025  lr: 0.00011963  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:37:26 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 259  total_loss: 0.5362  loss_cls: 0.2181  loss_box_reg: 0.3047  loss_rpn_cls: 0.02114  loss_rpn_loc: 0.007905  time: 1.0530  data_time: 0.0026  lr: 0.00012962  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:37:48 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 279  total_loss: 0.5082  loss_cls: 0.1807  loss_box_reg: 0.2998  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.008175  time: 1.0568  data_time: 0.0023  lr: 0.00013961  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:38:10 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 299  total_loss: 0.5698  loss_cls: 0.2116  loss_box_reg: 0.2864  loss_rpn_cls: 0.02279  loss_rpn_loc: 0.007902  time: 1.0602  data_time: 0.0023  lr: 0.0001496  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:38:34 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 319  total_loss: 0.6299  loss_cls: 0.219  loss_box_reg: 0.3419  loss_rpn_cls: 0.0178  loss_rpn_loc: 0.004595  time: 1.0674  data_time: 0.0024  lr: 0.00015959  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:38:55 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 339  total_loss: 0.4812  loss_cls: 0.1944  loss_box_reg: 0.2411  loss_rpn_cls: 0.02838  loss_rpn_loc: 0.006749  time: 1.0662  data_time: 0.0024  lr: 0.00016958  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:39:18 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 359  total_loss: 0.5638  loss_cls: 0.2142  loss_box_reg: 0.2864  loss_rpn_cls: 0.01874  loss_rpn_loc: 0.004861  time: 1.0730  data_time: 0.0023  lr: 0.00017957  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:39:40 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 379  total_loss: 0.5997  loss_cls: 0.2111  loss_box_reg: 0.3691  loss_rpn_cls: 0.02749  loss_rpn_loc: 0.006363  time: 1.0724  data_time: 0.0024  lr: 0.00018956  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:40:01 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 399  total_loss: 0.5594  loss_cls: 0.2119  loss_box_reg: 0.3096  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.004292  time: 1.0719  data_time: 0.0022  lr: 0.00019955  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:40:20 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 419  total_loss: 0.5899  loss_cls: 0.2128  loss_box_reg: 0.3293  loss_rpn_cls: 0.02035  loss_rpn_loc: 0.006844  time: 1.0667  data_time: 0.0024  lr: 0.00020954  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:40:42 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 439  total_loss: 0.5074  loss_cls: 0.2042  loss_box_reg: 0.2571  loss_rpn_cls: 0.02129  loss_rpn_loc: 0.01155  time: 1.0688  data_time: 0.0024  lr: 0.00021953  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:41:03 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 459  total_loss: 0.4847  loss_cls: 0.1968  loss_box_reg: 0.2778  loss_rpn_cls: 0.01705  loss_rpn_loc: 0.004741  time: 1.0676  data_time: 0.0024  lr: 0.00022952  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:41:26 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 479  total_loss: 0.4642  loss_cls: 0.1947  loss_box_reg: 0.2253  loss_rpn_cls: 0.03734  loss_rpn_loc: 0.007803  time: 1.0706  data_time: 0.0025  lr: 0.00023951  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:41:49 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.539  loss_cls: 0.2126  loss_box_reg: 0.2656  loss_rpn_cls: 0.01522  loss_rpn_loc: 0.005525  time: 1.0734  data_time: 0.0024  lr: 0.0002495  max_mem: 6046M\n",
+      "\u001b[32m[10/28 20:41:49 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:08:54 (1.0734 s / it)\n",
+      "\u001b[32m[10/28 20:41:49 d2.engine.hooks]: \u001b[0mTotal training time: 0:08:55 (0:00:00 on hooks)\n",
+      "\u001b[32m[10/28 20:41:52 d2.evaluation.coco_evaluation]: \u001b[0m'test' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
+      "\u001b[32m[10/28 20:41:52 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'test' to COCO format ...)\n",
+      "325\n",
+      "\u001b[32m[10/28 20:41:52 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
+      "\u001b[32m[10/28 20:41:52 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 325, #annotations: 325\n",
+      "\u001b[32m[10/28 20:41:52 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/test_coco_format.json' ...\n",
+      "325\n",
+      "\u001b[32m[10/28 20:41:52 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
+      "\u001b[36m|  category  | #instances   |\n",
+      "|:----------:|:-------------|\n",
+      "|    Card    | 325          |\n",
+      "|            |              |\u001b[0m\n",
+      "\u001b[32m[10/28 20:41:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
+      "\u001b[32m[10/28 20:41:52 d2.data.common]: \u001b[0mSerializing 325 elements to byte tensors and concatenating them all ...\n",
+      "\u001b[32m[10/28 20:41:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
+      "\u001b[32m[10/28 20:41:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 325 batches\n",
+      "\u001b[32m[10/28 20:41:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/325. Dataloading: 0.0064 s/iter. Inference: 0.1780 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:00:57\n",
+      "\u001b[32m[10/28 20:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 39/325. Dataloading: 0.0018 s/iter. Inference: 0.1813 s/iter. Eval: 0.0001 s/iter. Total: 0.1833 s/iter. ETA=0:00:52\n",
+      "\u001b[32m[10/28 20:42:05 d2.evaluation.evaluator]: \u001b[0mInference done 67/325. Dataloading: 0.0014 s/iter. Inference: 0.1811 s/iter. Eval: 0.0001 s/iter. Total: 0.1827 s/iter. ETA=0:00:47\n",
+      "\u001b[32m[10/28 20:42:10 d2.evaluation.evaluator]: \u001b[0mInference done 94/325. Dataloading: 0.0013 s/iter. Inference: 0.1821 s/iter. Eval: 0.0001 s/iter. Total: 0.1835 s/iter. ETA=0:00:42\n",
+      "\u001b[32m[10/28 20:42:15 d2.evaluation.evaluator]: \u001b[0mInference done 122/325. Dataloading: 0.0019 s/iter. Inference: 0.1804 s/iter. Eval: 0.0001 s/iter. Total: 0.1825 s/iter. ETA=0:00:37\n",
+      "\u001b[32m[10/28 20:42:20 d2.evaluation.evaluator]: \u001b[0mInference done 149/325. Dataloading: 0.0034 s/iter. Inference: 0.1805 s/iter. Eval: 0.0001 s/iter. Total: 0.1840 s/iter. ETA=0:00:32\n",
+      "\u001b[32m[10/28 20:42:25 d2.evaluation.evaluator]: \u001b[0mInference done 178/325. Dataloading: 0.0030 s/iter. Inference: 0.1792 s/iter. Eval: 0.0001 s/iter. Total: 0.1824 s/iter. ETA=0:00:26\n",
+      "\u001b[32m[10/28 20:42:30 d2.evaluation.evaluator]: \u001b[0mInference done 203/325. Dataloading: 0.0052 s/iter. Inference: 0.1793 s/iter. Eval: 0.0001 s/iter. Total: 0.1847 s/iter. ETA=0:00:22\n",
+      "\u001b[32m[10/28 20:42:35 d2.evaluation.evaluator]: \u001b[0mInference done 230/325. Dataloading: 0.0047 s/iter. Inference: 0.1804 s/iter. Eval: 0.0001 s/iter. Total: 0.1852 s/iter. ETA=0:00:17\n",
+      "\u001b[32m[10/28 20:42:40 d2.evaluation.evaluator]: \u001b[0mInference done 257/325. Dataloading: 0.0051 s/iter. Inference: 0.1802 s/iter. Eval: 0.0001 s/iter. Total: 0.1854 s/iter. ETA=0:00:12\n",
+      "\u001b[32m[10/28 20:42:45 d2.evaluation.evaluator]: \u001b[0mInference done 286/325. Dataloading: 0.0047 s/iter. Inference: 0.1798 s/iter. Eval: 0.0001 s/iter. Total: 0.1846 s/iter. ETA=0:00:07\n",
+      "\u001b[32m[10/28 20:42:50 d2.evaluation.evaluator]: \u001b[0mInference done 314/325. Dataloading: 0.0044 s/iter. Inference: 0.1796 s/iter. Eval: 0.0001 s/iter. Total: 0.1842 s/iter. ETA=0:00:02\n",
+      "\u001b[32m[10/28 20:42:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:58.916088 (0.184113 s / iter per device, on 1 devices)\n",
+      "\u001b[32m[10/28 20:42:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:57 (0.179219 s / iter per device, on 1 devices)\n",
+      "\u001b[32m[10/28 20:42:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
+      "\u001b[32m[10/28 20:42:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
+      "\u001b[32m[10/28 20:42:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
+      "Loading and preparing results...\n",
+      "DONE (t=0.00s)\n",
+      "creating index...\n",
+      "index created!\n",
+      "\u001b[32m[10/28 20:42:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
+      "\u001b[32m[10/28 20:42:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
+      "\u001b[32m[10/28 20:42:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
+      "\u001b[32m[10/28 20:42:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n",
+      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
+      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.147\n",
+      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.117\n",
+      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
+      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.060\n",
+      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.114\n",
+      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
+      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.250\n",
+      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n",
+      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
+      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.111\n",
+      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.276\n",
+      "\u001b[32m[10/28 20:42:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
+      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
+      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
+      "| 10.239 | 14.740 | 11.678 | 0.000 | 5.971 | 11.360 |\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "100%|█████████████████████████████████████████| 26/26 [00:00<00:00, 2940.51it/s]\n"
+     ]
+    },
+    {
+     "ename": "TypeError",
+     "evalue": "'NoneType' object is not subscriptable",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
+      "\u001b[0;32m/tmp/ipykernel_559010/115025483.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./test_imgs/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./test_imgs/{img}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     v = v.draw_instance_predictions(\n",
+      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
      ]
     }
    ],
diff --git a/V2/test_imgs/README.md b/V2/test_imgs/README.md
deleted file mode 100644
index e56eaa7..0000000
--- a/V2/test_imgs/README.md
+++ /dev/null
@@ -1 +0,0 @@
-# Test Images
diff --git a/V2/wandb/latest-run b/V2/wandb/latest-run
index 4bd0b72..611a059 120000
--- a/V2/wandb/latest-run
+++ b/V2/wandb/latest-run
@@ -1 +1 @@
-run-20211028_201107-2jukfznr
\ No newline at end of file
+run-20211028_204457-3r95n0qd
\ No newline at end of file
