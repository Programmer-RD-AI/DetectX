
  0%|                                                                           | 0/1853 [00:00<?, ?it/s]
[32m[10/28 15:08:27 d2.engine.defaults]: [39mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )























































 99%|███████████████████████████████████████████████████████████████▎| 1834/1853 [01:50<00:01, 15.20it/s]
[32m[10/28 15:10:18 d2.data.build]: [39mRemoved 0 images with no usable annotations. 1853 images left.
[32m[10/28 15:10:18 d2.data.build]: [39mDistribution of instances among all 1 categories:
[36m|  category  | #instances   |
[36m|:----------:|:-------------|
[36m|    Card    | 1853         |
[36m|            |              |
[32m[10/28 15:10:18 d2.data.dataset_mapper]: [39m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[10/28 15:10:18 d2.data.build]: [39mUsing training sampler TrainingSampler
[32m[10/28 15:10:18 d2.data.common]: [39mSerializing 1853 elements to byte tensors and concatenating them all ...
100%|████████████████████████████████████████████████████████████████| 1853/1853 [01:51<00:00, 16.64it/s]
2021-10-28 15:10:18.896888: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[32m[10/28 15:10:22 d2.engine.train_loop]: [39mStarting training from iteration 0
Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.
Some model parameters or buffers are not found in the checkpoint:
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}
[34mroi_heads.box_predictor.cls_score.{bias, weight}
The checkpoint state_dict contains keys that are not used by the model:
  [35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}
/media/indika/Sync/anaconda3/envs/detectron2/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
[32m[10/28 15:10:47 d2.utils.events]: [39m eta: 0:08:40  iter: 19  total_loss: 0.8811  loss_cls: 0.5306  loss_box_reg: 0.2811  loss_rpn_cls: 0.02198  loss_rpn_loc: 0.005865  time: 1.1527  data_time: 0.0409  lr: 9.7405e-06  max_mem: 6057M
[32m[10/28 15:11:09 d2.utils.events]: [39m eta: 0:07:45  iter: 39  total_loss: 0.8157  loss_cls: 0.4688  loss_box_reg: 0.3063  loss_rpn_cls: 0.03293  loss_rpn_loc: 0.01132  time: 1.1319  data_time: 0.0025  lr: 1.9731e-05  max_mem: 6057M
[32m[10/28 15:11:29 d2.utils.events]: [39m eta: 0:07:17  iter: 59  total_loss: 0.7406  loss_cls: 0.3689  loss_box_reg: 0.3237  loss_rpn_cls: 0.01889  loss_rpn_loc: 0.006502  time: 1.0900  data_time: 0.0023  lr: 2.972e-05  max_mem: 6057M
[32m[10/28 15:11:50 d2.utils.events]: [39m eta: 0:06:56  iter: 79  total_loss: 0.6703  loss_cls: 0.3188  loss_box_reg: 0.3264  loss_rpn_cls: 0.01773  loss_rpn_loc: 0.008067  time: 1.0757  data_time: 0.0025  lr: 3.9711e-05  max_mem: 6057M
[32m[10/28 15:12:11 d2.utils.events]: [39m eta: 0:06:38  iter: 99  total_loss: 0.7431  loss_cls: 0.3075  loss_box_reg: 0.4022  loss_rpn_cls: 0.01657  loss_rpn_loc: 0.006802  time: 1.0768  data_time: 0.0024  lr: 4.9701e-05  max_mem: 6057M
[32m[10/28 15:12:32 d2.utils.events]: [39m eta: 0:06:17  iter: 119  total_loss: 0.5785  loss_cls: 0.2265  loss_box_reg: 0.2429  loss_rpn_cls: 0.07409  loss_rpn_loc: 0.008323  time: 1.0708  data_time: 0.0028  lr: 5.9691e-05  max_mem: 6057M
[32m[10/28 15:12:53 d2.utils.events]: [39m eta: 0:05:58  iter: 139  total_loss: 0.6013  loss_cls: 0.2423  loss_box_reg: 0.327  loss_rpn_cls: 0.0257  loss_rpn_loc: 0.006715  time: 1.0673  data_time: 0.0023  lr: 6.9681e-05  max_mem: 6057M
[32m[10/28 15:13:13 d2.utils.events]: [39m eta: 0:05:37  iter: 159  total_loss: 0.5823  loss_cls: 0.234  loss_box_reg: 0.2872  loss_rpn_cls: 0.04877  loss_rpn_loc: 0.007639  time: 1.0585  data_time: 0.0030  lr: 7.9671e-05  max_mem: 6057M
[32m[10/28 15:13:35 d2.utils.events]: [39m eta: 0:05:17  iter: 179  total_loss: 0.6151  loss_cls: 0.2451  loss_box_reg: 0.314  loss_rpn_cls: 0.02016  loss_rpn_loc: 0.00778  time: 1.0605  data_time: 0.0024  lr: 8.966e-05  max_mem: 6057M
[32m[10/28 15:13:58 d2.utils.events]: [39m eta: 0:04:58  iter: 199  total_loss: 0.6535  loss_cls: 0.268  loss_box_reg: 0.3028  loss_rpn_cls: 0.0156  loss_rpn_loc: 0.006283  time: 1.0703  data_time: 0.0026  lr: 9.9651e-05  max_mem: 6057M
[32m[10/28 15:14:19 d2.utils.events]: [39m eta: 0:04:39  iter: 219  total_loss: 0.5704  loss_cls: 0.2235  loss_box_reg: 0.3124  loss_rpn_cls: 0.008797  loss_rpn_loc: 0.01037  time: 1.0688  data_time: 0.0025  lr: 0.00010964  max_mem: 6057M
[32m[10/28 15:14:42 d2.utils.events]: [39m eta: 0:04:19  iter: 239  total_loss: 0.561  loss_cls: 0.2143  loss_box_reg: 0.3015  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.007977  time: 1.0749  data_time: 0.0027  lr: 0.00011963  max_mem: 6057M
[32m[10/28 15:15:04 d2.utils.events]: [39m eta: 0:04:00  iter: 259  total_loss: 0.5804  loss_cls: 0.229  loss_box_reg: 0.2983  loss_rpn_cls: 0.02855  loss_rpn_loc: 0.006716  time: 1.0754  data_time: 0.0024  lr: 0.00012962  max_mem: 6057M
[32m[10/28 15:15:24 d2.utils.events]: [39m eta: 0:03:39  iter: 279  total_loss: 0.6063  loss_cls: 0.2166  loss_box_reg: 0.3845  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.006625  time: 1.0724  data_time: 0.0025  lr: 0.00013961  max_mem: 6057M
[32m[10/28 15:15:45 d2.utils.events]: [39m eta: 0:03:19  iter: 299  total_loss: 0.5845  loss_cls: 0.2118  loss_box_reg: 0.2966  loss_rpn_cls: 0.03712  loss_rpn_loc: 0.007604  time: 1.0699  data_time: 0.0025  lr: 0.0001496  max_mem: 6057M
[32m[10/28 15:16:08 d2.utils.events]: [39m eta: 0:03:00  iter: 319  total_loss: 0.6078  loss_cls: 0.2123  loss_box_reg: 0.3402  loss_rpn_cls: 0.02941  loss_rpn_loc: 0.004774  time: 1.0756  data_time: 0.0025  lr: 0.00015959  max_mem: 6057M
[32m[10/28 15:16:29 d2.utils.events]: [39m eta: 0:02:39  iter: 339  total_loss: 0.4728  loss_cls: 0.1883  loss_box_reg: 0.2398  loss_rpn_cls: 0.02379  loss_rpn_loc: 0.006566  time: 1.0730  data_time: 0.0024  lr: 0.00016958  max_mem: 6057M
[32m[10/28 15:16:50 d2.utils.events]: [39m eta: 0:02:20  iter: 359  total_loss: 0.6132  loss_cls: 0.2326  loss_box_reg: 0.3252  loss_rpn_cls: 0.01898  loss_rpn_loc: 0.007248  time: 1.0720  data_time: 0.0025  lr: 0.00017957  max_mem: 6057M
[32m[10/28 15:17:10 d2.utils.events]: [39m eta: 0:01:59  iter: 379  total_loss: 0.4686  loss_cls: 0.1838  loss_box_reg: 0.2682  loss_rpn_cls: 0.01287  loss_rpn_loc: 0.008878  time: 1.0678  data_time: 0.0025  lr: 0.00018956  max_mem: 6057M
[32m[10/28 15:17:29 d2.utils.events]: [39m eta: 0:01:39  iter: 399  total_loss: 0.5403  loss_cls: 0.2048  loss_box_reg: 0.3134  loss_rpn_cls: 0.01506  loss_rpn_loc: 0.004758  time: 1.0612  data_time: 0.0024  lr: 0.00019955  max_mem: 6057M
[32m[10/28 15:17:51 d2.utils.events]: [39m eta: 0:01:19  iter: 419  total_loss: 0.4696  loss_cls: 0.1805  loss_box_reg: 0.2375  loss_rpn_cls: 0.01904  loss_rpn_loc: 0.009774  time: 1.0646  data_time: 0.0026  lr: 0.00020954  max_mem: 6057M
[32m[10/28 15:18:13 d2.utils.events]: [39m eta: 0:00:59  iter: 439  total_loss: 0.5541  loss_cls: 0.2029  loss_box_reg: 0.3123  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.008527  time: 1.0653  data_time: 0.0024  lr: 0.00021953  max_mem: 6057M
[32m[10/28 15:18:34 d2.utils.events]: [39m eta: 0:00:39  iter: 459  total_loss: 0.5209  loss_cls: 0.1938  loss_box_reg: 0.304  loss_rpn_cls: 0.01682  loss_rpn_loc: 0.0122  time: 1.0653  data_time: 0.0023  lr: 0.00022952  max_mem: 6057M
[32m[10/28 15:18:54 d2.utils.events]: [39m eta: 0:00:19  iter: 479  total_loss: 0.459  loss_cls: 0.1916  loss_box_reg: 0.2289  loss_rpn_cls: 0.02379  loss_rpn_loc: 0.009945  time: 1.0629  data_time: 0.0025  lr: 0.00023951  max_mem: 6057M
[32m[10/28 15:19:16 d2.utils.events]: [39m eta: 0:00:00  iter: 499  total_loss: 0.4826  loss_cls: 0.2005  loss_box_reg: 0.2432  loss_rpn_cls: 0.0224  loss_rpn_loc: 0.008176  time: 1.0621  data_time: 0.0023  lr: 0.0002495  max_mem: 6057M
[32m[10/28 15:19:16 d2.engine.hooks]: [39mOverall training speed: 498 iterations in 0:08:48 (1.0621 s / it)
[32m[10/28 15:19:16 d2.engine.hooks]: [39mTotal training time: 0:08:49 (0:00:00 on hooks)
  1%|▍                                                                 | 11/1853 [00:00<02:36, 11.80it/s]
[32m[10/28 15:19:19 d2.evaluation.coco_evaluation]: [39m'test' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...
























































100%|████████████████████████████████████████████████████████████████| 1853/1853 [01:54<00:00, 16.24it/s]
  0%|▎                                                                  | 7/1853 [00:00<02:13, 13.84it/s]
[32m[10/28 15:21:13 d2.data.datasets.coco]: [39mConverting dataset dicts into COCO format
[32m[10/28 15:21:13 d2.data.datasets.coco]: [39mConversion finished, #images: 1853, #annotations: 1853
























































100%|████████████████████████████████████████████████████████████████| 1853/1853 [01:51<00:00, 16.66it/s]
[32m[10/28 15:23:04 d2.data.dataset_mapper]: [39m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[10/28 15:23:04 d2.data.common]: [39mSerializing 1853 elements to byte tensors and concatenating them all ...
[32m[10/28 15:23:04 d2.data.common]: [39mSerialized dataset takes 0.40 MiB
[32m[10/28 15:23:04 d2.evaluation.evaluator]: [39mStart inference on 1853 batches
[32m[10/28 15:23:07 d2.evaluation.evaluator]: [39mInference done 11/1853. Dataloading: 0.0006 s/iter. Inference: 0.1795 s/iter. Eval: 0.0001 s/iter. Total: 0.1803 s/iter. ETA=0:05:32
[32m[10/28 15:23:12 d2.evaluation.evaluator]: [39mInference done 38/1853. Dataloading: 0.0053 s/iter. Inference: 0.1845 s/iter. Eval: 0.0001 s/iter. Total: 0.1900 s/iter. ETA=0:05:44
[32m[10/28 15:23:17 d2.evaluation.evaluator]: [39mInference done 65/1853. Dataloading: 0.0048 s/iter. Inference: 0.1844 s/iter. Eval: 0.0001 s/iter. Total: 0.1893 s/iter. ETA=0:05:38
[32m[10/28 15:23:22 d2.evaluation.evaluator]: [39mInference done 94/1853. Dataloading: 0.0054 s/iter. Inference: 0.1794 s/iter. Eval: 0.0001 s/iter. Total: 0.1849 s/iter. ETA=0:05:25
[32m[10/28 15:23:27 d2.evaluation.evaluator]: [39mInference done 122/1853. Dataloading: 0.0043 s/iter. Inference: 0.1803 s/iter. Eval: 0.0001 s/iter. Total: 0.1848 s/iter. ETA=0:05:19
[32m[10/28 15:23:32 d2.evaluation.evaluator]: [39mInference done 149/1853. Dataloading: 0.0046 s/iter. Inference: 0.1801 s/iter. Eval: 0.0001 s/iter. Total: 0.1849 s/iter. ETA=0:05:15
[32m[10/28 15:23:37 d2.evaluation.evaluator]: [39mInference done 175/1853. Dataloading: 0.0062 s/iter. Inference: 0.1801 s/iter. Eval: 0.0001 s/iter. Total: 0.1864 s/iter. ETA=0:05:12
[32m[10/28 15:23:43 d2.evaluation.evaluator]: [39mInference done 204/1853. Dataloading: 0.0059 s/iter. Inference: 0.1786 s/iter. Eval: 0.0001 s/iter. Total: 0.1847 s/iter. ETA=0:05:04
[32m[10/28 15:23:48 d2.evaluation.evaluator]: [39mInference done 232/1853. Dataloading: 0.0053 s/iter. Inference: 0.1786 s/iter. Eval: 0.0001 s/iter. Total: 0.1841 s/iter. ETA=0:04:58
[32m[10/28 15:23:53 d2.evaluation.evaluator]: [39mInference done 261/1853. Dataloading: 0.0048 s/iter. Inference: 0.1785 s/iter. Eval: 0.0001 s/iter. Total: 0.1835 s/iter. ETA=0:04:52
[32m[10/28 15:23:58 d2.evaluation.evaluator]: [39mInference done 289/1853. Dataloading: 0.0044 s/iter. Inference: 0.1789 s/iter. Eval: 0.0001 s/iter. Total: 0.1835 s/iter. ETA=0:04:47
[32m[10/28 15:24:03 d2.evaluation.evaluator]: [39mInference done 316/1853. Dataloading: 0.0041 s/iter. Inference: 0.1796 s/iter. Eval: 0.0001 s/iter. Total: 0.1839 s/iter. ETA=0:04:42
[32m[10/28 15:24:08 d2.evaluation.evaluator]: [39mInference done 342/1853. Dataloading: 0.0045 s/iter. Inference: 0.1800 s/iter. Eval: 0.0001 s/iter. Total: 0.1847 s/iter. ETA=0:04:39
[32m[10/28 15:24:13 d2.evaluation.evaluator]: [39mInference done 370/1853. Dataloading: 0.0043 s/iter. Inference: 0.1800 s/iter. Eval: 0.0001 s/iter. Total: 0.1844 s/iter. ETA=0:04:33
[32m[10/28 15:24:18 d2.evaluation.evaluator]: [39mInference done 398/1853. Dataloading: 0.0041 s/iter. Inference: 0.1799 s/iter. Eval: 0.0001 s/iter. Total: 0.1841 s/iter. ETA=0:04:27
[32m[10/28 15:24:23 d2.evaluation.evaluator]: [39mInference done 426/1853. Dataloading: 0.0040 s/iter. Inference: 0.1798 s/iter. Eval: 0.0001 s/iter. Total: 0.1839 s/iter. ETA=0:04:22
[32m[10/28 15:24:28 d2.evaluation.evaluator]: [39mInference done 454/1853. Dataloading: 0.0038 s/iter. Inference: 0.1799 s/iter. Eval: 0.0001 s/iter. Total: 0.1838 s/iter. ETA=0:04:17
[32m[10/28 15:24:33 d2.evaluation.evaluator]: [39mInference done 482/1853. Dataloading: 0.0037 s/iter. Inference: 0.1799 s/iter. Eval: 0.0001 s/iter. Total: 0.1838 s/iter. ETA=0:04:12
[32m[10/28 15:24:39 d2.evaluation.evaluator]: [39mInference done 510/1853. Dataloading: 0.0038 s/iter. Inference: 0.1799 s/iter. Eval: 0.0001 s/iter. Total: 0.1839 s/iter. ETA=0:04:06
[32m[10/28 15:24:44 d2.evaluation.evaluator]: [39mInference done 538/1853. Dataloading: 0.0036 s/iter. Inference: 0.1798 s/iter. Eval: 0.0001 s/iter. Total: 0.1836 s/iter. ETA=0:04:01
[32m[10/28 15:24:49 d2.evaluation.evaluator]: [39mInference done 566/1853. Dataloading: 0.0035 s/iter. Inference: 0.1799 s/iter. Eval: 0.0001 s/iter. Total: 0.1836 s/iter. ETA=0:03:56
[32m[10/28 15:24:54 d2.evaluation.evaluator]: [39mInference done 594/1853. Dataloading: 0.0034 s/iter. Inference: 0.1799 s/iter. Eval: 0.0001 s/iter. Total: 0.1834 s/iter. ETA=0:03:50
[32m[10/28 15:24:59 d2.evaluation.evaluator]: [39mInference done 620/1853. Dataloading: 0.0036 s/iter. Inference: 0.1801 s/iter. Eval: 0.0001 s/iter. Total: 0.1839 s/iter. ETA=0:03:46
[32m[10/28 15:25:04 d2.evaluation.evaluator]: [39mInference done 647/1853. Dataloading: 0.0035 s/iter. Inference: 0.1803 s/iter. Eval: 0.0001 s/iter. Total: 0.1840 s/iter. ETA=0:03:41
[32m[10/28 15:25:09 d2.evaluation.evaluator]: [39mInference done 674/1853. Dataloading: 0.0037 s/iter. Inference: 0.1804 s/iter. Eval: 0.0001 s/iter. Total: 0.1843 s/iter. ETA=0:03:37
[32m[10/28 15:25:14 d2.evaluation.evaluator]: [39mInference done 700/1853. Dataloading: 0.0040 s/iter. Inference: 0.1805 s/iter. Eval: 0.0001 s/iter. Total: 0.1847 s/iter. ETA=0:03:32
[32m[10/28 15:25:19 d2.evaluation.evaluator]: [39mInference done 728/1853. Dataloading: 0.0040 s/iter. Inference: 0.1804 s/iter. Eval: 0.0001 s/iter. Total: 0.1846 s/iter. ETA=0:03:27
[32m[10/28 15:25:24 d2.evaluation.evaluator]: [39mInference done 756/1853. Dataloading: 0.0039 s/iter. Inference: 0.1805 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:03:22
[32m[10/28 15:25:29 d2.evaluation.evaluator]: [39mInference done 783/1853. Dataloading: 0.0041 s/iter. Inference: 0.1804 s/iter. Eval: 0.0001 s/iter. Total: 0.1847 s/iter. ETA=0:03:17
[32m[10/28 15:25:35 d2.evaluation.evaluator]: [39mInference done 808/1853. Dataloading: 0.0045 s/iter. Inference: 0.1806 s/iter. Eval: 0.0001 s/iter. Total: 0.1853 s/iter. ETA=0:03:13
[32m[10/28 15:25:40 d2.evaluation.evaluator]: [39mInference done 834/1853. Dataloading: 0.0046 s/iter. Inference: 0.1807 s/iter. Eval: 0.0001 s/iter. Total: 0.1855 s/iter. ETA=0:03:09
[32m[10/28 15:25:45 d2.evaluation.evaluator]: [39mInference done 863/1853. Dataloading: 0.0045 s/iter. Inference: 0.1806 s/iter. Eval: 0.0001 s/iter. Total: 0.1852 s/iter. ETA=0:03:03
[32m[10/28 15:25:50 d2.evaluation.evaluator]: [39mInference done 890/1853. Dataloading: 0.0045 s/iter. Inference: 0.1807 s/iter. Eval: 0.0001 s/iter. Total: 0.1854 s/iter. ETA=0:02:58
[32m[10/28 15:25:55 d2.evaluation.evaluator]: [39mInference done 918/1853. Dataloading: 0.0045 s/iter. Inference: 0.1806 s/iter. Eval: 0.0001 s/iter. Total: 0.1852 s/iter. ETA=0:02:53
[32m[10/28 15:26:00 d2.evaluation.evaluator]: [39mInference done 946/1853. Dataloading: 0.0045 s/iter. Inference: 0.1804 s/iter. Eval: 0.0001 s/iter. Total: 0.1851 s/iter. ETA=0:02:47
[32m[10/28 15:26:05 d2.evaluation.evaluator]: [39mInference done 974/1853. Dataloading: 0.0044 s/iter. Inference: 0.1804 s/iter. Eval: 0.0001 s/iter. Total: 0.1850 s/iter. ETA=0:02:42
[32m[10/28 15:26:10 d2.evaluation.evaluator]: [39mInference done 1003/1853. Dataloading: 0.0043 s/iter. Inference: 0.1802 s/iter. Eval: 0.0001 s/iter. Total: 0.1847 s/iter. ETA=0:02:37
[32m[10/28 15:26:15 d2.evaluation.evaluator]: [39mInference done 1032/1853. Dataloading: 0.0042 s/iter. Inference: 0.1801 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:02:31
[32m[10/28 15:26:20 d2.evaluation.evaluator]: [39mInference done 1060/1853. Dataloading: 0.0042 s/iter. Inference: 0.1801 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:02:26
[32m[10/28 15:26:25 d2.evaluation.evaluator]: [39mInference done 1086/1853. Dataloading: 0.0043 s/iter. Inference: 0.1802 s/iter. Eval: 0.0001 s/iter. Total: 0.1847 s/iter. ETA=0:02:21
[32m[10/28 15:26:31 d2.evaluation.evaluator]: [39mInference done 1114/1853. Dataloading: 0.0043 s/iter. Inference: 0.1802 s/iter. Eval: 0.0001 s/iter. Total: 0.1846 s/iter. ETA=0:02:16
[32m[10/28 15:26:36 d2.evaluation.evaluator]: [39mInference done 1143/1853. Dataloading: 0.0042 s/iter. Inference: 0.1800 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:02:10
[32m[10/28 15:26:41 d2.evaluation.evaluator]: [39mInference done 1171/1853. Dataloading: 0.0042 s/iter. Inference: 0.1801 s/iter. Eval: 0.0001 s/iter. Total: 0.1844 s/iter. ETA=0:02:05
[32m[10/28 15:26:46 d2.evaluation.evaluator]: [39mInference done 1197/1853. Dataloading: 0.0042 s/iter. Inference: 0.1802 s/iter. Eval: 0.0001 s/iter. Total: 0.1846 s/iter. ETA=0:02:01
[32m[10/28 15:26:51 d2.evaluation.evaluator]: [39mInference done 1225/1853. Dataloading: 0.0042 s/iter. Inference: 0.1803 s/iter. Eval: 0.0001 s/iter. Total: 0.1846 s/iter. ETA=0:01:55
[32m[10/28 15:26:56 d2.evaluation.evaluator]: [39mInference done 1252/1853. Dataloading: 0.0043 s/iter. Inference: 0.1803 s/iter. Eval: 0.0001 s/iter. Total: 0.1847 s/iter. ETA=0:01:50
[32m[10/28 15:27:01 d2.evaluation.evaluator]: [39mInference done 1280/1853. Dataloading: 0.0042 s/iter. Inference: 0.1802 s/iter. Eval: 0.0001 s/iter. Total: 0.1846 s/iter. ETA=0:01:45
[32m[10/28 15:27:06 d2.evaluation.evaluator]: [39mInference done 1308/1853. Dataloading: 0.0042 s/iter. Inference: 0.1802 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:01:40
[32m[10/28 15:27:11 d2.evaluation.evaluator]: [39mInference done 1335/1853. Dataloading: 0.0041 s/iter. Inference: 0.1803 s/iter. Eval: 0.0001 s/iter. Total: 0.1846 s/iter. ETA=0:01:35
[32m[10/28 15:27:16 d2.evaluation.evaluator]: [39mInference done 1363/1853. Dataloading: 0.0040 s/iter. Inference: 0.1803 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:01:30
[32m[10/28 15:27:21 d2.evaluation.evaluator]: [39mInference done 1390/1853. Dataloading: 0.0040 s/iter. Inference: 0.1804 s/iter. Eval: 0.0001 s/iter. Total: 0.1846 s/iter. ETA=0:01:25
[32m[10/28 15:27:27 d2.evaluation.evaluator]: [39mInference done 1419/1853. Dataloading: 0.0039 s/iter. Inference: 0.1804 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:01:20
[32m[10/28 15:27:32 d2.evaluation.evaluator]: [39mInference done 1447/1853. Dataloading: 0.0038 s/iter. Inference: 0.1804 s/iter. Eval: 0.0001 s/iter. Total: 0.1844 s/iter. ETA=0:01:14
[32m[10/28 15:27:37 d2.evaluation.evaluator]: [39mInference done 1477/1853. Dataloading: 0.0038 s/iter. Inference: 0.1802 s/iter. Eval: 0.0001 s/iter. Total: 0.1841 s/iter. ETA=0:01:09
[32m[10/28 15:27:42 d2.evaluation.evaluator]: [39mInference done 1505/1853. Dataloading: 0.0038 s/iter. Inference: 0.1801 s/iter. Eval: 0.0001 s/iter. Total: 0.1841 s/iter. ETA=0:01:04
[32m[10/28 15:27:47 d2.evaluation.evaluator]: [39mInference done 1533/1853. Dataloading: 0.0037 s/iter. Inference: 0.1801 s/iter. Eval: 0.0001 s/iter. Total: 0.1840 s/iter. ETA=0:00:58
[32m[10/28 15:27:52 d2.evaluation.evaluator]: [39mInference done 1560/1853. Dataloading: 0.0037 s/iter. Inference: 0.1802 s/iter. Eval: 0.0001 s/iter. Total: 0.1841 s/iter. ETA=0:00:53
[32m[10/28 15:27:57 d2.evaluation.evaluator]: [39mInference done 1587/1853. Dataloading: 0.0038 s/iter. Inference: 0.1802 s/iter. Eval: 0.0001 s/iter. Total: 0.1841 s/iter. ETA=0:00:48
[32m[10/28 15:28:02 d2.evaluation.evaluator]: [39mInference done 1615/1853. Dataloading: 0.0037 s/iter. Inference: 0.1802 s/iter. Eval: 0.0001 s/iter. Total: 0.1841 s/iter. ETA=0:00:43
[32m[10/28 15:28:07 d2.evaluation.evaluator]: [39mInference done 1645/1853. Dataloading: 0.0037 s/iter. Inference: 0.1801 s/iter. Eval: 0.0001 s/iter. Total: 0.1839 s/iter. ETA=0:00:38
[32m[10/28 15:28:12 d2.evaluation.evaluator]: [39mInference done 1673/1853. Dataloading: 0.0036 s/iter. Inference: 0.1801 s/iter. Eval: 0.0001 s/iter. Total: 0.1838 s/iter. ETA=0:00:33
[32m[10/28 15:28:18 d2.evaluation.evaluator]: [39mInference done 1702/1853. Dataloading: 0.0036 s/iter. Inference: 0.1800 s/iter. Eval: 0.0001 s/iter. Total: 0.1837 s/iter. ETA=0:00:27
[32m[10/28 15:28:23 d2.evaluation.evaluator]: [39mInference done 1730/1853. Dataloading: 0.0036 s/iter. Inference: 0.1800 s/iter. Eval: 0.0001 s/iter. Total: 0.1837 s/iter. ETA=0:00:22
[32m[10/28 15:28:28 d2.evaluation.evaluator]: [39mInference done 1759/1853. Dataloading: 0.0035 s/iter. Inference: 0.1799 s/iter. Eval: 0.0001 s/iter. Total: 0.1836 s/iter. ETA=0:00:17
[32m[10/28 15:28:33 d2.evaluation.evaluator]: [39mInference done 1788/1853. Dataloading: 0.0035 s/iter. Inference: 0.1799 s/iter. Eval: 0.0001 s/iter. Total: 0.1835 s/iter. ETA=0:00:11
[32m[10/28 15:28:38 d2.evaluation.evaluator]: [39mInference done 1816/1853. Dataloading: 0.0035 s/iter. Inference: 0.1798 s/iter. Eval: 0.0001 s/iter. Total: 0.1835 s/iter. ETA=0:00:06
[32m[10/28 15:28:43 d2.evaluation.evaluator]: [39mInference done 1844/1853. Dataloading: 0.0034 s/iter. Inference: 0.1799 s/iter. Eval: 0.0001 s/iter. Total: 0.1834 s/iter. ETA=0:00:01
100%|██████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 2736.35it/s]
[32m[10/28 15:28:45 d2.evaluation.evaluator]: [39mTotal inference time: 0:05:38.996392 (0.183440 s / iter per device, on 1 devices)
[32m[10/28 15:28:45 d2.evaluation.evaluator]: [39mTotal inference pure compute time: 0:05:32 (0.179804 s / iter per device, on 1 devices)
[32m[10/28 15:28:45 d2.evaluation.coco_evaluation]: [39mPreparing results for COCO format ...
[32m[10/28 15:28:45 d2.evaluation.coco_evaluation]: [39mSaving results to ./output/coco_instances_results.json
[32m[10/28 15:28:45 d2.evaluation.coco_evaluation]: [39mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[32m[10/28 15:28:45 d2.evaluation.fast_eval_api]: [39mEvaluate annotation type *bbox*
[32m[10/28 15:28:45 d2.evaluation.fast_eval_api]: [39mCOCOeval_opt.evaluate() finished in 0.09 seconds.
[32m[10/28 15:28:45 d2.evaluation.fast_eval_api]: [39mAccumulating evaluation results...
[32m[10/28 15:28:45 d2.evaluation.fast_eval_api]: [39mCOCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.112
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.162
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.123
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.038
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.126
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.280
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.280
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.084
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313
[32m[10/28 15:28:45 d2.evaluation.coco_evaluation]: [39mEvaluation results for bbox:
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 11.203 | 16.180 | 12.257 | 0.000 | 3.813 | 12.589 |