diff --git a/V2/Final.py b/V2/Final.py
index e69de29..2510d43 100644
--- a/V2/Final.py
+++ b/V2/Final.py
@@ -0,0 +1,4 @@
+from Model import *
+
+model = Model()
+model.train()
diff --git a/V2/box.jpg b/V2/box.jpg
deleted file mode 100644
index c38da34..0000000
Binary files a/V2/box.jpg and /dev/null differ
diff --git a/V2/crop.jpg b/V2/crop.jpg
deleted file mode 100644
index 9f51961..0000000
Binary files a/V2/crop.jpg and /dev/null differ
diff --git a/V2/output.png b/V2/output.png
deleted file mode 100644
index 24f7c5a..0000000
Binary files a/V2/output.png and /dev/null differ
diff --git a/V2/output/last_checkpoint b/V2/output/last_checkpoint
deleted file mode 100644
index da0e9f9..0000000
--- a/V2/output/last_checkpoint
+++ /dev/null
@@ -1 +0,0 @@
-model_final.pth
\ No newline at end of file
diff --git a/V2/output/metrics.json b/V2/output/metrics.json
deleted file mode 100644
index b1514e4..0000000
--- a/V2/output/metrics.json
+++ /dev/null
@@ -1,25 +0,0 @@
-{"data_time": 0.002241438998680678, "eta_seconds": 455.20828439912293, "fast_rcnn/cls_accuracy": 0.78515625, "fast_rcnn/false_negative": 0.9383301707779885, "fast_rcnn/fg_cls_accuracy": 0.061669829222011384, "iteration": 19, "loss_box_reg": 0.3170660436153412, "loss_cls": 0.6054781675338745, "loss_rpn_cls": 0.020858346950262785, "loss_rpn_loc": 0.006697731325402856, "lr": 9.7405e-06, "roi_head/num_bg_samples": 117.5, "roi_head/num_fg_samples": 10.5, "rpn/num_neg_anchors": 251.5, "rpn/num_pos_anchors": 4.5, "time": 0.9483505924981728, "total_loss": 1.0273798005655408}
-{"data_time": 0.002371901498918305, "eta_seconds": 452.43091711981833, "fast_rcnn/cls_accuracy": 0.87890625, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 39, "loss_box_reg": 0.3697272837162018, "loss_cls": 0.5125723481178284, "loss_rpn_cls": 0.013182254508137703, "loss_rpn_loc": 0.007744537433609366, "lr": 1.97305e-05, "roi_head/num_bg_samples": 116.25, "roi_head/num_fg_samples": 11.75, "rpn/num_neg_anchors": 251.75, "rpn/num_pos_anchors": 4.25, "time": 1.0257414994994178, "total_loss": 0.9200895733665675}
-{"data_time": 0.0024158399992302293, "eta_seconds": 447.8779998001846, "fast_rcnn/cls_accuracy": 0.900390625, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 59, "loss_box_reg": 0.3843126744031906, "loss_cls": 0.4076386094093323, "loss_rpn_cls": 0.01381482370197773, "loss_rpn_loc": 0.009916133247315884, "lr": 2.9720499999999998e-05, "roi_head/num_bg_samples": 115.5, "roi_head/num_fg_samples": 12.5, "rpn/num_neg_anchors": 249.25, "rpn/num_pos_anchors": 6.75, "time": 1.0952504120014055, "total_loss": 0.8184949597343802}
-{"data_time": 0.0023400029986078152, "eta_seconds": 427.51990890017623, "fast_rcnn/cls_accuracy": 0.888671875, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 79, "loss_box_reg": 0.41639071702957153, "loss_cls": 0.34615862369537354, "loss_rpn_cls": 0.015523521229624748, "loss_rpn_loc": 0.005156809464097023, "lr": 3.9710500000000005e-05, "roi_head/num_bg_samples": 113.75, "roi_head/num_fg_samples": 14.25, "rpn/num_neg_anchors": 251.0, "rpn/num_pos_anchors": 5.0, "time": 0.9977671289998398, "total_loss": 0.8034012820571661}
-{"data_time": 0.0022925234989088494, "eta_seconds": 398.74284459947376, "fast_rcnn/cls_accuracy": 0.90625, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 99, "loss_box_reg": 0.33875276148319244, "loss_cls": 0.29640980064868927, "loss_rpn_cls": 0.017908543348312378, "loss_rpn_loc": 0.007840546313673258, "lr": 4.97005e-05, "roi_head/num_bg_samples": 116.0, "roi_head/num_fg_samples": 12.0, "rpn/num_neg_anchors": 251.0, "rpn/num_pos_anchors": 5.0, "time": 0.9674310354985209, "total_loss": 0.7256043251836672}
-{"data_time": 0.0022571404988411814, "eta_seconds": 381.9686642899251, "fast_rcnn/cls_accuracy": 0.921875, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 119, "loss_box_reg": 0.3031190186738968, "loss_cls": 0.27066364884376526, "loss_rpn_cls": 0.05773824639618397, "loss_rpn_loc": 0.008314355043694377, "lr": 5.96905e-05, "roi_head/num_bg_samples": 118.0, "roi_head/num_fg_samples": 10.0, "rpn/num_neg_anchors": 251.75, "rpn/num_pos_anchors": 4.25, "time": 1.0254427350027981, "total_loss": 0.6438839139882475}
-{"data_time": 0.0022656845012534177, "eta_seconds": 358.84349315965665, "fast_rcnn/cls_accuracy": 0.921875, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 139, "loss_box_reg": 0.27208341658115387, "loss_cls": 0.24440716207027435, "loss_rpn_cls": 0.04227563738822937, "loss_rpn_loc": 0.0069620986469089985, "lr": 6.96805e-05, "roi_head/num_bg_samples": 118.0, "roi_head/num_fg_samples": 10.0, "rpn/num_neg_anchors": 252.25, "rpn/num_pos_anchors": 3.75, "time": 0.9649403189996519, "total_loss": 0.5783320274204016}
-{"data_time": 0.0021804214993608184, "eta_seconds": 335.4296735893513, "fast_rcnn/cls_accuracy": 0.896484375, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 159, "loss_box_reg": 0.38456328213214874, "loss_cls": 0.2709561288356781, "loss_rpn_cls": 0.02542264573276043, "loss_rpn_loc": 0.005178260151296854, "lr": 7.967050000000001e-05, "roi_head/num_bg_samples": 114.75, "roi_head/num_fg_samples": 13.25, "rpn/num_neg_anchors": 252.5, "rpn/num_pos_anchors": 3.5, "time": 0.9510910494973359, "total_loss": 0.660144170280546}
-{"data_time": 0.002534584498789627, "eta_seconds": 318.1551560002845, "fast_rcnn/cls_accuracy": 0.916015625, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 179, "loss_box_reg": 0.31551769375801086, "loss_cls": 0.21085751056671143, "loss_rpn_cls": 0.024786025285720825, "loss_rpn_loc": 0.006785662611946464, "lr": 8.966049999999999e-05, "roi_head/num_bg_samples": 117.25, "roi_head/num_fg_samples": 10.75, "rpn/num_neg_anchors": 252.0, "rpn/num_pos_anchors": 4.0, "time": 1.0467128564996528, "total_loss": 0.6067179501987994}
-{"data_time": 0.0023198095004772767, "eta_seconds": 295.9673590494276, "fast_rcnn/cls_accuracy": 0.919921875, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 199, "loss_box_reg": 0.2799084037542343, "loss_cls": 0.22719429433345795, "loss_rpn_cls": 0.01838659681379795, "loss_rpn_loc": 0.008870458230376244, "lr": 9.96505e-05, "roi_head/num_bg_samples": 117.75, "roi_head/num_fg_samples": 10.25, "rpn/num_neg_anchors": 250.5, "rpn/num_pos_anchors": 5.5, "time": 0.9369367970011808, "total_loss": 0.5595364281907678}
-{"data_time": 0.0021939870002825046, "eta_seconds": 276.31187443927047, "fast_rcnn/cls_accuracy": 0.900390625, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 219, "loss_box_reg": 0.357006311416626, "loss_cls": 0.26337647438049316, "loss_rpn_cls": 0.03349246084690094, "loss_rpn_loc": 0.005261845188215375, "lr": 0.00010964050000000001, "roi_head/num_bg_samples": 115.25, "roi_head/num_fg_samples": 12.75, "rpn/num_neg_anchors": 252.5, "rpn/num_pos_anchors": 3.5, "time": 1.0204763104993617, "total_loss": 0.6638175924308598}
-{"data_time": 0.0023448795000149403, "eta_seconds": 259.4671010106322, "fast_rcnn/cls_accuracy": 0.91015625, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 239, "loss_box_reg": 0.3104320764541626, "loss_cls": 0.22369372099637985, "loss_rpn_cls": 0.015341060236096382, "loss_rpn_loc": 0.006358274258673191, "lr": 0.0001196305, "roi_head/num_bg_samples": 116.5, "roi_head/num_fg_samples": 11.5, "rpn/num_neg_anchors": 251.75, "rpn/num_pos_anchors": 4.25, "time": 1.097560757500105, "total_loss": 0.5666924840770662}
-{"data_time": 0.002324134498849162, "eta_seconds": 240.38377007993404, "fast_rcnn/cls_accuracy": 0.896484375, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 259, "loss_box_reg": 0.4049177020788193, "loss_cls": 0.24624978005886078, "loss_rpn_cls": 0.01653564814478159, "loss_rpn_loc": 0.007125839125365019, "lr": 0.0001296205, "roi_head/num_bg_samples": 114.75, "roi_head/num_fg_samples": 13.25, "rpn/num_neg_anchors": 251.75, "rpn/num_pos_anchors": 4.25, "time": 1.062130349499057, "total_loss": 0.6764889288460836}
-{"data_time": 0.00233131449931534, "eta_seconds": 220.73094823976135, "fast_rcnn/cls_accuracy": 0.900390625, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 279, "loss_box_reg": 0.32900530099868774, "loss_cls": 0.23568590730428696, "loss_rpn_cls": 0.02040062751621008, "loss_rpn_loc": 0.005203890614211559, "lr": 0.00013961050000000003, "roi_head/num_bg_samples": 115.25, "roi_head/num_fg_samples": 12.75, "rpn/num_neg_anchors": 251.75, "rpn/num_pos_anchors": 4.25, "time": 1.047927694500686, "total_loss": 0.5931385192088783}
-{"data_time": 0.002312415999767836, "eta_seconds": 201.54887860044255, "fast_rcnn/cls_accuracy": 0.921875, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 299, "loss_box_reg": 0.2783239036798477, "loss_cls": 0.20193222910165787, "loss_rpn_cls": 0.02775962743908167, "loss_rpn_loc": 0.010606387630105019, "lr": 0.0001496005, "roi_head/num_bg_samples": 118.0, "roi_head/num_fg_samples": 10.0, "rpn/num_neg_anchors": 251.75, "rpn/num_pos_anchors": 4.25, "time": 1.1011687664977217, "total_loss": 0.5314042954705656}
-{"data_time": 0.002452332500979537, "eta_seconds": 181.3939907403983, "fast_rcnn/cls_accuracy": 0.91015625, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 319, "loss_box_reg": 0.3467448055744171, "loss_cls": 0.20204617083072662, "loss_rpn_cls": 0.016039039473980665, "loss_rpn_loc": 0.009110166691243649, "lr": 0.0001595905, "roi_head/num_bg_samples": 115.5, "roi_head/num_fg_samples": 12.5, "rpn/num_neg_anchors": 252.0, "rpn/num_pos_anchors": 4.0, "time": 1.0335855844969046, "total_loss": 0.5689474592218176}
-{"data_time": 0.002380849498877069, "eta_seconds": 160.80737951997435, "fast_rcnn/cls_accuracy": 0.923828125, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 339, "loss_box_reg": 0.25983744859695435, "loss_cls": 0.2101910561323166, "loss_rpn_cls": 0.029031481593847275, "loss_rpn_loc": 0.00654958002269268, "lr": 0.00016958050000000002, "roi_head/num_bg_samples": 118.25, "roi_head/num_fg_samples": 9.75, "rpn/num_neg_anchors": 252.0, "rpn/num_pos_anchors": 4.0, "time": 0.9463381784989906, "total_loss": 0.5651442279340699}
-{"data_time": 0.002430993499729084, "eta_seconds": 141.08421502030978, "fast_rcnn/cls_accuracy": 0.92578125, "fast_rcnn/false_negative": 1.0, "fast_rcnn/fg_cls_accuracy": 0.0, "iteration": 359, "loss_box_reg": 0.2631916254758835, "loss_cls": 0.18191325664520264, "loss_rpn_cls": 0.042160166427493095, "loss_rpn_loc": 0.006141096353530884, "lr": 0.0001795705, "roi_head/num_bg_samples": 117.75, "roi_head/num_fg_samples": 10.25, "rpn/num_neg_anchors": 251.0, "rpn/num_pos_anchors": 5.0, "time": 1.0286284529993281, "total_loss": 0.5074426191858947}
-{"data_time": 0.0022974815001362003, "eta_seconds": 120.92932716026553, "fast_rcnn/cls_accuracy": 0.91796875, "fast_rcnn/false_negative": 0.9791666666666667, "fast_rcnn/fg_cls_accuracy": 0.020833333333333332, "iteration": 379, "loss_box_reg": 0.30178171396255493, "loss_cls": 0.1994471549987793, "loss_rpn_cls": 0.01821263786405325, "loss_rpn_loc": 0.0066777062602341175, "lr": 0.0001895605, "roi_head/num_bg_samples": 115.75, "roi_head/num_fg_samples": 12.25, "rpn/num_neg_anchors": 251.75, "rpn/num_pos_anchors": 4.25, "time": 1.042335270502008, "total_loss": 0.5502437175018713}
-{"data_time": 0.002367255001445301, "eta_seconds": 100.27583724986471, "fast_rcnn/cls_accuracy": 0.935546875, "fast_rcnn/false_negative": 0.802801724137931, "fast_rcnn/fg_cls_accuracy": 0.19719827586206895, "iteration": 399, "loss_box_reg": 0.29931333661079407, "loss_cls": 0.1768626868724823, "loss_rpn_cls": 0.030365345999598503, "loss_rpn_loc": 0.005837622098624706, "lr": 0.00019955050000000003, "roi_head/num_bg_samples": 117.25, "roi_head/num_fg_samples": 10.75, "rpn/num_neg_anchors": 252.0, "rpn/num_pos_anchors": 4.0, "time": 0.9460760420006409, "total_loss": 0.5073113315738738}
-{"data_time": 0.0024355290006496944, "eta_seconds": 80.17887107984279, "fast_rcnn/cls_accuracy": 0.916015625, "fast_rcnn/false_negative": 0.9446969696969697, "fast_rcnn/fg_cls_accuracy": 0.055303030303030305, "iteration": 419, "loss_box_reg": 0.3196738511323929, "loss_cls": 0.22123073041439056, "loss_rpn_cls": 0.023836852051317692, "loss_rpn_loc": 0.008727185428142548, "lr": 0.00020954049999999998, "roi_head/num_bg_samples": 115.5, "roi_head/num_fg_samples": 12.5, "rpn/num_neg_anchors": 252.0, "rpn/num_pos_anchors": 4.0, "time": 0.9997415009984252, "total_loss": 0.6064589547459036}
-{"data_time": 0.0025333164994663093, "eta_seconds": 60.41425953004364, "fast_rcnn/cls_accuracy": 0.921875, "fast_rcnn/false_negative": 0.7963800904977376, "fast_rcnn/fg_cls_accuracy": 0.20361990950226244, "iteration": 439, "loss_box_reg": 0.30250634253025055, "loss_cls": 0.1904505342245102, "loss_rpn_cls": 0.016873210202902555, "loss_rpn_loc": 0.006766991224139929, "lr": 0.0002195305, "roi_head/num_bg_samples": 116.0, "roi_head/num_fg_samples": 12.0, "rpn/num_neg_anchors": 251.75, "rpn/num_pos_anchors": 4.25, "time": 1.0880890354983421, "total_loss": 0.5381636922247708}
-{"data_time": 0.0024294495015055872, "eta_seconds": 40.27617302002909, "fast_rcnn/cls_accuracy": 0.91796875, "fast_rcnn/false_negative": 0.7759856630824373, "fast_rcnn/fg_cls_accuracy": 0.22401433691756273, "iteration": 459, "loss_box_reg": 0.304866686463356, "loss_cls": 0.17763881385326385, "loss_rpn_cls": 0.014809648506343365, "loss_rpn_loc": 0.006364703411236405, "lr": 0.00022952050000000002, "roi_head/num_bg_samples": 114.0, "roi_head/num_fg_samples": 14.0, "rpn/num_neg_anchors": 251.0, "rpn/num_pos_anchors": 5.0, "time": 1.0132071085008647, "total_loss": 0.5109291590633802}
-{"data_time": 0.0022333430006256094, "eta_seconds": 20.165542850008933, "fast_rcnn/cls_accuracy": 0.927734375, "fast_rcnn/false_negative": 0.8200000000000001, "fast_rcnn/fg_cls_accuracy": 0.18, "iteration": 479, "loss_box_reg": 0.24445094168186188, "loss_cls": 0.17373357713222504, "loss_rpn_cls": 0.015467526856809855, "loss_rpn_loc": 0.00480739027261734, "lr": 0.0002395105, "roi_head/num_bg_samples": 116.0, "roi_head/num_fg_samples": 12.0, "rpn/num_neg_anchors": 252.5, "rpn/num_pos_anchors": 3.5, "time": 1.0641198180001084, "total_loss": 0.47634494700469077}
-{"data_time": 0.0023894554997241357, "eta_seconds": 0.0, "fast_rcnn/cls_accuracy": 0.931640625, "fast_rcnn/false_negative": 0.8768939393939394, "fast_rcnn/fg_cls_accuracy": 0.12310606060606061, "iteration": 499, "loss_box_reg": 0.2042917013168335, "loss_cls": 0.2030467614531517, "loss_rpn_cls": 0.024149617180228233, "loss_rpn_loc": 0.007974678883329034, "lr": 0.0002495005, "roi_head/num_bg_samples": 117.75, "roi_head/num_fg_samples": 10.25, "rpn/num_neg_anchors": 251.5, "rpn/num_pos_anchors": 4.5, "time": 1.1120363869995344, "total_loss": 0.47657962582889013}
diff --git a/V2/output/test_coco_format.json.lock b/V2/output/test_coco_format.json.lock
deleted file mode 100644
index e69de29..0000000
diff --git a/V2/param-tunning.ipynb b/V2/param-tunning.ipynb
deleted file mode 100644
index d16734b..0000000
--- a/V2/param-tunning.ipynb
+++ /dev/null
@@ -1,479 +0,0 @@
-{
- "cells": [
-  {
-   "cell_type": "code",
-   "execution_count": 1,
-   "id": "05913d59-e9de-41ee-8ef4-ffc288015942",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "import os\n",
-    "import matplotlib.pyplot as plt\n",
-    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
-    "from detectron2.data import build_detection_test_loader\n",
-    "import torch, torchvision\n",
-    "import detectron2\n",
-    "import json\n",
-    "import ast \n",
-    "import tensorboard,os\n",
-    "from detectron2.utils.logger import setup_logger\n",
-    "\n",
-    "setup_logger()\n",
-    "import numpy as np\n",
-    "import pandas as pd\n",
-    "import wandb\n",
-    "import os, json, cv2, random\n",
-    "from detectron2 import model_zoo\n",
-    "from torchmetrics import MeanSquaredError\n",
-    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
-    "from detectron2.config import get_cfg\n",
-    "from detectron2.structures import BoxMode\n",
-    "from tqdm import tqdm\n",
-    "from detectron2.utils.visualizer import Visualizer\n",
-    "from detectron2.data import MetadataCatalog, DatasetCatalog"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 2,
-   "id": "54f77166-567f-4e53-87a4-bebed5fcf8d9",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "files_to_remove = os.listdir('./output/')\n",
-    "files_to_remove.remove('metrics.json')\n",
-    "for file_to_remove in files_to_remove:\n",
-    "    os.remove(f'./output/{file_to_remove}')"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 3,
-   "id": "886fa83a-c439-4554-8d17-777cee97dfdb",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "data = pd.read_csv(\"./Data.csv\").sample(frac=1)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 4,
-   "id": "9f392a7f-893b-4b55-af75-1a5987b1e741",
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "array([[[187, 211, 217],\n",
-       "        [185, 209, 215],\n",
-       "        [185, 209, 215],\n",
-       "        ...,\n",
-       "        [191, 212, 220],\n",
-       "        [194, 215, 223],\n",
-       "        [195, 216, 224]],\n",
-       "\n",
-       "       [[187, 211, 217],\n",
-       "        [186, 210, 216],\n",
-       "        [186, 210, 216],\n",
-       "        ...,\n",
-       "        [196, 215, 223],\n",
-       "        [195, 214, 222],\n",
-       "        [195, 214, 222]],\n",
-       "\n",
-       "       [[190, 212, 218],\n",
-       "        [189, 211, 217],\n",
-       "        [187, 211, 217],\n",
-       "        ...,\n",
-       "        [197, 216, 224],\n",
-       "        [196, 213, 222],\n",
-       "        [197, 214, 223]],\n",
-       "\n",
-       "       ...,\n",
-       "\n",
-       "       [[ 37,  29,  12],\n",
-       "        [ 35,  27,  10],\n",
-       "        [ 36,  28,  11],\n",
-       "        ...,\n",
-       "        [ 65,  41,  17],\n",
-       "        [ 61,  41,  16],\n",
-       "        [ 61,  41,  16]],\n",
-       "\n",
-       "       [[ 39,  29,  12],\n",
-       "        [ 37,  27,  10],\n",
-       "        [ 39,  29,  12],\n",
-       "        ...,\n",
-       "        [ 67,  43,  21],\n",
-       "        [ 61,  40,  18],\n",
-       "        [ 61,  40,  18]],\n",
-       "\n",
-       "       [[ 40,  30,  13],\n",
-       "        [ 38,  28,  11],\n",
-       "        [ 40,  30,  13],\n",
-       "        ...,\n",
-       "        [ 68,  44,  22],\n",
-       "        [ 65,  41,  21],\n",
-       "        [ 63,  42,  21]]], dtype=uint8)"
-      ]
-     },
-     "execution_count": 4,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "info = data.iloc[59]\n",
-    "img = cv2.imread(f'./Img/{info[\"Path\"]}')\n",
-    "height, width = cv2.imread(\"./Img/\" + info[\"Path\"]).shape[:2]\n",
-    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
-    "xmin = round(xmin * width)\n",
-    "xmax = round(xmax * width)\n",
-    "ymin = round(ymin * height)\n",
-    "ymax = round(ymax * height)\n",
-    "x = xmin\n",
-    "y = ymin\n",
-    "w = xmax - xmin\n",
-    "h = ymax - ymin\n",
-    "x,y,w,h = round(x),round(y),round(w),round(h)\n",
-    "cv2.imwrite('./output.png',img)\n",
-    "roi=img[y:y+h,x:x+w]\n",
-    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),10)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 5,
-   "id": "b17e1f90-c8b5-432e-be3a-df122a2fb919",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "# Loading Data\n",
-    "def load_data(data=data, test=False):\n",
-    "    if test is True:\n",
-    "        if \"data.npy\" in os.listdir(\"./\"):\n",
-    "            data = np.load(\"./data.npy\", allow_pickle=True)\n",
-    "            data = data[:325]\n",
-    "            print(len(data))\n",
-    "            return data\n",
-    "    if \"data.npy\" in os.listdir(\"./\"):\n",
-    "        data = np.load(\"./data.npy\", allow_pickle=True)\n",
-    "        print(len(data))\n",
-    "        return data\n",
-    "    new_data = []\n",
-    "    for idx in tqdm(range(len(data))):\n",
-    "        record = {}\n",
-    "        info = data.iloc[idx]\n",
-    "        height, width = cv2.imread(\"./Img/\" + info[\"Path\"]).shape[:2]\n",
-    "        xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
-    "        xmin = round(xmin * width)\n",
-    "        xmax = round(xmax * width)\n",
-    "        ymin = round(ymin * height)\n",
-    "        ymax = round(ymax * height)\n",
-    "        record[\"file_name\"] = \"./Img/\" + info[\"Path\"]\n",
-    "        record[\"height\"] = height\n",
-    "        record[\"width\"] = width\n",
-    "        objs = [\n",
-    "            {\n",
-    "                \"bbox\": [xmin,ymin,xmax,ymax],\n",
-    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
-    "                \"category_id\": 0,\n",
-    "            }\n",
-    "        ]\n",
-    "        record[\"image_id\"] = idx\n",
-    "        record[\"annotations\"] = objs\n",
-    "        new_data.append(record)\n",
-    "    np.random.shuffle(new_data)\n",
-    "    np.save(\"data.npy\", new_data)\n",
-    "    return new_data"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 6,
-   "id": "fb92183d-6ced-44ec-9586-ed3ce8ce9b49",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "# Config\n",
-    "labels = [\"Card\"]"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 7,
-   "id": "de01b6ab-0060-4988-bea8-90145f494d8e",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "# Adding the data\n",
-    "DatasetCatalog.register(\"data\", lambda: load_data())\n",
-    "MetadataCatalog.get(\"data\").set(thing_classes=labels)\n",
-    "metadata = MetadataCatalog.get(\"data\")\n",
-    "DatasetCatalog.register(\"test\", lambda: load_data(test=True))\n",
-    "MetadataCatalog.get(\"test\").set(thing_classes=labels)\n",
-    "metadata_test = MetadataCatalog.get(\"test\")"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 8,
-   "id": "c6fa0905-7359-47bb-82d1-7e46e01e98f8",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "models = [\n",
-    "    \"fast_rcnn_R_50_FPN_1x.yaml\",\n",
-    "    \"faster_rcnn_R_50_C4_1x.yaml\",\n",
-    "    \"faster_rcnn_R_50_C4_3x.yaml\",\n",
-    "    \"faster_rcnn_R_50_DC5_1x.yaml\",\n",
-    "    \"faster_rcnn_R_50_DC5_3x.yaml\",\n",
-    "    \"retinanet_R_50_FPN_1x.py\",\n",
-    "    \"retinanet_R_50_FPN_1x.yaml\",\n",
-    "    \"retinanet_R_50_FPN_3x.yaml\",\n",
-    "    \"rpn_R_50_C4_1x.yaml\",\n",
-    "    \"rpn_R_50_FPN_1x.yaml\"\n",
-    "    \"faster_rcnn_R_50_FPN_1x.yaml\",\n",
-    "    \"faster_rcnn_R_50_FPN_3x.yaml\",\n",
-    "    \"faster_rcnn_R_101_DC5_3x.yaml\",\n",
-    "    \"faster_rcnn_R_101_FPN_3x.yaml\",\n",
-    "    \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
-    "]\n",
-    "max_iters = [\n",
-    "    50,100,125,250,500,1000,2000,2500,5000\n",
-    "]\n",
-    "base_lrs = [\n",
-    "    0.1,0.01,0.001,0.0001,0.00001,0.000001\n",
-    "]\n",
-    "ims_per_batchs = [\n",
-    "    1,2,3,4,5,6,7,8,9,10\n",
-    "]\n",
-    "batch_size_per_images = [\n",
-    "    8,16,32,64,128,256,512\n",
-    "]"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 9,
-   "id": "ce211722-cd2a-4392-a22d-e769ae8c5a40",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "BASE_LR = 0.00025\n",
-    "MAX_ITER = 500\n",
-    "EVAL_PERIOD = 500\n",
-    "IMS_PER_BATCH = 2\n",
-    "BATCH_SIZE_PER_IMAGE = 128\n",
-    "SCORE_THRESH_TEST = 0.625\n",
-    "model = f\"COCO-Detection/\" + \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\""
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 10,
-   "id": "93b60993-b010-4f8b-a9cc-ce7ff377dcb2",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "NAME = \"test\""
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "ee9430a7-604e-405e-a456-f0b4efc91a96",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "#### files_to_remove = os.listdir(\"./output/\")\n",
-    "for file_to_remove in files_to_remove:\n",
-    "    os.remove(f\"./output/{file_to_remove}\")\n",
-    "from detectron2.utils.logger import setup_logger\n",
-    "setup_logger()\n",
-    "torch.cuda.empty_cache()\n",
-    "wandb.init(entity='find-card',project=\"Find-Card\", name=NAME,config={\n",
-    "    'BASE_LR':BASE_LR,\n",
-    "    'MAX_ITER':MAX_ITER,\n",
-    "    'EVAL_PERIOD':EVAL_PERIOD,\n",
-    "    'IMS_PER_BATCH':IMS_PER_BATCH,\n",
-    "    'BATCH_SIZE_PER_IMAGE':BATCH_SIZE_PER_IMAGE,\n",
-    "    'SCORE_THRESH_TEST':SCORE_THRESH_TEST,\n",
-    "    'MODEL':model,\n",
-    "    'NAME':NAME\n",
-    "})\n",
-    "torch.cuda.empty_cache()\n",
-    "cfg = get_cfg()\n",
-    "torch.cuda.empty_cache()\n",
-    "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
-    "torch.cuda.empty_cache()\n",
-    "cfg.DATASETS.TRAIN = (\"data\",)\n",
-    "torch.cuda.empty_cache()\n",
-    "cfg.DATASETS.TEST = ()\n",
-    "torch.cuda.empty_cache()\n",
-    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
-    "torch.cuda.empty_cache()\n",
-    "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
-    "torch.cuda.empty_cache()\n",
-    "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
-    "cfg.SOLVER.BASE_LR = BASE_LR\n",
-    "torch.cuda.empty_cache()\n",
-    "cfg.SOLVER.STEPS = []\n",
-    "torch.cuda.empty_cache()\n",
-    "cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH\n",
-    "torch.cuda.empty_cache()\n",
-    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
-    "torch.cuda.empty_cache()\n",
-    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = BATCH_SIZE_PER_IMAGE\n",
-    "torch.cuda.empty_cache()\n",
-    "trainer = DefaultTrainer(cfg)\n",
-    "torch.cuda.empty_cache()\n",
-    "trainer.resume_or_load(resume=False)\n",
-    "torch.cuda.empty_cache()\n",
-    "trainer.train()\n",
-    "torch.cuda.empty_cache()\n",
-    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
-    "torch.cuda.empty_cache()\n",
-    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
-    "torch.cuda.empty_cache()\n",
-    "predictor = DefaultPredictor(cfg)\n",
-    "torch.cuda.empty_cache()\n",
-    "cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"\n",
-    "cfg.SOLVER.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
-    "predictor = DefaultPredictor(cfg)\n",
-    "evaluator = COCOEvaluator(\"test\", output_dir=\"./output/\")\n",
-    "val_loader = build_detection_test_loader(cfg, \"test\")\n",
-    "metrics = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
-    "wandb.log(metrics)\n",
-    "torch.cuda.empty_cache()\n",
-    "logs = open(\"./output/metrics.json\", \"r\").read().split(\"\\n\")\n",
-    "for log in tqdm(range(len(logs))):\n",
-    "    try:\n",
-    "        res = ast.literal_eval(logs[log])\n",
-    "        wandb.log(res)\n",
-    "    except:\n",
-    "        pass\n",
-    "for img in os.listdir(\"./test_imgs/\"):\n",
-    "    torch.cuda.empty_cache()\n",
-    "    v = Visualizer(cv2.imread(f\"./test_imgs/{img}\")[:, :, ::-1], metadata=metadata)\n",
-    "    torch.cuda.empty_cache()\n",
-    "    v = v.draw_instance_predictions(\n",
-    "        predictor(cv2.imread(f\"./test_imgs/{img}\"))[\"instances\"].to(\"cpu\")\n",
-    "    )\n",
-    "    torch.cuda.empty_cache()\n",
-    "    v = v.get_image()[:, :, ::-1]\n",
-    "    torch.cuda.empty_cache()\n",
-    "    plt.figure(figsize=(24, 12))\n",
-    "    torch.cuda.empty_cache()\n",
-    "    plt.imshow(v)\n",
-    "    torch.cuda.empty_cache()\n",
-    "    plt.savefig(f\"./preds/{img}\")\n",
-    "    torch.cuda.empty_cache()\n",
-    "    plt.close()\n",
-    "    torch.cuda.empty_cache()\n",
-    "    wandb.log({f\"Img/{img}\": wandb.Image(cv2.imread(f\"./preds/{img}\"))})\n",
-    "info = data.iloc[589]\n",
-    "img = cv2.imread(\"./download/Img/\" + info[\"Path\"])\n",
-    "height, width = cv2.imread(\"./download/Img/\" + info[\"Path\"]).shape[:2]\n",
-    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
-    "xmin = round(xmin * width)\n",
-    "xmax = round(xmax * width)\n",
-    "ymin = round(ymin * height)\n",
-    "ymax = round(ymax * height)\n",
-    "x = xmin\n",
-    "y = ymin\n",
-    "w = xmax - xmin\n",
-    "h = ymax - ymin\n",
-    "preds = predictor(img)\n",
-    "target = torch.tensor([xmin, ymin, xmax, ymax])\n",
-    "lowest_rmse = 0\n",
-    "r_mean_squared_error = MeanSquaredError(squared=False)\n",
-    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
-    "for pred_i in range(len(preds)):\n",
-    "    pred = preds_new[pred_i]\n",
-    "    if r_mean_squared_error(pred.to(\"cpu\"), target) > lowest_rmse:\n",
-    "        lowest_rmse = r_mean_squared_error(pred.to(\"cpu\"), target)\n",
-    "lowest_mse = 0\n",
-    "mean_squared_error = MeanSquaredError(squared=True)\n",
-    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
-    "for pred_i in range(len(preds)):\n",
-    "    pred = preds_new[pred_i]\n",
-    "    if mean_squared_error(pred.to(\"cpu\"), target) > lowest_mse:\n",
-    "        lowest_mse = mean_squared_error(pred.to(\"cpu\"), target)\n",
-    "wandb.log({\"MSE\": lowest_mse})\n",
-    "wandb.log({\"RMSE\": lowest_rmse})\n",
-    "wandb.finish()"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 12,
-   "id": "95809b5d-b53f-4d51-8248-5106c8c3ba19",
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "'625.png'"
-      ]
-     },
-     "execution_count": 12,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "info['Path']"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "7c24e0a3-96fa-424f-9741-a188f5f96532",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "torch.save(cfg,f'./models/cfg-{NAME}.pt')\n",
-    "torch.save(cfg,f'./models/cfg-{NAME}.pth')\n",
-    "torch.save(predictor,f'./models/predictor-{NAME}.pt')\n",
-    "torch.save(predictor,f'./models/predictor-{NAME}.pth')\n",
-    "torch.save(evaluator,f'./models/evaluator-{NAME}.pt')\n",
-    "torch.save(evaluator,f'./models/evaluator-{NAME}.pth')\n",
-    "torch.save(model,f'./models/model-{NAME}.pt')\n",
-    "torch.save(model,f'./models/model-{NAME}.pth')\n",
-    "torch.save(labels,f'./models/labels-{NAME}.pt')\n",
-    "torch.save(labels,f'./models/labels-{NAME}.pth')\n",
-    "torch.save(metrics,f'./models/metrics-{NAME}.pt')\n",
-    "torch.save(metrics,f'./models/metrics-{NAME}.pth')"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "cd76b61b-ac9c-418f-8462-6b1deee60162",
-   "metadata": {},
-   "outputs": [],
-   "source": []
-  }
- ],
- "metadata": {
-  "kernelspec": {
-   "display_name": "Python 3.8.12 64-bit ('detectron2': conda)",
-   "language": "python",
-   "name": "python3812jvsc74a57bd0585e9a5027b519a27e411109b09a66bc779a1bba36bd86b08fdb64645f8a2c5a"
-  },
-  "language_info": {
-   "codemirror_mode": {
-    "name": "ipython",
-    "version": 3
-   },
-   "file_extension": ".py",
-   "mimetype": "text/x-python",
-   "name": "python",
-   "nbconvert_exporter": "python",
-   "pygments_lexer": "ipython3",
-   "version": "3.8.12"
-  }
- },
- "nbformat": 4,
- "nbformat_minor": 5
-}
diff --git a/V2/param-tunning.py b/V2/param-tunning.py
deleted file mode 100644
index 0c10528..0000000
--- a/V2/param-tunning.py
+++ /dev/null
@@ -1,268 +0,0 @@
-import random
-import cv2
-from detectron2.data import MetadataCatalog, DatasetCatalog
-from detectron2.utils.visualizer import Visualizer
-from tqdm import tqdm
-from detectron2.structures import BoxMode
-from detectron2.config import get_cfg
-from detectron2.engine import DefaultPredictor, DefaultTrainer
-from torchmetrics import MeanSquaredError
-from detectron2 import model_zoo
-import wandb
-import pandas as pd
-import numpy as np
-import os
-import matplotlib.pyplot as plt
-from detectron2.evaluation import COCOEvaluator, inference_on_dataset
-from detectron2.data import build_detection_test_loader
-import torch
-import torchvision
-import detectron2
-import json
-import ast
-import tensorboard
-import os
-from detectron2.utils.logger import setup_logger
-
-setup_logger()
-files_to_remove = os.listdir('./output/')
-files_to_remove.remove('metrics.json')
-for file_to_remove in files_to_remove:
-    os.remove(f'./output/{file_to_remove}')
-data = pd.read_csv("./Data.csv").sample(frac=1)
-info = data.iloc[59]
-img = cv2.imread(f'./Img/{info["Path"]}')
-height, width = cv2.imread("./Img/" + info["Path"]).shape[:2]
-xmin, ymin, xmax, ymax = info["XMin"], info["YMin"], info["XMax"], info["YMax"]
-xmin = round(xmin * width)
-xmax = round(xmax * width)
-ymin = round(ymin * height)
-ymax = round(ymax * height)
-x = xmin
-y = ymin
-w = xmax - xmin
-h = ymax - ymin
-x, y, w, h = round(x), round(y), round(w), round(h)
-cv2.imwrite('./output.png', img)
-roi = img[y:y+h, x:x+w]
-cv2.rectangle(img, (x, y), (x+w, y+h), (200, 0, 0), 10)
-# Loading Data
-
-
-def load_data(data=data, test=False):
-    if test is True:
-        if "data.npy" in os.listdir("./"):
-            data = np.load("./data.npy", allow_pickle=True)
-            data = data[:325]
-            print(len(data))
-            return data
-    if "data.npy" in os.listdir("./"):
-        data = np.load("./data.npy", allow_pickle=True)
-        print(len(data))
-        return data
-    new_data = []
-    for idx in tqdm(range(len(data))):
-        record = {}
-        info = data.iloc[idx]
-        height, width = cv2.imread("./Img/" + info["Path"]).shape[:2]
-        xmin, ymin, xmax, ymax = info["XMin"], info["YMin"], info["XMax"], info["YMax"]
-        xmin = round(xmin * width)
-        xmax = round(xmax * width)
-        ymin = round(ymin * height)
-        ymax = round(ymax * height)
-        record["file_name"] = "./Img/" + info["Path"]
-        record["height"] = height
-        record["width"] = width
-        objs = [
-            {
-                "bbox": [xmin, ymin, xmax, ymax],
-                "bbox_mode": BoxMode.XYXY_ABS,
-                "category_id": 0,
-            }
-        ]
-        record["image_id"] = idx
-        record["annotations"] = objs
-        new_data.append(record)
-    np.random.shuffle(new_data)
-    np.save("data.npy", new_data)
-    return new_data
-
-
-# Config
-labels = ["Card"]
-# Adding the data
-DatasetCatalog.register("data", lambda: load_data())
-MetadataCatalog.get("data").set(thing_classes=labels)
-metadata = MetadataCatalog.get("data")
-DatasetCatalog.register("test", lambda: load_data(test=True))
-MetadataCatalog.get("test").set(thing_classes=labels)
-metadata_test = MetadataCatalog.get("test")
-
-models = [
-    "fast_rcnn_R_50_FPN_1x.yaml",
-    "faster_rcnn_R_50_C4_1x.yaml",
-    "faster_rcnn_R_50_C4_3x.yaml",
-    "faster_rcnn_R_50_DC5_1x.yaml",
-    "faster_rcnn_R_50_DC5_3x.yaml",
-    "retinanet_R_50_FPN_1x.py",
-    "retinanet_R_50_FPN_1x.yaml",
-    "retinanet_R_50_FPN_3x.yaml",
-    "rpn_R_50_C4_1x.yaml",
-    "rpn_R_50_FPN_1x.yaml"
-    "faster_rcnn_R_50_FPN_1x.yaml",
-    "faster_rcnn_R_50_FPN_3x.yaml",
-    "faster_rcnn_R_101_DC5_3x.yaml",
-    "faster_rcnn_R_101_FPN_3x.yaml",
-    "faster_rcnn_X_101_32x8d_FPN_3x.yaml",
-]
-max_iters = [
-    50, 100, 125, 250, 500, 1000, 2000, 2500, 5000
-]
-base_lrs = [
-    0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001
-]
-ims_per_batchs = [
-    1, 2, 3, 4, 5, 6, 7, 8, 9, 10
-]
-batch_size_per_images = [
-    8, 16, 32, 64, 128, 256, 512
-]
-BASE_LR = 0.00025
-MAX_ITER = 500
-EVAL_PERIOD = 500
-IMS_PER_BATCH = 2
-BATCH_SIZE_PER_IMAGE = 128
-SCORE_THRESH_TEST = 0.625
-model = f"COCO-Detection/" + "faster_rcnn_X_101_32x8d_FPN_3x.yaml"
-NAME = "baseline"
-#### files_to_remove = os.listdir("./output/")
-for file_to_remove in files_to_remove:
-    os.remove(f"./output/{file_to_remove}")
-setup_logger()
-torch.cuda.empty_cache()
-wandb.init(entity='find-card', project="Find-Card", name=NAME, config={
-    'BASE_LR': BASE_LR,
-    'MAX_ITER': MAX_ITER,
-    'EVAL_PERIOD': EVAL_PERIOD,
-    'IMS_PER_BATCH': IMS_PER_BATCH,
-    'BATCH_SIZE_PER_IMAGE': BATCH_SIZE_PER_IMAGE,
-    'SCORE_THRESH_TEST': SCORE_THRESH_TEST,
-    'MODEL': model,
-    'NAME': NAME
-})
-torch.cuda.empty_cache()
-cfg = get_cfg()
-torch.cuda.empty_cache()
-cfg.merge_from_file(model_zoo.get_config_file(model))
-torch.cuda.empty_cache()
-cfg.DATASETS.TRAIN = ("data",)
-torch.cuda.empty_cache()
-cfg.DATASETS.TEST = ()
-torch.cuda.empty_cache()
-cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)
-torch.cuda.empty_cache()
-cfg.SOLVER.MAX_ITER = MAX_ITER
-torch.cuda.empty_cache()
-cfg.TEST.EVAL_PERIOD = EVAL_PERIOD
-cfg.SOLVER.BASE_LR = BASE_LR
-torch.cuda.empty_cache()
-cfg.SOLVER.STEPS = []
-torch.cuda.empty_cache()
-cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH
-torch.cuda.empty_cache()
-cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)
-torch.cuda.empty_cache()
-cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = BATCH_SIZE_PER_IMAGE
-torch.cuda.empty_cache()
-trainer = DefaultTrainer(cfg)
-torch.cuda.empty_cache()
-trainer.resume_or_load(resume=False)
-torch.cuda.empty_cache()
-trainer.train()
-torch.cuda.empty_cache()
-cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = SCORE_THRESH_TEST
-torch.cuda.empty_cache()
-cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
-torch.cuda.empty_cache()
-predictor = DefaultPredictor(cfg)
-torch.cuda.empty_cache()
-cfg.MODEL.WEIGHTS = "./output/model_final.pth"
-cfg.SOLVER.SCORE_THRESH_TEST = SCORE_THRESH_TEST
-predictor = DefaultPredictor(cfg)
-evaluator = COCOEvaluator("test", output_dir="./output/")
-val_loader = build_detection_test_loader(cfg, "test")
-metrics = inference_on_dataset(predictor.model, val_loader, evaluator)
-wandb.log(metrics)
-torch.cuda.empty_cache()
-logs = open("./output/metrics.json", "r").read().split("\n")
-for log in tqdm(range(len(logs))):
-    try:
-        res = ast.literal_eval(logs[log])
-        wandb.log(res)
-    except:
-        pass
-for img in os.listdir("./test_imgs/"):
-    torch.cuda.empty_cache()
-    v = Visualizer(cv2.imread(
-        f"./test_imgs/{img}")[:, :, ::-1], metadata=metadata)
-    torch.cuda.empty_cache()
-    v = v.draw_instance_predictions(
-        predictor(cv2.imread(f"./test_imgs/{img}"))["instances"].to("cpu")
-    )
-    torch.cuda.empty_cache()
-    v = v.get_image()[:, :, ::-1]
-    torch.cuda.empty_cache()
-    plt.figure(figsize=(24, 12))
-    torch.cuda.empty_cache()
-    plt.imshow(v)
-    torch.cuda.empty_cache()
-    plt.savefig(f"./preds/{img}")
-    torch.cuda.empty_cache()
-    plt.close()
-    torch.cuda.empty_cache()
-    wandb.log({f"Img/{img}": wandb.Image(cv2.imread(f"./preds/{img}"))})
-info = data.iloc[589]
-img = cv2.imread("./download/Img/" + info["Path"])
-height, width = cv2.imread("./download/Img/" + info["Path"]).shape[:2]
-xmin, ymin, xmax, ymax = info["XMin"], info["YMin"], info["XMax"], info["YMax"]
-xmin = round(xmin * width)
-xmax = round(xmax * width)
-ymin = round(ymin * height)
-ymax = round(ymax * height)
-x = xmin
-y = ymin
-w = xmax - xmin
-h = ymax - ymin
-preds = predictor(img)
-target = torch.tensor([xmin, ymin, xmax, ymax])
-lowest_rmse = 0
-r_mean_squared_error = MeanSquaredError(squared=False)
-preds_new = preds["instances"].__dict__[
-    "_fields"]["pred_boxes"].__dict__["tensor"]
-for pred_i in range(len(preds)):
-    pred = preds_new[pred_i]
-    if r_mean_squared_error(pred.to("cpu"), target) > lowest_rmse:
-        lowest_rmse = r_mean_squared_error(pred.to("cpu"), target)
-lowest_mse = 0
-mean_squared_error = MeanSquaredError(squared=True)
-preds_new = preds["instances"].__dict__[
-    "_fields"]["pred_boxes"].__dict__["tensor"]
-for pred_i in range(len(preds)):
-    pred = preds_new[pred_i]
-    if mean_squared_error(pred.to("cpu"), target) > lowest_mse:
-        lowest_mse = mean_squared_error(pred.to("cpu"), target)
-wandb.log({"MSE": lowest_mse})
-wandb.log({"RMSE": lowest_rmse})
-wandb.finish()
-torch.save(cfg, f'./models/cfg-{NAME}.pt')
-torch.save(cfg, f'./models/cfg-{NAME}.pth')
-torch.save(predictor, f'./models/predictor-{NAME}.pt')
-torch.save(predictor, f'./models/predictor-{NAME}.pth')
-torch.save(evaluator, f'./models/evaluator-{NAME}.pt')
-torch.save(evaluator, f'./models/evaluator-{NAME}.pth')
-torch.save(model, f'./models/model-{NAME}.pt')
-torch.save(model, f'./models/model-{NAME}.pth')
-torch.save(labels, f'./models/labels-{NAME}.pt')
-torch.save(labels, f'./models/labels-{NAME}.pth')
-torch.save(metrics, f'./models/metrics-{NAME}.pt')
-torch.save(metrics, f'./models/metrics-{NAME}.pth')
diff --git a/V2/wandb/latest-run b/V2/wandb/latest-run
index 611a059..13d1a20 120000
--- a/V2/wandb/latest-run
+++ b/V2/wandb/latest-run
@@ -1 +1 @@
-run-20211028_204457-3r95n0qd
\ No newline at end of file
+run-20211028_234202-buxdgrrs
\ No newline at end of file
