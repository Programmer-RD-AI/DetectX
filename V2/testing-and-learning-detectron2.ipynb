{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b4a3d4-b21c-4992-a1ba-5f085a8ecc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73c36019-a19d-462e-83aa-c1879a508677",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_remove = os.listdir('./output/')\n",
    "files_to_remove.remove('metrics.json')\n",
    "for file_to_remove in files_to_remove:\n",
    "    os.remove(f'./output/{file_to_remove}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50fb87ec-3b47-4d9b-a9af-896f38c50577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "import torch, torchvision\n",
    "import detectron2\n",
    "import json\n",
    "import ast \n",
    "import tensorboard,os\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from tqdm import tqdm\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d870d2-7a17-4aa7-bfa3-5b1dfd09477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version\n",
    "data = pd.read_csv(\"./Data.csv\").sample(frac=1)\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d30532e-3cfa-4437-afcb-1c2f8a2b6d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>XMin</th>\n",
       "      <th>YMin</th>\n",
       "      <th>XMax</th>\n",
       "      <th>YMax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>4437.png</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>0.704971</td>\n",
       "      <td>0.528750</td>\n",
       "      <td>0.845966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>2336.png</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.171958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>4153.png</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>0.334375</td>\n",
       "      <td>0.224167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154</th>\n",
       "      <td>5620.png</td>\n",
       "      <td>0.208750</td>\n",
       "      <td>0.887041</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.967429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>4718.png</td>\n",
       "      <td>0.093809</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.182927</td>\n",
       "      <td>0.870625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4656</th>\n",
       "      <td>5109.png</td>\n",
       "      <td>0.311250</td>\n",
       "      <td>0.417195</td>\n",
       "      <td>0.381875</td>\n",
       "      <td>0.676923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>610.png</td>\n",
       "      <td>0.257238</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.351893</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>2759.png</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.206379</td>\n",
       "      <td>0.666875</td>\n",
       "      <td>0.409006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>4379.png</td>\n",
       "      <td>0.620625</td>\n",
       "      <td>0.169519</td>\n",
       "      <td>0.668125</td>\n",
       "      <td>0.303993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531</th>\n",
       "      <td>6012.png</td>\n",
       "      <td>0.560625</td>\n",
       "      <td>0.481667</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.759167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5766 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Path      XMin      YMin      XMax      YMax\n",
       "4015  4437.png  0.490625  0.704971  0.528750  0.845966\n",
       "2093  2336.png  0.922500  0.009700  0.999375  0.171958\n",
       "3742  4153.png  0.315000  0.195000  0.334375  0.224167\n",
       "5154  5620.png  0.208750  0.887041  0.280000  0.967429\n",
       "4281  4718.png  0.093809  0.845000  0.182927  0.870625\n",
       "...        ...       ...       ...       ...       ...\n",
       "4656  5109.png  0.311250  0.417195  0.381875  0.676923\n",
       "562    610.png  0.257238  0.005000  0.351893  0.075000\n",
       "2494  2759.png  0.405000  0.206379  0.666875  0.409006\n",
       "3957  4379.png  0.620625  0.169519  0.668125  0.303993\n",
       "5531  6012.png  0.560625  0.481667  0.635000  0.759167\n",
       "\n",
       "[5766 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c99c7a-bd83-42c3-a118-2488cb3ee20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['XMin'] = data['XMin']*255\n",
    "# data['YMin'] = data['YMin']*255\n",
    "# data['XMax'] = data['XMax']*255\n",
    "# data['YMax'] = data['YMax']*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "804034a1-aba5-40e2-8bf1-1a21b26c74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(len(data))):\n",
    "#     info = data.iloc[i]\n",
    "# #     ymin,xmin,ymax,xmax = info['XMin'],info['YMin'],info['XMax'],info['YMax']\n",
    "#     height,width = cv2.imread(f'./Img/{info[\"Path\"]}').shape[:2]\n",
    "#     xmin,ymin,xmax,ymax = info['XMin'],info['YMin'],info['XMax'],info['YMax']\n",
    "# #     print(xmin,ymin,xmax,ymax)\n",
    "#     xmin = round(xmin * width)\n",
    "#     xmax = round(xmax * width)\n",
    "#     ymin = round(ymin * height)\n",
    "#     ymax = round(ymax * height)\n",
    "#     x = xmin\n",
    "#     y = ymin\n",
    "#     w = xmax - xmin\n",
    "#     h = ymax - ymin\n",
    "# #     x,y,w,h = x*255,y*255,w*255,h*255\n",
    "#     x,y,w,h = round(x),round(y),round(w),round(h)\n",
    "# #     print(x,y,w,h,xmin,xmax,ymin,ymax,height,width)\n",
    "#     img = cv2.imread(f'./Img/{info[\"Path\"]}')\n",
    "#     cv2.imwrite('./output.png',img)\n",
    "#     roi=img[y:y+h,x:x+w]\n",
    "#     cv2.imwrite(str('crop') + '.jpg', roi)\n",
    "#     cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),10)\n",
    "#     cv2.imwrite(str('box') + '.jpg', img)\n",
    "#     plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7e3d108-f67c-4eba-9bf3-efdbee7deaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = data.iloc[50]\n",
    "# xmin,ymin,xmax,ymax = info['XMin']*im[0],info['YMin']*im[1],info['XMax']*im[0],info['YMax']*im[1]\n",
    "xmin,ymin,xmax,ymax = info['XMin']*255,info['YMin']*255,info['XMax']*255,info['YMax']*255\n",
    "# xmin,ymin,xmax,ymax = info['XMin'],info['YMin'],info['XMax'],info['YMax']\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "# x,y,w,h = x*255,y*255,w*255,h*255\n",
    "# x,y,w,h = x*255,y*255,w*255,h*255\n",
    "x,y,w,h = round(x),round(y),round(w),round(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d2b8d4d-820e-4127-b246-f791f063d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "def load_data(data=data, test=False):\n",
    "    if test is True:\n",
    "        if \"data.npy\" in os.listdir(\"./\"):\n",
    "            data = np.load(\"./data.npy\", allow_pickle=True)\n",
    "            data = data[:325]\n",
    "            print(len(data))\n",
    "            return data\n",
    "    if \"data.npy\" in os.listdir(\"./\"):\n",
    "        data = np.load(\"./data.npy\", allow_pickle=True)\n",
    "        print(len(data))\n",
    "        return data\n",
    "    new_data = []\n",
    "    for idx in tqdm(range(len(data))):\n",
    "        record = {}\n",
    "        info = data.iloc[idx]\n",
    "        height, width = cv2.imread(\"./Img/\" + info[\"Path\"]).shape[:2]\n",
    "        xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "        xmin = round(xmin * width)\n",
    "        xmax = round(xmax * width)\n",
    "        ymin = round(ymin * height)\n",
    "        ymax = round(ymax * height)\n",
    "        record[\"file_name\"] = \"./Img/\" + info[\"Path\"]\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        record[\"cateogry_id\"] = 1\n",
    "        objs = [\n",
    "            {\n",
    "                \"bbox\": [xmin,ymin,xmax,ymax],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"category_id\": 1,\n",
    "            }\n",
    "        ]\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"annotations\"] = objs\n",
    "        new_data.append(record)\n",
    "    np.random.shuffle(new_data)\n",
    "    np.save(\"data.npy\", new_data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc33c998-6463-4b59-9abd-9c99693f6b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "labels = [\"Card\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93234b89-0bb9-4153-83e0-da231b28a22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the data\n",
    "DatasetCatalog.register(\"data\", lambda: load_data())\n",
    "MetadataCatalog.get(\"data\").set(thing_classes=labels)\n",
    "metadata = MetadataCatalog.get(\"data\")\n",
    "DatasetCatalog.register(\"test\", lambda: load_data(test=True))\n",
    "MetadataCatalog.get(\"test\").set(thing_classes=labels)\n",
    "metadata_test = MetadataCatalog.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17853a58-221a-47a8-9370-1792032b38b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-17 14:53:09.750569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mranuga-d\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20211017_145312-2uutsu76\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/ranuga-d/Find-Card\" target=\"_blank\">https://app.wandb.ai/ranuga-d/Find-Card</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/ranuga-d/Find-Card/runs/2uutsu76\" target=\"_blank\">https://app.wandb.ai/ranuga-d/Find-Card/runs/2uutsu76</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config /home/indika/anaconda3/envs/myenv/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m[10/17 14:53:26 d2.engine.defaults]: \u001b[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n",
      "5766\n",
      "\u001b[32m[10/17 14:53:26 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5766 images left.\n",
      "\u001b[32m[10/17 14:53:26 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    Card    | 5766         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/17 14:53:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[10/17 14:53:26 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/17 14:53:26 d2.data.common]: \u001b[0mSerializing 5766 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/17 14:53:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.19 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n",
      "  \u001b[35manchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/17 14:53:27 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/envs/myenv/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/17 14:53:45 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 19  total_loss: 1.725  loss_cls: 1.338  loss_box_reg: 0.2968  time: 0.8910  data_time: 0.0306  lr: 4.7703e-05  max_mem: 5424M\n",
      "\u001b[32m[10/17 14:53:55 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 39  total_loss: 1.444  loss_cls: 1.172  loss_box_reg: 0.3934  time: 0.6875  data_time: 0.0023  lr: 9.7653e-05  max_mem: 5424M\n",
      "\u001b[32m[10/17 14:54:05 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 59  total_loss: 0.9723  loss_cls: 0.6755  loss_box_reg: 0.3074  time: 0.6123  data_time: 0.0118  lr: 0.0001476  max_mem: 5424M\n",
      "\u001b[32m[10/17 14:54:14 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 79  total_loss: 1.131  loss_cls: 0.7394  loss_box_reg: 0.404  time: 0.5737  data_time: 0.0089  lr: 0.00019755  max_mem: 5424M\n",
      "\u001b[32m[10/17 14:54:23 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 99  total_loss: 0.8986  loss_cls: 0.5954  loss_box_reg: 0.2946  time: 0.5463  data_time: 0.0038  lr: 0.0002475  max_mem: 5424M\n",
      "\u001b[32m[10/17 14:54:23 d2.engine.hooks]: \u001b[0mOverall training speed: 98 iterations in 0:00:53 (0.5463 s / it)\n",
      "\u001b[32m[10/17 14:54:23 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:53 (0:00:00 on hooks)\n",
      "\u001b[32m[10/17 14:54:24 d2.evaluation.coco_evaluation]: \u001b[0m'test' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
      "\u001b[32m[10/17 14:54:24 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'test' to COCO format ...)\n",
      "325\n",
      "\u001b[32m[10/17 14:54:24 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[10/17 14:54:24 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 325, #annotations: 325\n",
      "\u001b[32m[10/17 14:54:24 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/test_coco_format.json' ...\n",
      "325\n",
      "\u001b[32m[10/17 14:54:24 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    Card    | 325          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/17 14:54:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/17 14:54:24 d2.data.common]: \u001b[0mSerializing 325 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/17 14:54:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/17 14:54:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 325 batches\n",
      "\u001b[32m[10/17 14:54:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/325. Dataloading: 0.0004 s/iter. Inference: 0.1057 s/iter. Eval: 0.0002 s/iter. Total: 0.1063 s/iter. ETA=0:00:33\n",
      "\u001b[32m[10/17 14:54:31 d2.evaluation.evaluator]: \u001b[0mInference done 52/325. Dataloading: 0.0133 s/iter. Inference: 0.1065 s/iter. Eval: 0.0002 s/iter. Total: 0.1201 s/iter. ETA=0:00:32\n",
      "\u001b[32m[10/17 14:54:36 d2.evaluation.evaluator]: \u001b[0mInference done 95/325. Dataloading: 0.0121 s/iter. Inference: 0.1063 s/iter. Eval: 0.0002 s/iter. Total: 0.1186 s/iter. ETA=0:00:27\n",
      "\u001b[32m[10/17 14:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 138/325. Dataloading: 0.0124 s/iter. Inference: 0.1057 s/iter. Eval: 0.0002 s/iter. Total: 0.1184 s/iter. ETA=0:00:22\n",
      "\u001b[32m[10/17 14:54:47 d2.evaluation.evaluator]: \u001b[0mInference done 186/325. Dataloading: 0.0095 s/iter. Inference: 0.1053 s/iter. Eval: 0.0002 s/iter. Total: 0.1150 s/iter. ETA=0:00:15\n",
      "\u001b[32m[10/17 14:54:52 d2.evaluation.evaluator]: \u001b[0mInference done 230/325. Dataloading: 0.0091 s/iter. Inference: 0.1055 s/iter. Eval: 0.0002 s/iter. Total: 0.1148 s/iter. ETA=0:00:10\n",
      "\u001b[32m[10/17 14:54:57 d2.evaluation.evaluator]: \u001b[0mInference done 273/325. Dataloading: 0.0089 s/iter. Inference: 0.1062 s/iter. Eval: 0.0002 s/iter. Total: 0.1154 s/iter. ETA=0:00:05\n",
      "\u001b[32m[10/17 14:55:02 d2.evaluation.evaluator]: \u001b[0mInference done 312/325. Dataloading: 0.0095 s/iter. Inference: 0.1073 s/iter. Eval: 0.0002 s/iter. Total: 0.1172 s/iter. ETA=0:00:01\n",
      "\u001b[32m[10/17 14:55:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.004774 (0.118765 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/17 14:55:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:34 (0.108225 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/17 14:55:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/17 14:55:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[10/17 14:55:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/17 14:55:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/17 14:55:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.13 seconds.\n",
      "\u001b[32m[10/17 14:55:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/17 14:55:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.038\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.278\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n",
      "\u001b[32m[10/17 14:55:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 4.618 | 9.011  | 3.776  | 0.147 | 2.265 | 5.718 |\n",
      "\u001b[32m[10/17 14:55:04 d2.evaluation.coco_evaluation]: \u001b[0m'data' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
      "\u001b[32m[10/17 14:55:04 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'data' to COCO format ...)\n",
      "5766\n",
      "\u001b[32m[10/17 14:55:04 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[10/17 14:55:05 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 5766, #annotations: 5766\n",
      "\u001b[32m[10/17 14:55:05 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/data_coco_format.json' ...\n",
      "5766\n",
      "\u001b[32m[10/17 14:55:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/17 14:55:05 d2.data.common]: \u001b[0mSerializing 5766 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/17 14:55:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.19 MiB\n",
      "\u001b[32m[10/17 14:55:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 5766 batches\n",
      "\u001b[32m[10/17 14:55:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/5766. Dataloading: 0.0005 s/iter. Inference: 0.1195 s/iter. Eval: 0.0002 s/iter. Total: 0.1203 s/iter. ETA=0:11:32\n",
      "\u001b[32m[10/17 14:55:12 d2.evaluation.evaluator]: \u001b[0mInference done 48/5766. Dataloading: 0.0151 s/iter. Inference: 0.1191 s/iter. Eval: 0.0003 s/iter. Total: 0.1345 s/iter. ETA=0:12:49\n",
      "\u001b[32m[10/17 14:55:17 d2.evaluation.evaluator]: \u001b[0mInference done 85/5766. Dataloading: 0.0165 s/iter. Inference: 0.1194 s/iter. Eval: 0.0002 s/iter. Total: 0.1362 s/iter. ETA=0:12:54\n",
      "\u001b[32m[10/17 14:55:22 d2.evaluation.evaluator]: \u001b[0mInference done 127/5766. Dataloading: 0.0140 s/iter. Inference: 0.1162 s/iter. Eval: 0.0002 s/iter. Total: 0.1306 s/iter. ETA=0:12:16\n",
      "\u001b[32m[10/17 14:55:27 d2.evaluation.evaluator]: \u001b[0mInference done 171/5766. Dataloading: 0.0117 s/iter. Inference: 0.1144 s/iter. Eval: 0.0002 s/iter. Total: 0.1265 s/iter. ETA=0:11:47\n",
      "\u001b[32m[10/17 14:55:32 d2.evaluation.evaluator]: \u001b[0mInference done 214/5766. Dataloading: 0.0103 s/iter. Inference: 0.1139 s/iter. Eval: 0.0002 s/iter. Total: 0.1245 s/iter. ETA=0:11:31\n",
      "\u001b[32m[10/17 14:55:37 d2.evaluation.evaluator]: \u001b[0mInference done 254/5766. Dataloading: 0.0110 s/iter. Inference: 0.1136 s/iter. Eval: 0.0002 s/iter. Total: 0.1249 s/iter. ETA=0:11:28\n",
      "\u001b[32m[10/17 14:55:42 d2.evaluation.evaluator]: \u001b[0mInference done 291/5766. Dataloading: 0.0125 s/iter. Inference: 0.1127 s/iter. Eval: 0.0010 s/iter. Total: 0.1263 s/iter. ETA=0:11:31\n",
      "\u001b[32m[10/17 14:55:47 d2.evaluation.evaluator]: \u001b[0mInference done 332/5766. Dataloading: 0.0130 s/iter. Inference: 0.1120 s/iter. Eval: 0.0009 s/iter. Total: 0.1260 s/iter. ETA=0:11:24\n",
      "\u001b[32m[10/17 14:55:53 d2.evaluation.evaluator]: \u001b[0mInference done 380/5766. Dataloading: 0.0116 s/iter. Inference: 0.1109 s/iter. Eval: 0.0008 s/iter. Total: 0.1235 s/iter. ETA=0:11:04\n",
      "\u001b[32m[10/17 14:55:58 d2.evaluation.evaluator]: \u001b[0mInference done 423/5766. Dataloading: 0.0114 s/iter. Inference: 0.1107 s/iter. Eval: 0.0008 s/iter. Total: 0.1230 s/iter. ETA=0:10:56\n",
      "\u001b[32m[10/17 14:56:03 d2.evaluation.evaluator]: \u001b[0mInference done 464/5766. Dataloading: 0.0117 s/iter. Inference: 0.1105 s/iter. Eval: 0.0007 s/iter. Total: 0.1230 s/iter. ETA=0:10:52\n",
      "\u001b[32m[10/17 14:56:08 d2.evaluation.evaluator]: \u001b[0mInference done 505/5766. Dataloading: 0.0120 s/iter. Inference: 0.1102 s/iter. Eval: 0.0007 s/iter. Total: 0.1230 s/iter. ETA=0:10:46\n",
      "\u001b[32m[10/17 14:56:13 d2.evaluation.evaluator]: \u001b[0mInference done 547/5766. Dataloading: 0.0121 s/iter. Inference: 0.1100 s/iter. Eval: 0.0007 s/iter. Total: 0.1228 s/iter. ETA=0:10:40\n",
      "\u001b[32m[10/17 14:56:18 d2.evaluation.evaluator]: \u001b[0mInference done 587/5766. Dataloading: 0.0123 s/iter. Inference: 0.1100 s/iter. Eval: 0.0006 s/iter. Total: 0.1231 s/iter. ETA=0:10:37\n",
      "\u001b[32m[10/17 14:56:23 d2.evaluation.evaluator]: \u001b[0mInference done 629/5766. Dataloading: 0.0125 s/iter. Inference: 0.1097 s/iter. Eval: 0.0006 s/iter. Total: 0.1229 s/iter. ETA=0:10:31\n",
      "\u001b[32m[10/17 14:56:28 d2.evaluation.evaluator]: \u001b[0mInference done 670/5766. Dataloading: 0.0126 s/iter. Inference: 0.1096 s/iter. Eval: 0.0006 s/iter. Total: 0.1228 s/iter. ETA=0:10:25\n",
      "\u001b[32m[10/17 14:56:33 d2.evaluation.evaluator]: \u001b[0mInference done 712/5766. Dataloading: 0.0126 s/iter. Inference: 0.1095 s/iter. Eval: 0.0005 s/iter. Total: 0.1227 s/iter. ETA=0:10:20\n",
      "\u001b[32m[10/17 14:56:38 d2.evaluation.evaluator]: \u001b[0mInference done 758/5766. Dataloading: 0.0121 s/iter. Inference: 0.1091 s/iter. Eval: 0.0005 s/iter. Total: 0.1219 s/iter. ETA=0:10:10\n",
      "\u001b[32m[10/17 14:56:43 d2.evaluation.evaluator]: \u001b[0mInference done 798/5766. Dataloading: 0.0121 s/iter. Inference: 0.1091 s/iter. Eval: 0.0007 s/iter. Total: 0.1220 s/iter. ETA=0:10:06\n",
      "\u001b[32m[10/17 14:56:48 d2.evaluation.evaluator]: \u001b[0mInference done 842/5766. Dataloading: 0.0119 s/iter. Inference: 0.1089 s/iter. Eval: 0.0007 s/iter. Total: 0.1216 s/iter. ETA=0:09:58\n",
      "\u001b[32m[10/17 14:56:53 d2.evaluation.evaluator]: \u001b[0mInference done 885/5766. Dataloading: 0.0119 s/iter. Inference: 0.1088 s/iter. Eval: 0.0007 s/iter. Total: 0.1214 s/iter. ETA=0:09:52\n",
      "\u001b[32m[10/17 14:56:58 d2.evaluation.evaluator]: \u001b[0mInference done 932/5766. Dataloading: 0.0115 s/iter. Inference: 0.1085 s/iter. Eval: 0.0006 s/iter. Total: 0.1207 s/iter. ETA=0:09:43\n",
      "\u001b[32m[10/17 14:57:03 d2.evaluation.evaluator]: \u001b[0mInference done 974/5766. Dataloading: 0.0113 s/iter. Inference: 0.1087 s/iter. Eval: 0.0006 s/iter. Total: 0.1207 s/iter. ETA=0:09:38\n",
      "\u001b[32m[10/17 14:57:08 d2.evaluation.evaluator]: \u001b[0mInference done 1015/5766. Dataloading: 0.0112 s/iter. Inference: 0.1089 s/iter. Eval: 0.0006 s/iter. Total: 0.1208 s/iter. ETA=0:09:33\n",
      "\u001b[32m[10/17 14:57:13 d2.evaluation.evaluator]: \u001b[0mInference done 1054/5766. Dataloading: 0.0113 s/iter. Inference: 0.1092 s/iter. Eval: 0.0006 s/iter. Total: 0.1212 s/iter. ETA=0:09:30\n",
      "\u001b[32m[10/17 14:57:18 d2.evaluation.evaluator]: \u001b[0mInference done 1090/5766. Dataloading: 0.0113 s/iter. Inference: 0.1099 s/iter. Eval: 0.0006 s/iter. Total: 0.1219 s/iter. ETA=0:09:29\n",
      "\u001b[32m[10/17 14:57:24 d2.evaluation.evaluator]: \u001b[0mInference done 1129/5766. Dataloading: 0.0112 s/iter. Inference: 0.1103 s/iter. Eval: 0.0006 s/iter. Total: 0.1222 s/iter. ETA=0:09:26\n",
      "\u001b[32m[10/17 14:57:29 d2.evaluation.evaluator]: \u001b[0mInference done 1168/5766. Dataloading: 0.0110 s/iter. Inference: 0.1107 s/iter. Eval: 0.0006 s/iter. Total: 0.1224 s/iter. ETA=0:09:22\n",
      "\u001b[32m[10/17 14:57:34 d2.evaluation.evaluator]: \u001b[0mInference done 1206/5766. Dataloading: 0.0111 s/iter. Inference: 0.1110 s/iter. Eval: 0.0006 s/iter. Total: 0.1228 s/iter. ETA=0:09:19\n",
      "\u001b[32m[10/17 14:57:39 d2.evaluation.evaluator]: \u001b[0mInference done 1248/5766. Dataloading: 0.0110 s/iter. Inference: 0.1111 s/iter. Eval: 0.0005 s/iter. Total: 0.1227 s/iter. ETA=0:09:14\n",
      "\u001b[32m[10/17 14:57:44 d2.evaluation.evaluator]: \u001b[0mInference done 1285/5766. Dataloading: 0.0109 s/iter. Inference: 0.1115 s/iter. Eval: 0.0005 s/iter. Total: 0.1230 s/iter. ETA=0:09:11\n",
      "\u001b[32m[10/17 14:57:49 d2.evaluation.evaluator]: \u001b[0mInference done 1325/5766. Dataloading: 0.0108 s/iter. Inference: 0.1117 s/iter. Eval: 0.0005 s/iter. Total: 0.1232 s/iter. ETA=0:09:06\n",
      "\u001b[32m[10/17 14:57:54 d2.evaluation.evaluator]: \u001b[0mInference done 1368/5766. Dataloading: 0.0106 s/iter. Inference: 0.1117 s/iter. Eval: 0.0005 s/iter. Total: 0.1230 s/iter. ETA=0:09:00\n",
      "\u001b[32m[10/17 14:57:59 d2.evaluation.evaluator]: \u001b[0mInference done 1411/5766. Dataloading: 0.0106 s/iter. Inference: 0.1116 s/iter. Eval: 0.0005 s/iter. Total: 0.1228 s/iter. ETA=0:08:54\n",
      "\u001b[32m[10/17 14:58:04 d2.evaluation.evaluator]: \u001b[0mInference done 1452/5766. Dataloading: 0.0105 s/iter. Inference: 0.1118 s/iter. Eval: 0.0005 s/iter. Total: 0.1228 s/iter. ETA=0:08:49\n",
      "\u001b[32m[10/17 14:58:09 d2.evaluation.evaluator]: \u001b[0mInference done 1494/5766. Dataloading: 0.0103 s/iter. Inference: 0.1119 s/iter. Eval: 0.0005 s/iter. Total: 0.1228 s/iter. ETA=0:08:44\n",
      "\u001b[32m[10/17 14:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 1538/5766. Dataloading: 0.0101 s/iter. Inference: 0.1119 s/iter. Eval: 0.0005 s/iter. Total: 0.1226 s/iter. ETA=0:08:38\n",
      "\u001b[32m[10/17 14:58:19 d2.evaluation.evaluator]: \u001b[0mInference done 1580/5766. Dataloading: 0.0101 s/iter. Inference: 0.1119 s/iter. Eval: 0.0005 s/iter. Total: 0.1225 s/iter. ETA=0:08:32\n",
      "\u001b[32m[10/17 14:58:24 d2.evaluation.evaluator]: \u001b[0mInference done 1624/5766. Dataloading: 0.0100 s/iter. Inference: 0.1117 s/iter. Eval: 0.0005 s/iter. Total: 0.1223 s/iter. ETA=0:08:26\n",
      "\u001b[32m[10/17 14:58:29 d2.evaluation.evaluator]: \u001b[0mInference done 1668/5766. Dataloading: 0.0099 s/iter. Inference: 0.1116 s/iter. Eval: 0.0005 s/iter. Total: 0.1221 s/iter. ETA=0:08:20\n",
      "\u001b[32m[10/17 14:58:34 d2.evaluation.evaluator]: \u001b[0mInference done 1705/5766. Dataloading: 0.0102 s/iter. Inference: 0.1115 s/iter. Eval: 0.0006 s/iter. Total: 0.1224 s/iter. ETA=0:08:17\n",
      "\u001b[32m[10/17 14:58:40 d2.evaluation.evaluator]: \u001b[0mInference done 1748/5766. Dataloading: 0.0102 s/iter. Inference: 0.1115 s/iter. Eval: 0.0006 s/iter. Total: 0.1223 s/iter. ETA=0:08:11\n",
      "\u001b[32m[10/17 14:58:45 d2.evaluation.evaluator]: \u001b[0mInference done 1794/5766. Dataloading: 0.0100 s/iter. Inference: 0.1114 s/iter. Eval: 0.0005 s/iter. Total: 0.1220 s/iter. ETA=0:08:04\n",
      "\u001b[32m[10/17 14:58:50 d2.evaluation.evaluator]: \u001b[0mInference done 1834/5766. Dataloading: 0.0100 s/iter. Inference: 0.1114 s/iter. Eval: 0.0005 s/iter. Total: 0.1221 s/iter. ETA=0:08:00\n",
      "\u001b[32m[10/17 14:58:55 d2.evaluation.evaluator]: \u001b[0mInference done 1879/5766. Dataloading: 0.0099 s/iter. Inference: 0.1113 s/iter. Eval: 0.0005 s/iter. Total: 0.1218 s/iter. ETA=0:07:53\n",
      "\u001b[32m[10/17 14:59:00 d2.evaluation.evaluator]: \u001b[0mInference done 1924/5766. Dataloading: 0.0098 s/iter. Inference: 0.1113 s/iter. Eval: 0.0005 s/iter. Total: 0.1217 s/iter. ETA=0:07:47\n",
      "\u001b[32m[10/17 14:59:05 d2.evaluation.evaluator]: \u001b[0mInference done 1964/5766. Dataloading: 0.0099 s/iter. Inference: 0.1113 s/iter. Eval: 0.0005 s/iter. Total: 0.1218 s/iter. ETA=0:07:42\n",
      "\u001b[32m[10/17 14:59:10 d2.evaluation.evaluator]: \u001b[0mInference done 2005/5766. Dataloading: 0.0100 s/iter. Inference: 0.1113 s/iter. Eval: 0.0005 s/iter. Total: 0.1218 s/iter. ETA=0:07:38\n",
      "\u001b[32m[10/17 14:59:15 d2.evaluation.evaluator]: \u001b[0mInference done 2049/5766. Dataloading: 0.0098 s/iter. Inference: 0.1112 s/iter. Eval: 0.0005 s/iter. Total: 0.1216 s/iter. ETA=0:07:32\n",
      "\u001b[32m[10/17 14:59:20 d2.evaluation.evaluator]: \u001b[0mInference done 2094/5766. Dataloading: 0.0098 s/iter. Inference: 0.1111 s/iter. Eval: 0.0005 s/iter. Total: 0.1215 s/iter. ETA=0:07:25\n",
      "\u001b[32m[10/17 14:59:25 d2.evaluation.evaluator]: \u001b[0mInference done 2138/5766. Dataloading: 0.0097 s/iter. Inference: 0.1110 s/iter. Eval: 0.0005 s/iter. Total: 0.1213 s/iter. ETA=0:07:20\n",
      "\u001b[32m[10/17 14:59:30 d2.evaluation.evaluator]: \u001b[0mInference done 2182/5766. Dataloading: 0.0097 s/iter. Inference: 0.1109 s/iter. Eval: 0.0005 s/iter. Total: 0.1212 s/iter. ETA=0:07:14\n",
      "\u001b[32m[10/17 14:59:35 d2.evaluation.evaluator]: \u001b[0mInference done 2228/5766. Dataloading: 0.0096 s/iter. Inference: 0.1108 s/iter. Eval: 0.0005 s/iter. Total: 0.1210 s/iter. ETA=0:07:08\n",
      "\u001b[32m[10/17 14:59:40 d2.evaluation.evaluator]: \u001b[0mInference done 2274/5766. Dataloading: 0.0096 s/iter. Inference: 0.1106 s/iter. Eval: 0.0005 s/iter. Total: 0.1208 s/iter. ETA=0:07:01\n",
      "\u001b[32m[10/17 14:59:45 d2.evaluation.evaluator]: \u001b[0mInference done 2320/5766. Dataloading: 0.0094 s/iter. Inference: 0.1105 s/iter. Eval: 0.0005 s/iter. Total: 0.1205 s/iter. ETA=0:06:55\n",
      "\u001b[32m[10/17 14:59:50 d2.evaluation.evaluator]: \u001b[0mInference done 2364/5766. Dataloading: 0.0094 s/iter. Inference: 0.1105 s/iter. Eval: 0.0005 s/iter. Total: 0.1204 s/iter. ETA=0:06:49\n",
      "\u001b[32m[10/17 14:59:55 d2.evaluation.evaluator]: \u001b[0mInference done 2411/5766. Dataloading: 0.0092 s/iter. Inference: 0.1104 s/iter. Eval: 0.0005 s/iter. Total: 0.1202 s/iter. ETA=0:06:43\n",
      "\u001b[32m[10/17 15:00:00 d2.evaluation.evaluator]: \u001b[0mInference done 2453/5766. Dataloading: 0.0093 s/iter. Inference: 0.1103 s/iter. Eval: 0.0005 s/iter. Total: 0.1202 s/iter. ETA=0:06:38\n",
      "\u001b[32m[10/17 15:00:06 d2.evaluation.evaluator]: \u001b[0mInference done 2499/5766. Dataloading: 0.0092 s/iter. Inference: 0.1102 s/iter. Eval: 0.0005 s/iter. Total: 0.1200 s/iter. ETA=0:06:31\n",
      "\u001b[32m[10/17 15:00:11 d2.evaluation.evaluator]: \u001b[0mInference done 2544/5766. Dataloading: 0.0092 s/iter. Inference: 0.1101 s/iter. Eval: 0.0005 s/iter. Total: 0.1199 s/iter. ETA=0:06:26\n",
      "\u001b[32m[10/17 15:00:16 d2.evaluation.evaluator]: \u001b[0mInference done 2588/5766. Dataloading: 0.0092 s/iter. Inference: 0.1101 s/iter. Eval: 0.0004 s/iter. Total: 0.1198 s/iter. ETA=0:06:20\n",
      "\u001b[32m[10/17 15:00:21 d2.evaluation.evaluator]: \u001b[0mInference done 2633/5766. Dataloading: 0.0091 s/iter. Inference: 0.1100 s/iter. Eval: 0.0004 s/iter. Total: 0.1197 s/iter. ETA=0:06:14\n",
      "\u001b[32m[10/17 15:00:26 d2.evaluation.evaluator]: \u001b[0mInference done 2677/5766. Dataloading: 0.0091 s/iter. Inference: 0.1099 s/iter. Eval: 0.0004 s/iter. Total: 0.1196 s/iter. ETA=0:06:09\n",
      "\u001b[32m[10/17 15:00:31 d2.evaluation.evaluator]: \u001b[0mInference done 2718/5766. Dataloading: 0.0092 s/iter. Inference: 0.1099 s/iter. Eval: 0.0004 s/iter. Total: 0.1197 s/iter. ETA=0:06:04\n",
      "\u001b[32m[10/17 15:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 2766/5766. Dataloading: 0.0091 s/iter. Inference: 0.1098 s/iter. Eval: 0.0004 s/iter. Total: 0.1194 s/iter. ETA=0:05:58\n",
      "\u001b[32m[10/17 15:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 2807/5766. Dataloading: 0.0091 s/iter. Inference: 0.1097 s/iter. Eval: 0.0005 s/iter. Total: 0.1195 s/iter. ETA=0:05:53\n",
      "\u001b[32m[10/17 15:00:46 d2.evaluation.evaluator]: \u001b[0mInference done 2852/5766. Dataloading: 0.0091 s/iter. Inference: 0.1097 s/iter. Eval: 0.0005 s/iter. Total: 0.1194 s/iter. ETA=0:05:47\n",
      "\u001b[32m[10/17 15:00:51 d2.evaluation.evaluator]: \u001b[0mInference done 2896/5766. Dataloading: 0.0090 s/iter. Inference: 0.1097 s/iter. Eval: 0.0005 s/iter. Total: 0.1193 s/iter. ETA=0:05:42\n",
      "\u001b[32m[10/17 15:00:56 d2.evaluation.evaluator]: \u001b[0mInference done 2939/5766. Dataloading: 0.0091 s/iter. Inference: 0.1096 s/iter. Eval: 0.0005 s/iter. Total: 0.1193 s/iter. ETA=0:05:37\n",
      "\u001b[32m[10/17 15:01:01 d2.evaluation.evaluator]: \u001b[0mInference done 2982/5766. Dataloading: 0.0091 s/iter. Inference: 0.1096 s/iter. Eval: 0.0005 s/iter. Total: 0.1193 s/iter. ETA=0:05:32\n",
      "\u001b[32m[10/17 15:01:06 d2.evaluation.evaluator]: \u001b[0mInference done 3028/5766. Dataloading: 0.0090 s/iter. Inference: 0.1095 s/iter. Eval: 0.0005 s/iter. Total: 0.1191 s/iter. ETA=0:05:26\n",
      "\u001b[32m[10/17 15:01:11 d2.evaluation.evaluator]: \u001b[0mInference done 3072/5766. Dataloading: 0.0090 s/iter. Inference: 0.1095 s/iter. Eval: 0.0005 s/iter. Total: 0.1190 s/iter. ETA=0:05:20\n",
      "\u001b[32m[10/17 15:01:17 d2.evaluation.evaluator]: \u001b[0mInference done 3118/5766. Dataloading: 0.0090 s/iter. Inference: 0.1094 s/iter. Eval: 0.0005 s/iter. Total: 0.1189 s/iter. ETA=0:05:14\n",
      "\u001b[32m[10/17 15:01:22 d2.evaluation.evaluator]: \u001b[0mInference done 3161/5766. Dataloading: 0.0090 s/iter. Inference: 0.1093 s/iter. Eval: 0.0005 s/iter. Total: 0.1189 s/iter. ETA=0:05:09\n",
      "\u001b[32m[10/17 15:01:27 d2.evaluation.evaluator]: \u001b[0mInference done 3202/5766. Dataloading: 0.0091 s/iter. Inference: 0.1093 s/iter. Eval: 0.0005 s/iter. Total: 0.1190 s/iter. ETA=0:05:05\n",
      "\u001b[32m[10/17 15:01:32 d2.evaluation.evaluator]: \u001b[0mInference done 3247/5766. Dataloading: 0.0090 s/iter. Inference: 0.1093 s/iter. Eval: 0.0005 s/iter. Total: 0.1189 s/iter. ETA=0:04:59\n",
      "\u001b[32m[10/17 15:01:37 d2.evaluation.evaluator]: \u001b[0mInference done 3290/5766. Dataloading: 0.0090 s/iter. Inference: 0.1093 s/iter. Eval: 0.0005 s/iter. Total: 0.1189 s/iter. ETA=0:04:54\n",
      "\u001b[32m[10/17 15:01:42 d2.evaluation.evaluator]: \u001b[0mInference done 3332/5766. Dataloading: 0.0090 s/iter. Inference: 0.1093 s/iter. Eval: 0.0005 s/iter. Total: 0.1189 s/iter. ETA=0:04:49\n",
      "\u001b[32m[10/17 15:01:47 d2.evaluation.evaluator]: \u001b[0mInference done 3374/5766. Dataloading: 0.0091 s/iter. Inference: 0.1093 s/iter. Eval: 0.0005 s/iter. Total: 0.1189 s/iter. ETA=0:04:44\n",
      "\u001b[32m[10/17 15:01:52 d2.evaluation.evaluator]: \u001b[0mInference done 3420/5766. Dataloading: 0.0090 s/iter. Inference: 0.1092 s/iter. Eval: 0.0005 s/iter. Total: 0.1188 s/iter. ETA=0:04:38\n",
      "\u001b[32m[10/17 15:01:57 d2.evaluation.evaluator]: \u001b[0mInference done 3465/5766. Dataloading: 0.0091 s/iter. Inference: 0.1091 s/iter. Eval: 0.0005 s/iter. Total: 0.1188 s/iter. ETA=0:04:33\n",
      "\u001b[32m[10/17 15:02:02 d2.evaluation.evaluator]: \u001b[0mInference done 3510/5766. Dataloading: 0.0090 s/iter. Inference: 0.1091 s/iter. Eval: 0.0005 s/iter. Total: 0.1187 s/iter. ETA=0:04:27\n",
      "\u001b[32m[10/17 15:02:07 d2.evaluation.evaluator]: \u001b[0mInference done 3555/5766. Dataloading: 0.0090 s/iter. Inference: 0.1090 s/iter. Eval: 0.0005 s/iter. Total: 0.1186 s/iter. ETA=0:04:22\n",
      "\u001b[32m[10/17 15:02:12 d2.evaluation.evaluator]: \u001b[0mInference done 3598/5766. Dataloading: 0.0090 s/iter. Inference: 0.1090 s/iter. Eval: 0.0005 s/iter. Total: 0.1186 s/iter. ETA=0:04:17\n",
      "\u001b[32m[10/17 15:02:17 d2.evaluation.evaluator]: \u001b[0mInference done 3642/5766. Dataloading: 0.0090 s/iter. Inference: 0.1090 s/iter. Eval: 0.0005 s/iter. Total: 0.1185 s/iter. ETA=0:04:11\n",
      "\u001b[32m[10/17 15:02:22 d2.evaluation.evaluator]: \u001b[0mInference done 3689/5766. Dataloading: 0.0089 s/iter. Inference: 0.1089 s/iter. Eval: 0.0005 s/iter. Total: 0.1184 s/iter. ETA=0:04:05\n",
      "\u001b[32m[10/17 15:02:27 d2.evaluation.evaluator]: \u001b[0mInference done 3735/5766. Dataloading: 0.0089 s/iter. Inference: 0.1089 s/iter. Eval: 0.0005 s/iter. Total: 0.1183 s/iter. ETA=0:04:00\n",
      "\u001b[32m[10/17 15:02:33 d2.evaluation.evaluator]: \u001b[0mInference done 3783/5766. Dataloading: 0.0088 s/iter. Inference: 0.1088 s/iter. Eval: 0.0005 s/iter. Total: 0.1181 s/iter. ETA=0:03:54\n",
      "\u001b[32m[10/17 15:02:38 d2.evaluation.evaluator]: \u001b[0mInference done 3824/5766. Dataloading: 0.0089 s/iter. Inference: 0.1087 s/iter. Eval: 0.0004 s/iter. Total: 0.1182 s/iter. ETA=0:03:49\n",
      "\u001b[32m[10/17 15:02:43 d2.evaluation.evaluator]: \u001b[0mInference done 3869/5766. Dataloading: 0.0089 s/iter. Inference: 0.1087 s/iter. Eval: 0.0004 s/iter. Total: 0.1181 s/iter. ETA=0:03:44\n",
      "\u001b[32m[10/17 15:02:48 d2.evaluation.evaluator]: \u001b[0mInference done 3914/5766. Dataloading: 0.0088 s/iter. Inference: 0.1087 s/iter. Eval: 0.0004 s/iter. Total: 0.1181 s/iter. ETA=0:03:38\n",
      "\u001b[32m[10/17 15:02:53 d2.evaluation.evaluator]: \u001b[0mInference done 3957/5766. Dataloading: 0.0089 s/iter. Inference: 0.1087 s/iter. Eval: 0.0004 s/iter. Total: 0.1181 s/iter. ETA=0:03:33\n",
      "\u001b[32m[10/17 15:02:58 d2.evaluation.evaluator]: \u001b[0mInference done 4001/5766. Dataloading: 0.0088 s/iter. Inference: 0.1087 s/iter. Eval: 0.0004 s/iter. Total: 0.1180 s/iter. ETA=0:03:28\n",
      "\u001b[32m[10/17 15:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 4044/5766. Dataloading: 0.0088 s/iter. Inference: 0.1087 s/iter. Eval: 0.0004 s/iter. Total: 0.1180 s/iter. ETA=0:03:23\n",
      "\u001b[32m[10/17 15:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 4083/5766. Dataloading: 0.0089 s/iter. Inference: 0.1087 s/iter. Eval: 0.0004 s/iter. Total: 0.1181 s/iter. ETA=0:03:18\n",
      "\u001b[32m[10/17 15:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 4123/5766. Dataloading: 0.0090 s/iter. Inference: 0.1087 s/iter. Eval: 0.0004 s/iter. Total: 0.1182 s/iter. ETA=0:03:14\n",
      "\u001b[32m[10/17 15:03:18 d2.evaluation.evaluator]: \u001b[0mInference done 4164/5766. Dataloading: 0.0090 s/iter. Inference: 0.1088 s/iter. Eval: 0.0004 s/iter. Total: 0.1183 s/iter. ETA=0:03:09\n",
      "\u001b[32m[10/17 15:03:23 d2.evaluation.evaluator]: \u001b[0mInference done 4198/5766. Dataloading: 0.0091 s/iter. Inference: 0.1089 s/iter. Eval: 0.0005 s/iter. Total: 0.1186 s/iter. ETA=0:03:05\n",
      "\u001b[32m[10/17 15:03:28 d2.evaluation.evaluator]: \u001b[0mInference done 4240/5766. Dataloading: 0.0091 s/iter. Inference: 0.1089 s/iter. Eval: 0.0005 s/iter. Total: 0.1186 s/iter. ETA=0:03:00\n",
      "\u001b[32m[10/17 15:03:33 d2.evaluation.evaluator]: \u001b[0mInference done 4281/5766. Dataloading: 0.0090 s/iter. Inference: 0.1090 s/iter. Eval: 0.0005 s/iter. Total: 0.1186 s/iter. ETA=0:02:56\n",
      "\u001b[32m[10/17 15:03:39 d2.evaluation.evaluator]: \u001b[0mInference done 4319/5766. Dataloading: 0.0091 s/iter. Inference: 0.1091 s/iter. Eval: 0.0005 s/iter. Total: 0.1187 s/iter. ETA=0:02:51\n",
      "\u001b[32m[10/17 15:03:44 d2.evaluation.evaluator]: \u001b[0mInference done 4360/5766. Dataloading: 0.0091 s/iter. Inference: 0.1091 s/iter. Eval: 0.0005 s/iter. Total: 0.1188 s/iter. ETA=0:02:46\n",
      "\u001b[32m[10/17 15:03:49 d2.evaluation.evaluator]: \u001b[0mInference done 4402/5766. Dataloading: 0.0090 s/iter. Inference: 0.1092 s/iter. Eval: 0.0005 s/iter. Total: 0.1188 s/iter. ETA=0:02:42\n",
      "\u001b[32m[10/17 15:03:54 d2.evaluation.evaluator]: \u001b[0mInference done 4444/5766. Dataloading: 0.0090 s/iter. Inference: 0.1092 s/iter. Eval: 0.0005 s/iter. Total: 0.1188 s/iter. ETA=0:02:37\n",
      "\u001b[32m[10/17 15:03:59 d2.evaluation.evaluator]: \u001b[0mInference done 4487/5766. Dataloading: 0.0090 s/iter. Inference: 0.1092 s/iter. Eval: 0.0005 s/iter. Total: 0.1188 s/iter. ETA=0:02:31\n",
      "\u001b[32m[10/17 15:04:04 d2.evaluation.evaluator]: \u001b[0mInference done 4529/5766. Dataloading: 0.0090 s/iter. Inference: 0.1092 s/iter. Eval: 0.0005 s/iter. Total: 0.1188 s/iter. ETA=0:02:26\n",
      "\u001b[32m[10/17 15:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 4571/5766. Dataloading: 0.0089 s/iter. Inference: 0.1093 s/iter. Eval: 0.0005 s/iter. Total: 0.1188 s/iter. ETA=0:02:21\n",
      "\u001b[32m[10/17 15:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 4610/5766. Dataloading: 0.0090 s/iter. Inference: 0.1094 s/iter. Eval: 0.0005 s/iter. Total: 0.1189 s/iter. ETA=0:02:17\n",
      "\u001b[32m[10/17 15:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 4647/5766. Dataloading: 0.0091 s/iter. Inference: 0.1094 s/iter. Eval: 0.0005 s/iter. Total: 0.1191 s/iter. ETA=0:02:13\n",
      "\u001b[32m[10/17 15:04:24 d2.evaluation.evaluator]: \u001b[0mInference done 4692/5766. Dataloading: 0.0091 s/iter. Inference: 0.1094 s/iter. Eval: 0.0005 s/iter. Total: 0.1190 s/iter. ETA=0:02:07\n",
      "\u001b[32m[10/17 15:04:29 d2.evaluation.evaluator]: \u001b[0mInference done 4738/5766. Dataloading: 0.0090 s/iter. Inference: 0.1093 s/iter. Eval: 0.0005 s/iter. Total: 0.1189 s/iter. ETA=0:02:02\n",
      "\u001b[32m[10/17 15:04:34 d2.evaluation.evaluator]: \u001b[0mInference done 4781/5766. Dataloading: 0.0090 s/iter. Inference: 0.1093 s/iter. Eval: 0.0005 s/iter. Total: 0.1189 s/iter. ETA=0:01:57\n",
      "\u001b[32m[10/17 15:04:39 d2.evaluation.evaluator]: \u001b[0mInference done 4824/5766. Dataloading: 0.0090 s/iter. Inference: 0.1093 s/iter. Eval: 0.0005 s/iter. Total: 0.1189 s/iter. ETA=0:01:51\n",
      "\u001b[32m[10/17 15:04:44 d2.evaluation.evaluator]: \u001b[0mInference done 4868/5766. Dataloading: 0.0090 s/iter. Inference: 0.1093 s/iter. Eval: 0.0005 s/iter. Total: 0.1188 s/iter. ETA=0:01:46\n",
      "\u001b[32m[10/17 15:04:49 d2.evaluation.evaluator]: \u001b[0mInference done 4916/5766. Dataloading: 0.0090 s/iter. Inference: 0.1092 s/iter. Eval: 0.0005 s/iter. Total: 0.1187 s/iter. ETA=0:01:40\n",
      "\u001b[32m[10/17 15:04:54 d2.evaluation.evaluator]: \u001b[0mInference done 4957/5766. Dataloading: 0.0090 s/iter. Inference: 0.1092 s/iter. Eval: 0.0005 s/iter. Total: 0.1187 s/iter. ETA=0:01:36\n",
      "\u001b[32m[10/17 15:04:59 d2.evaluation.evaluator]: \u001b[0mInference done 5001/5766. Dataloading: 0.0090 s/iter. Inference: 0.1091 s/iter. Eval: 0.0005 s/iter. Total: 0.1187 s/iter. ETA=0:01:30\n",
      "\u001b[32m[10/17 15:05:04 d2.evaluation.evaluator]: \u001b[0mInference done 5045/5766. Dataloading: 0.0090 s/iter. Inference: 0.1092 s/iter. Eval: 0.0005 s/iter. Total: 0.1187 s/iter. ETA=0:01:25\n",
      "\u001b[32m[10/17 15:05:10 d2.evaluation.evaluator]: \u001b[0mInference done 5090/5766. Dataloading: 0.0090 s/iter. Inference: 0.1091 s/iter. Eval: 0.0004 s/iter. Total: 0.1186 s/iter. ETA=0:01:20\n",
      "\u001b[32m[10/17 15:05:15 d2.evaluation.evaluator]: \u001b[0mInference done 5133/5766. Dataloading: 0.0090 s/iter. Inference: 0.1091 s/iter. Eval: 0.0004 s/iter. Total: 0.1186 s/iter. ETA=0:01:15\n",
      "\u001b[32m[10/17 15:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 5178/5766. Dataloading: 0.0090 s/iter. Inference: 0.1091 s/iter. Eval: 0.0004 s/iter. Total: 0.1186 s/iter. ETA=0:01:09\n",
      "\u001b[32m[10/17 15:05:25 d2.evaluation.evaluator]: \u001b[0mInference done 5224/5766. Dataloading: 0.0089 s/iter. Inference: 0.1091 s/iter. Eval: 0.0004 s/iter. Total: 0.1185 s/iter. ETA=0:01:04\n",
      "\u001b[32m[10/17 15:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 5268/5766. Dataloading: 0.0089 s/iter. Inference: 0.1090 s/iter. Eval: 0.0004 s/iter. Total: 0.1185 s/iter. ETA=0:00:59\n",
      "\u001b[32m[10/17 15:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 5310/5766. Dataloading: 0.0090 s/iter. Inference: 0.1090 s/iter. Eval: 0.0004 s/iter. Total: 0.1185 s/iter. ETA=0:00:54\n",
      "\u001b[32m[10/17 15:05:40 d2.evaluation.evaluator]: \u001b[0mInference done 5349/5766. Dataloading: 0.0089 s/iter. Inference: 0.1091 s/iter. Eval: 0.0004 s/iter. Total: 0.1186 s/iter. ETA=0:00:49\n",
      "\u001b[32m[10/17 15:05:45 d2.evaluation.evaluator]: \u001b[0mInference done 5385/5766. Dataloading: 0.0090 s/iter. Inference: 0.1092 s/iter. Eval: 0.0004 s/iter. Total: 0.1187 s/iter. ETA=0:00:45\n",
      "\u001b[32m[10/17 15:05:54 d2.evaluation.evaluator]: \u001b[0mInference done 5416/5766. Dataloading: 0.0099 s/iter. Inference: 0.1093 s/iter. Eval: 0.0004 s/iter. Total: 0.1198 s/iter. ETA=0:00:41\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 126518) is killed by signal: Killed. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_122637/2575684217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCOEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./output/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_detection_test_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/detectron2/evaluation/evaluator.py\u001b[0m in \u001b[0;36minference_on_dataset\u001b[0;34m(model, data_loader, evaluator)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mstart_compute_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/detectron2/modeling/meta_arch/retinanet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_anchor_deltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/detectron2/modeling/meta_arch/retinanet.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, anchors, pred_logits, pred_anchor_deltas, image_sizes)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mpred_logits_per_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_logits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0mdeltas_per_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_anchor_deltas\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             results_per_image = self.inference_single_image(\n\u001b[0m\u001b[1;32m    415\u001b[0m                 \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_logits_per_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas_per_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/detectron2/modeling/meta_arch/retinanet.py\u001b[0m in \u001b[0;36minference_single_image\u001b[0;34m(self, anchors, box_cls, box_delta, image_size)\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;31m# 1. Keep boxes with confidence score higher than threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mkeep_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_prob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_score_thresh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0mpredicted_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m             \u001b[0mtopk_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonzero_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 126518) is killed by signal: Killed. "
     ]
    }
   ],
   "source": [
    "# from detectron2.utils.logger import setup_logger\n",
    "# setup_logger()\n",
    "# # models = [\n",
    "# #     \"fast_rcnn_R_50_FPN_1x.yaml\",\n",
    "# #     \"faster_rcnn_R_50_C4_1x.yaml\",\n",
    "# #     \"faster_rcnn_R_50_C4_3x.yaml\",\n",
    "# #     \"faster_rcnn_R_50_DC5_1x.yaml\",\n",
    "# #     \"faster_rcnn_R_50_DC5_3x.yaml\",\n",
    "# #     \"retinanet_R_50_FPN_1x.py\",\n",
    "# #     \"retinanet_R_50_FPN_1x.yaml\",\n",
    "# #     \"retinanet_R_50_FPN_3x.yaml\",\n",
    "# #     \"rpn_R_50_C4_1x.yaml\",\n",
    "# #     \"rpn_R_50_FPN_1x.yaml\"\n",
    "# #     \"faster_rcnn_R_50_FPN_1x.yaml\",\n",
    "# #     \"faster_rcnn_R_50_FPN_3x.yaml\",\n",
    "# #     \"faster_rcnn_R_101_DC5_3x.yaml\",\n",
    "# #     \"faster_rcnn_R_101_FPN_3x.yaml\",\n",
    "# #     \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
    "# #     \"\",\n",
    "# # ]\n",
    "# model = f\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"\n",
    "# torch.cuda.empty_cache()\n",
    "# wandb.tensorboard.patch(\"./output\")\n",
    "# wandb.init(project='Find-Card',name='baseline')\n",
    "# torch.cuda.empty_cache()\n",
    "# cfg = get_cfg()\n",
    "# torch.cuda.empty_cache()\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(model))\n",
    "# torch.cuda.empty_cache()\n",
    "# cfg.DATASETS.TRAIN = ('data',)\n",
    "# torch.cuda.empty_cache()\n",
    "# cfg.DATASETS.TEST = ()\n",
    "# torch.cuda.empty_cache()\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "# torch.cuda.empty_cache()\n",
    "# cfg.SOLVER.MAX_ITER = 100\n",
    "# torch.cuda.empty_cache()\n",
    "# cfg.TEST.EVAL_PERIOD = 50\n",
    "# cfg.SOLVER.BASE_LR = 0.00025\n",
    "# torch.cuda.empty_cache()\n",
    "# cfg.SOLVER.STEPS = []\n",
    "# torch.cuda.empty_cache()\n",
    "# cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "# torch.cuda.empty_cache()\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
    "# torch.cuda.empty_cache()\n",
    "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "# torch.cuda.empty_cache()\n",
    "# trainer = DefaultTrainer(cfg)\n",
    "# torch.cuda.empty_cache()\n",
    "# trainer.resume_or_load(resume=False)\n",
    "# torch.cuda.empty_cache()\n",
    "# trainer.train()\n",
    "# torch.cuda.empty_cache()\n",
    "# # cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
    "# torch.cuda.empty_cache()\n",
    "# cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "# torch.cuda.empty_cache()\n",
    "# predictor = DefaultPredictor(cfg)\n",
    "# torch.cuda.empty_cache()\n",
    "# cfg.MODEL.WEIGHTS = './output/model_final.pth'\n",
    "# cfg.SOLVER.SCORE_THRESH_TEST = 0.25\n",
    "# predictor = DefaultPredictor(cfg)\n",
    "# evaluator = COCOEvaluator('test',output_dir='./output/')\n",
    "# val_loader = build_detection_test_loader(cfg,'test')\n",
    "# metrics = inference_on_dataset(predictor.model,val_loader,evaluator)\n",
    "# wandb.log(metrics)\n",
    "# evaluator = COCOEvaluator('data',output_dir='./output/')\n",
    "# val_loader = build_detection_test_loader(cfg,'data')\n",
    "# metrics = inference_on_dataset(predictor.model,val_loader,evaluator)\n",
    "# wandb.log(metrics)\n",
    "# torch.cuda.empty_cache()\n",
    "# logs = open('./output/metrics.json','r').read().split('\\n')\n",
    "# for log in tqdm(range(len(logs))):\n",
    "#     res = ast.literal_eval(logs[log])\n",
    "#     wandb.log(res)\n",
    "# for img in os.listdir(\"./test_imgs/\"):\n",
    "#     torch.cuda.empty_cache()\n",
    "#     v = Visualizer(cv2.imread(f\"./test_imgs/{img}\")[:, :, ::-1], metadata=metadata)\n",
    "#     torch.cuda.empty_cache()\n",
    "#     v = v.draw_instance_predictions(\n",
    "#         predictor(cv2.imread(f\"./test_imgs/{img}\"))[\"instances\"].to(\"cpu\")\n",
    "#     )\n",
    "#     torch.cuda.empty_cache()\n",
    "#     v = v.get_image()[:, :, ::-1]\n",
    "#     torch.cuda.empty_cache()\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     torch.cuda.empty_cache()\n",
    "#     plt.imshow(v)\n",
    "#     torch.cuda.empty_cache()\n",
    "#     plt.savefig(f\"./preds/{img}\")\n",
    "#     torch.cuda.empty_cache()\n",
    "#     plt.close()\n",
    "#     torch.cuda.empty_cache()    \n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc68192-a8a5-400a-9d8b-89ed656c4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "models = [\n",
    "    \"fast_rcnn_R_50_FPN_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_C4_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_C4_3x.yaml\",\n",
    "    \"faster_rcnn_R_50_DC5_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_DC5_3x.yaml\",\n",
    "    \"retinanet_R_50_FPN_1x.py\",\n",
    "    \"retinanet_R_50_FPN_1x.yaml\",\n",
    "    \"retinanet_R_50_FPN_3x.yaml\",\n",
    "    \"rpn_R_50_C4_1x.yaml\",\n",
    "    \"rpn_R_50_FPN_1x.yaml\"\n",
    "    \"faster_rcnn_R_50_FPN_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_FPN_3x.yaml\",\n",
    "    \"faster_rcnn_R_101_DC5_3x.yaml\",\n",
    "    \"faster_rcnn_R_101_FPN_3x.yaml\",\n",
    "    \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
    "]\n",
    "for model in models:\n",
    "    model = f\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.tensorboard.patch(\"./output\")\n",
    "    wandb.init(project='Find-Card',name='baseline')\n",
    "    torch.cuda.empty_cache()\n",
    "    cfg = get_cfg()\n",
    "    torch.cuda.empty_cache()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(model))\n",
    "    torch.cuda.empty_cache()\n",
    "    cfg.DATASETS.TRAIN = ('data',)\n",
    "    torch.cuda.empty_cache()\n",
    "    cfg.DATASETS.TEST = ()\n",
    "    torch.cuda.empty_cache()\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "    torch.cuda.empty_cache()\n",
    "    cfg.SOLVER.MAX_ITER = 100\n",
    "    torch.cuda.empty_cache()\n",
    "    cfg.TEST.EVAL_PERIOD = 50\n",
    "    cfg.SOLVER.BASE_LR = 0.00025\n",
    "    torch.cuda.empty_cache()\n",
    "    cfg.SOLVER.STEPS = []\n",
    "    torch.cuda.empty_cache()\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "    torch.cuda.empty_cache()\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
    "    torch.cuda.empty_cache()\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "    torch.cuda.empty_cache()\n",
    "    trainer = DefaultTrainer(cfg)\n",
    "    torch.cuda.empty_cache()\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    torch.cuda.empty_cache()\n",
    "    trainer.train()\n",
    "    torch.cuda.empty_cache()\n",
    "    # cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
    "    torch.cuda.empty_cache()\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "    torch.cuda.empty_cache()\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    torch.cuda.empty_cache()\n",
    "    cfg.MODEL.WEIGHTS = './output/model_final.pth'\n",
    "    cfg.SOLVER.SCORE_THRESH_TEST = 0.25\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    evaluator = COCOEvaluator('test',output_dir='./output/')\n",
    "    val_loader = build_detection_test_loader(cfg,'test')\n",
    "    metrics = inference_on_dataset(predictor.model,val_loader,evaluator)\n",
    "    wandb.log(metrics)\n",
    "    evaluator = COCOEvaluator('data',output_dir='./output/')\n",
    "    val_loader = build_detection_test_loader(cfg,'data')\n",
    "    metrics = inference_on_dataset(predictor.model,val_loader,evaluator)\n",
    "    wandb.log(metrics)\n",
    "    torch.cuda.empty_cache()\n",
    "    logs = open('./output/metrics.json','r').read().split('\\n')\n",
    "    for log in tqdm(range(len(logs))):\n",
    "        res = ast.literal_eval(logs[log])\n",
    "        wandb.log(res)\n",
    "    for img in os.listdir(\"./test_imgs/\"):\n",
    "        torch.cuda.empty_cache()\n",
    "        v = Visualizer(cv2.imread(f\"./test_imgs/{img}\")[:, :, ::-1], metadata=metadata)\n",
    "        torch.cuda.empty_cache()\n",
    "        v = v.draw_instance_predictions(\n",
    "            predictor(cv2.imread(f\"./test_imgs/{img}\"))[\"instances\"].to(\"cpu\")\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        v = v.get_image()[:, :, ::-1]\n",
    "        torch.cuda.empty_cache()\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        torch.cuda.empty_cache()\n",
    "        plt.imshow(v)\n",
    "        torch.cuda.empty_cache()\n",
    "        plt.savefig(f\"./preds/{img}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        plt.close()\n",
    "        torch.cuda.empty_cache()    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7606bcd9-1de9-44b4-b357-8ebd89a597df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python3811jvsc74a57bd0f5712b28ab533ddcd3a93c4a815f0ece6a0b0b411aefcf33cd4d282335a68ea6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
