{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05913d59-e9de-41ee-8ef4-ffc288015942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "import torch, torchvision\n",
    "import detectron2\n",
    "import json\n",
    "import ast \n",
    "import tensorboard,os\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from tqdm import tqdm\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f77166-567f-4e53-87a4-bebed5fcf8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_remove = os.listdir('./output/')\n",
    "files_to_remove.remove('metrics.json')\n",
    "for file_to_remove in files_to_remove:\n",
    "    os.remove(f'./output/{file_to_remove}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886fa83a-c439-4554-8d17-777cee97dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Data.csv\").sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f392a7f-893b-4b55-af75-1a5987b1e741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[144, 141, 137],\n",
       "        [138, 135, 131],\n",
       "        [139, 136, 132],\n",
       "        ...,\n",
       "        [ 48,  24,   4],\n",
       "        [ 48,  24,   4],\n",
       "        [ 51,  27,   7]],\n",
       "\n",
       "       [[149, 146, 142],\n",
       "        [145, 142, 138],\n",
       "        [145, 142, 138],\n",
       "        ...,\n",
       "        [ 49,  25,   5],\n",
       "        [ 48,  24,   4],\n",
       "        [ 50,  26,   6]],\n",
       "\n",
       "       [[150, 147, 143],\n",
       "        [148, 145, 141],\n",
       "        [148, 145, 141],\n",
       "        ...,\n",
       "        [ 49,  25,   5],\n",
       "        [ 48,  24,   4],\n",
       "        [ 49,  25,   5]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[222, 214, 201],\n",
       "        [222, 214, 201],\n",
       "        [222, 214, 201],\n",
       "        ...,\n",
       "        [107, 127, 138],\n",
       "        [108, 128, 139],\n",
       "        [108, 128, 139]],\n",
       "\n",
       "       [[222, 214, 201],\n",
       "        [222, 214, 201],\n",
       "        [222, 214, 201],\n",
       "        ...,\n",
       "        [105, 125, 136],\n",
       "        [106, 126, 137],\n",
       "        [107, 127, 138]],\n",
       "\n",
       "       [[222, 214, 201],\n",
       "        [222, 214, 201],\n",
       "        [222, 214, 201],\n",
       "        ...,\n",
       "        [103, 123, 134],\n",
       "        [102, 122, 133],\n",
       "        [103, 123, 134]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = data.iloc[59]\n",
    "img = cv2.imread(f'./Img/{info[\"Path\"]}')\n",
    "height, width = cv2.imread(\"./Img/\" + info[\"Path\"]).shape[:2]\n",
    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "xmin = round(xmin * width)\n",
    "xmax = round(xmax * width)\n",
    "ymin = round(ymin * height)\n",
    "ymax = round(ymax * height)\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "x,y,w,h = round(x),round(y),round(w),round(h)\n",
    "cv2.imwrite('./output.png',img)\n",
    "roi=img[y:y+h,x:x+w]\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b17e1f90-c8b5-432e-be3a-df122a2fb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "def load_data(data=data, test=False):\n",
    "    if test is True:\n",
    "        if \"data.npy\" in os.listdir(\"./\"):\n",
    "            data = np.load(\"./data.npy\", allow_pickle=True)\n",
    "            data = data[:325]\n",
    "            print(len(data))\n",
    "            return data\n",
    "    if \"data.npy\" in os.listdir(\"./\"):\n",
    "        data = np.load(\"./data.npy\", allow_pickle=True)\n",
    "        print(len(data))\n",
    "        return data\n",
    "    new_data = []\n",
    "    for idx in tqdm(range(len(data))):\n",
    "        record = {}\n",
    "        info = data.iloc[idx]\n",
    "        height, width = cv2.imread(\"./Img/\" + info[\"Path\"]).shape[:2]\n",
    "        xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "        xmin = round(xmin * width)\n",
    "        xmax = round(xmax * width)\n",
    "        ymin = round(ymin * height)\n",
    "        ymax = round(ymax * height)\n",
    "        record[\"file_name\"] = \"./Img/\" + info[\"Path\"]\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        objs = [\n",
    "            {\n",
    "                \"bbox\": [xmin,ymin,xmax,ymax],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"category_id\": 0,\n",
    "            }\n",
    "        ]\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"annotations\"] = objs\n",
    "        new_data.append(record)\n",
    "    np.random.shuffle(new_data)\n",
    "    np.save(\"data.npy\", new_data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb92183d-6ced-44ec-9586-ed3ce8ce9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "labels = [\"Card\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de01b6ab-0060-4988-bea8-90145f494d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the data\n",
    "DatasetCatalog.register(\"data\", lambda: load_data())\n",
    "MetadataCatalog.get(\"data\").set(thing_classes=labels)\n",
    "metadata = MetadataCatalog.get(\"data\")\n",
    "DatasetCatalog.register(\"test\", lambda: load_data(test=True))\n",
    "MetadataCatalog.get(\"test\").set(thing_classes=labels)\n",
    "metadata_test = MetadataCatalog.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6fa0905-7359-47bb-82d1-7e46e01e98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"fast_rcnn_R_50_FPN_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_C4_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_C4_3x.yaml\",\n",
    "    \"faster_rcnn_R_50_DC5_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_DC5_3x.yaml\",\n",
    "    \"retinanet_R_50_FPN_1x.py\",\n",
    "    \"retinanet_R_50_FPN_1x.yaml\",\n",
    "    \"retinanet_R_50_FPN_3x.yaml\",\n",
    "    \"rpn_R_50_C4_1x.yaml\",\n",
    "    \"rpn_R_50_FPN_1x.yaml\"\n",
    "    \"faster_rcnn_R_50_FPN_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_FPN_3x.yaml\",\n",
    "    \"faster_rcnn_R_101_DC5_3x.yaml\",\n",
    "    \"faster_rcnn_R_101_FPN_3x.yaml\",\n",
    "    \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
    "]\n",
    "max_iters = [\n",
    "    50,100,125,250,500,1000,2000,2500,5000\n",
    "]\n",
    "base_lrs = [\n",
    "    0.1,0.01,0.001,0.0001,0.00001,0.000001\n",
    "]\n",
    "ims_per_batchs = [\n",
    "    1,2,3,4,5,6,7,8,9,10\n",
    "]\n",
    "batch_size_per_images = [\n",
    "    8,16,32,64,128,256,512\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce211722-cd2a-4392-a22d-e769ae8c5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_LR = 0.00025\n",
    "MAX_ITER = 500\n",
    "EVAL_PERIOD = 500\n",
    "IMS_PER_BATCH = 2\n",
    "BATCH_SIZE_PER_IMAGE = 128\n",
    "SCORE_THRESH_TEST = 0.625\n",
    "model = f\"COCO-Detection/\" + \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b60993-b010-4f8b-a9cc-ce7ff377dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a2539e4-017c-4bbd-99bd-439f1712a127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mranuga-d\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2021-10-28 20:30:44.451795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ranuga-d/Find-Card/runs/1dqs4kie\" target=\"_blank\">test</a></strong> to <a href=\"https://wandb.ai/ranuga-d/Find-Card\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:30:54 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1853/1853 [01:52<00:00, 16.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:32:47 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1853 images left.\n",
      "\u001b[32m[10/28 20:32:47 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    Card    | 1853         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/28 20:32:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[10/28 20:32:47 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/28 20:32:47 d2.data.common]: \u001b[0mSerializing 1853 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/28 20:32:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-10-28 20:32:47.839812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:32:51 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/indika/Sync/anaconda3/envs/detectron2/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:33:12 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 19  total_loss: 1  loss_cls: 0.693  loss_box_reg: 0.2271  loss_rpn_cls: 0.05657  loss_rpn_loc: 0.009185  time: 0.9780  data_time: 0.0345  lr: 9.7405e-06  max_mem: 5664M\n",
      "\u001b[32m[10/28 20:33:33 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 39  total_loss: 1.019  loss_cls: 0.6176  loss_box_reg: 0.3415  loss_rpn_cls: 0.02472  loss_rpn_loc: 0.008081  time: 1.0285  data_time: 0.0026  lr: 1.9731e-05  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:33:54 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 59  total_loss: 0.818  loss_cls: 0.42  loss_box_reg: 0.3191  loss_rpn_cls: 0.02792  loss_rpn_loc: 0.007938  time: 1.0272  data_time: 0.0024  lr: 2.972e-05  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:34:15 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 79  total_loss: 0.757  loss_cls: 0.3468  loss_box_reg: 0.3653  loss_rpn_cls: 0.01293  loss_rpn_loc: 0.004778  time: 1.0383  data_time: 0.0024  lr: 3.9711e-05  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:34:35 d2.utils.events]: \u001b[0m eta: 0:06:34  iter: 99  total_loss: 0.7258  loss_cls: 0.3038  loss_box_reg: 0.3705  loss_rpn_cls: 0.03467  loss_rpn_loc: 0.008464  time: 1.0290  data_time: 0.0025  lr: 4.9701e-05  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:34:56 d2.utils.events]: \u001b[0m eta: 0:06:14  iter: 119  total_loss: 0.58  loss_cls: 0.2552  loss_box_reg: 0.2856  loss_rpn_cls: 0.03111  loss_rpn_loc: 0.004531  time: 1.0317  data_time: 0.0028  lr: 5.9691e-05  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:35:17 d2.utils.events]: \u001b[0m eta: 0:05:54  iter: 139  total_loss: 0.5809  loss_cls: 0.2429  loss_box_reg: 0.3057  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.01377  time: 1.0375  data_time: 0.0025  lr: 6.9681e-05  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:35:39 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 159  total_loss: 0.6457  loss_cls: 0.2468  loss_box_reg: 0.3148  loss_rpn_cls: 0.01726  loss_rpn_loc: 0.005631  time: 1.0453  data_time: 0.0024  lr: 7.9671e-05  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:36:01 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 179  total_loss: 0.5904  loss_cls: 0.2329  loss_box_reg: 0.3105  loss_rpn_cls: 0.01975  loss_rpn_loc: 0.005262  time: 1.0481  data_time: 0.0025  lr: 8.966e-05  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:36:22 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 199  total_loss: 0.6827  loss_cls: 0.2715  loss_box_reg: 0.3727  loss_rpn_cls: 0.02775  loss_rpn_loc: 0.006949  time: 1.0480  data_time: 0.0025  lr: 9.9651e-05  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:36:42 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 219  total_loss: 0.5566  loss_cls: 0.23  loss_box_reg: 0.3097  loss_rpn_cls: 0.03435  loss_rpn_loc: 0.008049  time: 1.0465  data_time: 0.0026  lr: 0.00010964  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:37:02 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 239  total_loss: 0.5715  loss_cls: 0.2155  loss_box_reg: 0.3557  loss_rpn_cls: 0.02275  loss_rpn_loc: 0.00753  time: 1.0421  data_time: 0.0025  lr: 0.00011963  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:37:26 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 259  total_loss: 0.5362  loss_cls: 0.2181  loss_box_reg: 0.3047  loss_rpn_cls: 0.02114  loss_rpn_loc: 0.007905  time: 1.0530  data_time: 0.0026  lr: 0.00012962  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:37:48 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 279  total_loss: 0.5082  loss_cls: 0.1807  loss_box_reg: 0.2998  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.008175  time: 1.0568  data_time: 0.0023  lr: 0.00013961  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:38:10 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 299  total_loss: 0.5698  loss_cls: 0.2116  loss_box_reg: 0.2864  loss_rpn_cls: 0.02279  loss_rpn_loc: 0.007902  time: 1.0602  data_time: 0.0023  lr: 0.0001496  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:38:34 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 319  total_loss: 0.6299  loss_cls: 0.219  loss_box_reg: 0.3419  loss_rpn_cls: 0.0178  loss_rpn_loc: 0.004595  time: 1.0674  data_time: 0.0024  lr: 0.00015959  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:38:55 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 339  total_loss: 0.4812  loss_cls: 0.1944  loss_box_reg: 0.2411  loss_rpn_cls: 0.02838  loss_rpn_loc: 0.006749  time: 1.0662  data_time: 0.0024  lr: 0.00016958  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:39:18 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 359  total_loss: 0.5638  loss_cls: 0.2142  loss_box_reg: 0.2864  loss_rpn_cls: 0.01874  loss_rpn_loc: 0.004861  time: 1.0730  data_time: 0.0023  lr: 0.00017957  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:39:40 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 379  total_loss: 0.5997  loss_cls: 0.2111  loss_box_reg: 0.3691  loss_rpn_cls: 0.02749  loss_rpn_loc: 0.006363  time: 1.0724  data_time: 0.0024  lr: 0.00018956  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:40:01 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 399  total_loss: 0.5594  loss_cls: 0.2119  loss_box_reg: 0.3096  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.004292  time: 1.0719  data_time: 0.0022  lr: 0.00019955  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:40:20 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 419  total_loss: 0.5899  loss_cls: 0.2128  loss_box_reg: 0.3293  loss_rpn_cls: 0.02035  loss_rpn_loc: 0.006844  time: 1.0667  data_time: 0.0024  lr: 0.00020954  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:40:42 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 439  total_loss: 0.5074  loss_cls: 0.2042  loss_box_reg: 0.2571  loss_rpn_cls: 0.02129  loss_rpn_loc: 0.01155  time: 1.0688  data_time: 0.0024  lr: 0.00021953  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:41:03 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 459  total_loss: 0.4847  loss_cls: 0.1968  loss_box_reg: 0.2778  loss_rpn_cls: 0.01705  loss_rpn_loc: 0.004741  time: 1.0676  data_time: 0.0024  lr: 0.00022952  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:41:26 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 479  total_loss: 0.4642  loss_cls: 0.1947  loss_box_reg: 0.2253  loss_rpn_cls: 0.03734  loss_rpn_loc: 0.007803  time: 1.0706  data_time: 0.0025  lr: 0.00023951  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:41:49 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.539  loss_cls: 0.2126  loss_box_reg: 0.2656  loss_rpn_cls: 0.01522  loss_rpn_loc: 0.005525  time: 1.0734  data_time: 0.0024  lr: 0.0002495  max_mem: 6046M\n",
      "\u001b[32m[10/28 20:41:49 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:08:54 (1.0734 s / it)\n",
      "\u001b[32m[10/28 20:41:49 d2.engine.hooks]: \u001b[0mTotal training time: 0:08:55 (0:00:00 on hooks)\n",
      "\u001b[32m[10/28 20:41:52 d2.evaluation.coco_evaluation]: \u001b[0m'test' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
      "\u001b[32m[10/28 20:41:52 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'test' to COCO format ...)\n",
      "325\n",
      "\u001b[32m[10/28 20:41:52 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[10/28 20:41:52 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 325, #annotations: 325\n",
      "\u001b[32m[10/28 20:41:52 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/test_coco_format.json' ...\n",
      "325\n",
      "\u001b[32m[10/28 20:41:52 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    Card    | 325          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/28 20:41:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/28 20:41:52 d2.data.common]: \u001b[0mSerializing 325 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/28 20:41:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[32m[10/28 20:41:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 325 batches\n",
      "\u001b[32m[10/28 20:41:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/325. Dataloading: 0.0064 s/iter. Inference: 0.1780 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:00:57\n",
      "\u001b[32m[10/28 20:42:00 d2.evaluation.evaluator]: \u001b[0mInference done 39/325. Dataloading: 0.0018 s/iter. Inference: 0.1813 s/iter. Eval: 0.0001 s/iter. Total: 0.1833 s/iter. ETA=0:00:52\n",
      "\u001b[32m[10/28 20:42:05 d2.evaluation.evaluator]: \u001b[0mInference done 67/325. Dataloading: 0.0014 s/iter. Inference: 0.1811 s/iter. Eval: 0.0001 s/iter. Total: 0.1827 s/iter. ETA=0:00:47\n",
      "\u001b[32m[10/28 20:42:10 d2.evaluation.evaluator]: \u001b[0mInference done 94/325. Dataloading: 0.0013 s/iter. Inference: 0.1821 s/iter. Eval: 0.0001 s/iter. Total: 0.1835 s/iter. ETA=0:00:42\n",
      "\u001b[32m[10/28 20:42:15 d2.evaluation.evaluator]: \u001b[0mInference done 122/325. Dataloading: 0.0019 s/iter. Inference: 0.1804 s/iter. Eval: 0.0001 s/iter. Total: 0.1825 s/iter. ETA=0:00:37\n",
      "\u001b[32m[10/28 20:42:20 d2.evaluation.evaluator]: \u001b[0mInference done 149/325. Dataloading: 0.0034 s/iter. Inference: 0.1805 s/iter. Eval: 0.0001 s/iter. Total: 0.1840 s/iter. ETA=0:00:32\n",
      "\u001b[32m[10/28 20:42:25 d2.evaluation.evaluator]: \u001b[0mInference done 178/325. Dataloading: 0.0030 s/iter. Inference: 0.1792 s/iter. Eval: 0.0001 s/iter. Total: 0.1824 s/iter. ETA=0:00:26\n",
      "\u001b[32m[10/28 20:42:30 d2.evaluation.evaluator]: \u001b[0mInference done 203/325. Dataloading: 0.0052 s/iter. Inference: 0.1793 s/iter. Eval: 0.0001 s/iter. Total: 0.1847 s/iter. ETA=0:00:22\n",
      "\u001b[32m[10/28 20:42:35 d2.evaluation.evaluator]: \u001b[0mInference done 230/325. Dataloading: 0.0047 s/iter. Inference: 0.1804 s/iter. Eval: 0.0001 s/iter. Total: 0.1852 s/iter. ETA=0:00:17\n",
      "\u001b[32m[10/28 20:42:40 d2.evaluation.evaluator]: \u001b[0mInference done 257/325. Dataloading: 0.0051 s/iter. Inference: 0.1802 s/iter. Eval: 0.0001 s/iter. Total: 0.1854 s/iter. ETA=0:00:12\n",
      "\u001b[32m[10/28 20:42:45 d2.evaluation.evaluator]: \u001b[0mInference done 286/325. Dataloading: 0.0047 s/iter. Inference: 0.1798 s/iter. Eval: 0.0001 s/iter. Total: 0.1846 s/iter. ETA=0:00:07\n",
      "\u001b[32m[10/28 20:42:50 d2.evaluation.evaluator]: \u001b[0mInference done 314/325. Dataloading: 0.0044 s/iter. Inference: 0.1796 s/iter. Eval: 0.0001 s/iter. Total: 0.1842 s/iter. ETA=0:00:02\n",
      "\u001b[32m[10/28 20:42:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:58.916088 (0.184113 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/28 20:42:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:57 (0.179219 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/28 20:42:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/28 20:42:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[10/28 20:42:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/28 20:42:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/28 20:42:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/28 20:42:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/28 20:42:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.060\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.114\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.276\n",
      "\u001b[32m[10/28 20:42:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 10.239 | 14.740 | 11.678 | 0.000 | 5.971 | 11.360 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 26/26 [00:00<00:00, 2940.51it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_559010/115025483.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./test_imgs/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./test_imgs/{img}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     v = v.draw_instance_predictions(\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "files_to_remove = os.listdir(\"./output/\")\n",
    "for file_to_remove in files_to_remove:\n",
    "    os.remove(f\"./output/{file_to_remove}\")\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "torch.cuda.empty_cache()\n",
    "wandb.init(project=\"Find-Card\", name=NAME,config={\n",
    "    'BASE_LR':BASE_LR,\n",
    "    'MAX_ITER':MAX_ITER,\n",
    "    'EVAL_PERIOD':EVAL_PERIOD,\n",
    "    'IMS_PER_BATCH':IMS_PER_BATCH,\n",
    "    'BATCH_SIZE_PER_IMAGE':BATCH_SIZE_PER_IMAGE,\n",
    "    'SCORE_THRESH_TEST':SCORE_THRESH_TEST,\n",
    "    'MODEL':model,\n",
    "    'NAME':NAME\n",
    "})\n",
    "torch.cuda.empty_cache()\n",
    "cfg = get_cfg()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
    "torch.cuda.empty_cache()\n",
    "cfg.DATASETS.TRAIN = (\"data\",)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.DATASETS.TEST = ()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "torch.cuda.empty_cache()\n",
    "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "cfg.SOLVER.BASE_LR = BASE_LR\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.STEPS = []\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = BATCH_SIZE_PER_IMAGE\n",
    "torch.cuda.empty_cache()\n",
    "trainer = DefaultTrainer(cfg)\n",
    "torch.cuda.empty_cache()\n",
    "trainer.resume_or_load(resume=False)\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "torch.cuda.empty_cache()\n",
    "predictor = DefaultPredictor(cfg)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"\n",
    "cfg.SOLVER.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"test\", output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"test\")\n",
    "metrics = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "wandb.log(metrics)\n",
    "torch.cuda.empty_cache()\n",
    "logs = open(\"./output/metrics.json\", \"r\").read().split(\"\\n\")\n",
    "for log in tqdm(range(len(logs))):\n",
    "    try:\n",
    "        res = ast.literal_eval(logs[log])\n",
    "        wandb.log(res)\n",
    "    except:\n",
    "        pass\n",
    "for img in os.listdir(\"./test_imgs/\"):\n",
    "    torch.cuda.empty_cache()\n",
    "    v = Visualizer(cv2.imread(f\"./test_imgs/{img}\")[:, :, ::-1], metadata=metadata)\n",
    "    torch.cuda.empty_cache()\n",
    "    v = v.draw_instance_predictions(\n",
    "        predictor(cv2.imread(f\"./test_imgs/{img}\"))[\"instances\"].to(\"cpu\")\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    v = v.get_image()[:, :, ::-1]\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.imshow(v)\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.savefig(f\"./preds/{img}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.close()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({f\"Img/{img}\": wandb.Image(cv2.imread(f\"./preds/{img}\"))})\n",
    "info = data.iloc[589]\n",
    "img = cv2.imread(\"./download/Img/\" + info[\"Path\"])\n",
    "height, width = cv2.imread(\"./download/Img/\" + info[\"Path\"]).shape[:2]\n",
    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "xmin = round(xmin * width)\n",
    "xmax = round(xmax * width)\n",
    "ymin = round(ymin * height)\n",
    "ymax = round(ymax * height)\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "preds = predictor(img)\n",
    "target = torch.tensor([xmin, ymin, xmax, ymax])\n",
    "lowest_rmse = 0\n",
    "r_mean_squared_error = MeanSquaredError(squared=False)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if r_mean_squared_error(pred.to(\"cpu\"), target) > lowest_rmse:\n",
    "        lowest_rmse = r_mean_squared_error(pred.to(\"cpu\"), target)\n",
    "lowest_mse = 0\n",
    "mean_squared_error = MeanSquaredError(squared=True)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if mean_squared_error(pred.to(\"cpu\"), target) > lowest_mse:\n",
    "        lowest_mse = mean_squared_error(pred.to(\"cpu\"), target)\n",
    "wandb.log({\"MSE\": lowest_mse})\n",
    "wandb.log({\"RMSE\": lowest_rmse})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24e0a3-96fa-424f-9741-a188f5f96532",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cfg,f'./models/cfg-{NAME}.pt')\n",
    "torch.save(cfg,f'./models/cfg-{NAME}.pth')\n",
    "torch.save(predictor,f'./models/predictor-{NAME}.pt')\n",
    "torch.save(predictor,f'./models/predictor-{NAME}.pth')\n",
    "torch.save(evaluator,f'./models/evaluator-{NAME}.pt')\n",
    "torch.save(evaluator,f'./models/evaluator-{NAME}.pth')\n",
    "torch.save(model,f'./models/model-{NAME}.pt')\n",
    "torch.save(model,f'./models/model-{NAME}.pth')\n",
    "torch.save(labels,f'./models/labels-{NAME}.pt')\n",
    "torch.save(labels,f'./models/labels-{NAME}.pth')\n",
    "torch.save(metrics,f'./models/metrics-{NAME}.pt')\n",
    "torch.save(metrics,f'./models/metrics-{NAME}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76b61b-ac9c-418f-8462-6b1deee60162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('detectron2': conda)",
   "language": "python",
   "name": "python3812jvsc74a57bd0585e9a5027b519a27e411109b09a66bc779a1bba36bd86b08fdb64645f8a2c5a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
