{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05913d59-e9de-41ee-8ef4-ffc288015942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "import torch, torchvision\n",
    "import detectron2\n",
    "import json\n",
    "import ast \n",
    "import tensorboard,os\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from tqdm import tqdm\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f77166-567f-4e53-87a4-bebed5fcf8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_remove = os.listdir('./output/')\n",
    "files_to_remove.remove('metrics.json')\n",
    "for file_to_remove in files_to_remove:\n",
    "    os.remove(f'./output/{file_to_remove}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886fa83a-c439-4554-8d17-777cee97dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Data.csv\").sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f392a7f-893b-4b55-af75-1a5987b1e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = data.iloc[59]\n",
    "img = cv2.imread(f'./Img/{info[\"Path\"]}')\n",
    "height, width = cv2.imread(\"./Img/\" + info[\"Path\"]).shape[:2]\n",
    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "xmin = round(xmin * width)\n",
    "xmax = round(xmax * width)\n",
    "ymin = round(ymin * height)\n",
    "ymax = round(ymax * height)\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "x,y,w,h = round(x),round(y),round(w),round(h)\n",
    "cv2.imwrite('./output.png',img)\n",
    "roi=img[y:y+h,x:x+w]\n",
    "cv2.imwrite(str('crop') + '.jpg', roi)\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),10)\n",
    "cv2.imwrite(str('box') + '.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17e1f90-c8b5-432e-be3a-df122a2fb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "def load_data(data=data, test=False):\n",
    "    if test is True:\n",
    "        if \"data.npy\" in os.listdir(\"./\"):\n",
    "            data = np.load(\"./data.npy\", allow_pickle=True)\n",
    "            data = data[:325]\n",
    "            print(len(data))\n",
    "            return data\n",
    "    if \"data.npy\" in os.listdir(\"./\"):\n",
    "        data = np.load(\"./data.npy\", allow_pickle=True)\n",
    "        print(len(data))\n",
    "        return data\n",
    "    new_data = []\n",
    "    for idx in tqdm(range(len(data))):\n",
    "        record = {}\n",
    "        info = data.iloc[idx]\n",
    "        height, width = cv2.imread(\"./Img/\" + info[\"Path\"]).shape[:2]\n",
    "        xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "        xmin = round(xmin * width)\n",
    "        xmax = round(xmax * width)\n",
    "        ymin = round(ymin * height)\n",
    "        ymax = round(ymax * height)\n",
    "        record[\"file_name\"] = \"./Img/\" + info[\"Path\"]\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        record[\"cateogry_id\"] = 1\n",
    "        objs = [\n",
    "            {\n",
    "                \"bbox\": [xmin,ymin,xmax,ymax],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"category_id\": 1,\n",
    "            }\n",
    "        ]\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"annotations\"] = objs\n",
    "        new_data.append(record)\n",
    "    np.random.shuffle(new_data)\n",
    "#     np.save(\"data.npy\", new_data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92183d-6ced-44ec-9586-ed3ce8ce9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "labels = [\"Card\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de01b6ab-0060-4988-bea8-90145f494d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the data\n",
    "DatasetCatalog.register(\"data\", lambda: load_data())\n",
    "MetadataCatalog.get(\"data\").set(thing_classes=labels)\n",
    "metadata = MetadataCatalog.get(\"data\")\n",
    "DatasetCatalog.register(\"test\", lambda: load_data(test=True))\n",
    "MetadataCatalog.get(\"test\").set(thing_classes=labels)\n",
    "metadata_test = MetadataCatalog.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa0905-7359-47bb-82d1-7e46e01e98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"fast_rcnn_R_50_FPN_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_C4_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_C4_3x.yaml\",\n",
    "    \"faster_rcnn_R_50_DC5_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_DC5_3x.yaml\",\n",
    "    \"retinanet_R_50_FPN_1x.py\",\n",
    "    \"retinanet_R_50_FPN_1x.yaml\",\n",
    "    \"retinanet_R_50_FPN_3x.yaml\",\n",
    "    \"rpn_R_50_C4_1x.yaml\",\n",
    "    \"rpn_R_50_FPN_1x.yaml\"\n",
    "    \"faster_rcnn_R_50_FPN_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_FPN_3x.yaml\",\n",
    "    \"faster_rcnn_R_101_DC5_3x.yaml\",\n",
    "    \"faster_rcnn_R_101_FPN_3x.yaml\",\n",
    "    \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
    "]\n",
    "max_iters = [\n",
    "    50,100,125,250,500,1000,2000,2500,5000\n",
    "]\n",
    "base_lrs = [0.1,0.01,0.001,0.0001,0.00001,0.000001]\n",
    "ims_per_batchs = [1,2,3,4,5,6,7,8,9,10]\n",
    "batch_size_per_images = [8,16,32,64,128,256,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce211722-cd2a-4392-a22d-e769ae8c5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_LR = 0.00025\n",
    "MAX_ITER = 500\n",
    "EVAL_PERIOD = 500\n",
    "IMS_PER_BATCH = 2\n",
    "BATCH_SIZE_PER_IMAGE = 128\n",
    "SCORE_THRESH_TEST = 0.625\n",
    "model = f\"COCO-Detection/\" + \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b60993-b010-4f8b-a9cc-ce7ff377dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2539e4-017c-4bbd-99bd-439f1712a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_remove = os.listdir(\"./output/\")\n",
    "for file_to_remove in files_to_remove:\n",
    "    os.remove(f\"./output/{file_to_remove}\")\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "torch.cuda.empty_cache()\n",
    "wandb.init(project=\"Find-Card\", name=NAME,config={\n",
    "    'BASE_LR':BASE_LR,\n",
    "    'MAX_ITER':MAX_ITER,\n",
    "    'EVAL_PERIOD':EVAL_PERIOD,\n",
    "    'IMS_PER_BATCH':IMS_PER_BATCH,\n",
    "    'BATCH_SIZE_PER_IMAGE':BATCH_SIZE_PER_IMAGE,\n",
    "    'SCORE_THRESH_TEST':SCORE_THRESH_TEST,\n",
    "    'MODEL':model\n",
    "    'NAME':NAME\n",
    "})\n",
    "torch.cuda.empty_cache()\n",
    "cfg = get_cfg()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
    "torch.cuda.empty_cache()\n",
    "cfg.DATASETS.TRAIN = (\"data\",)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.DATASETS.TEST = ()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "torch.cuda.empty_cache()\n",
    "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "cfg.SOLVER.BASE_LR = BASE_LR\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.STEPS = []\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = BATCH_SIZE_PER_IMAGE\n",
    "torch.cuda.empty_cache()\n",
    "trainer = DefaultTrainer(cfg)\n",
    "torch.cuda.empty_cache()\n",
    "trainer.resume_or_load(resume=False)\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "torch.cuda.empty_cache()\n",
    "predictor = DefaultPredictor(cfg)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"\n",
    "cfg.SOLVER.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"test\", output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"test\")\n",
    "metrics = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "wandb.log(metrics)\n",
    "torch.cuda.empty_cache()\n",
    "logs = open(\"./output/metrics.json\", \"r\").read().split(\"\\n\")\n",
    "for log in tqdm(range(len(logs))):\n",
    "    try:\n",
    "        res = ast.literal_eval(logs[log])\n",
    "        wandb.log(res)\n",
    "    except:\n",
    "        pass\n",
    "for img in os.listdir(\"./test_imgs/\"):\n",
    "    torch.cuda.empty_cache()\n",
    "    v = Visualizer(cv2.imread(f\"./test_imgs/{img}\")[:, :, ::-1], metadata=metadata)\n",
    "    torch.cuda.empty_cache()\n",
    "    v = v.draw_instance_predictions(\n",
    "        predictor(cv2.imread(f\"./test_imgs/{img}\"))[\"instances\"].to(\"cpu\")\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    v = v.get_image()[:, :, ::-1]\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.imshow(v)\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.savefig(f\"./preds/{img}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.close()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({f\"Img/{img}\": wandb.Image(cv2.imread(f\"./preds/{img}\"))})\n",
    "info = data.iloc[589]\n",
    "img = cv2.imread(\"./download/Img/\" + info[\"Path\"])\n",
    "height, width = cv2.imread(\"./download/Img/\" + info[\"Path\"]).shape[:2]\n",
    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "xmin = round(xmin * width)\n",
    "xmax = round(xmax * width)\n",
    "ymin = round(ymin * height)\n",
    "ymax = round(ymax * height)\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "preds = predictor(img)\n",
    "target = torch.tensor([xmin, ymin, xmax, ymax])\n",
    "lowest_rmse = 0\n",
    "r_mean_squared_error = MeanSquaredError(squared=False)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if r_mean_squared_error(pred.to(\"cpu\"), target) > lowest_rmse:\n",
    "        lowest_rmse = r_mean_squared_error(pred.to(\"cpu\"), target)\n",
    "lowest_mse = 0\n",
    "mean_squared_error = MeanSquaredError(squared=True)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if mean_squared_error(pred.to(\"cpu\"), target) > lowest_mse:\n",
    "        lowest_mse = mean_squared_error(pred.to(\"cpu\"), target)\n",
    "wandb.log({\"MSE\": lowest_mse})\n",
    "wandb.log({\"RMSE\": lowest_rmse})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24e0a3-96fa-424f-9741-a188f5f96532",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cfg,f'./models/cfg-{NAME}.pt')\n",
    "torch.save(cfg,f'./models/cfg.pth')\n",
    "torch.save(predictor,f'./models/predictor.pt')\n",
    "torch.save(predictor,f'./models/predictor.pth')\n",
    "torch.save(evaluator,f'./models/evaluator.pt')\n",
    "torch.save(evaluator,f'./models/evaluator.pth')\n",
    "torch.save(model,f'./models/model.pt')\n",
    "torch.save(model,f'./models/model.pth')\n",
    "torch.save(labels,f'./models/labels.pt')\n",
    "torch.save(labels,f'./models/labels.pth')\n",
    "torch.save(metrics,f'./models/metrics.pt')\n",
    "torch.save(metrics,f'./models/metrics.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76b61b-ac9c-418f-8462-6b1deee60162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('detectron2': conda)",
   "language": "python",
   "name": "python3812jvsc74a57bd0585e9a5027b519a27e411109b09a66bc779a1bba36bd86b08fdb64645f8a2c5a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
