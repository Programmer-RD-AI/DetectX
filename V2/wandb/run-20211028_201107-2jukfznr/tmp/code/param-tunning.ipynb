{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05913d59-e9de-41ee-8ef4-ffc288015942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "import torch, torchvision\n",
    "import detectron2\n",
    "import json\n",
    "import ast \n",
    "import tensorboard,os\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from tqdm import tqdm\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f77166-567f-4e53-87a4-bebed5fcf8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_remove = os.listdir('./output/')\n",
    "files_to_remove.remove('metrics.json')\n",
    "for file_to_remove in files_to_remove:\n",
    "    os.remove(f'./output/{file_to_remove}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886fa83a-c439-4554-8d17-777cee97dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Data.csv\").sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f392a7f-893b-4b55-af75-1a5987b1e741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = data.iloc[59]\n",
    "img = cv2.imread(f'./Img/{info[\"Path\"]}')\n",
    "height, width = cv2.imread(\"./Img/\" + info[\"Path\"]).shape[:2]\n",
    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "xmin = round(xmin * width)\n",
    "xmax = round(xmax * width)\n",
    "ymin = round(ymin * height)\n",
    "ymax = round(ymax * height)\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "x,y,w,h = round(x),round(y),round(w),round(h)\n",
    "cv2.imwrite('./output.png',img)\n",
    "roi=img[y:y+h,x:x+w]\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b17e1f90-c8b5-432e-be3a-df122a2fb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "def load_data(data=data, test=False):\n",
    "    if test is True:\n",
    "        if \"data.npy\" in os.listdir(\"./\"):\n",
    "            data = np.load(\"./data.npy\", allow_pickle=True)\n",
    "            data = data[:325]\n",
    "            print(len(data))\n",
    "            return data\n",
    "    if \"data.npy\" in os.listdir(\"./\"):\n",
    "        data = np.load(\"./data.npy\", allow_pickle=True)\n",
    "        print(len(data))\n",
    "        return data\n",
    "    new_data = []\n",
    "    for idx in tqdm(range(len(data))):\n",
    "        record = {}\n",
    "        info = data.iloc[idx]\n",
    "        height, width = cv2.imread(\"./Img/\" + info[\"Path\"]).shape[:2]\n",
    "        xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "        xmin = round(xmin * width)\n",
    "        xmax = round(xmax * width)\n",
    "        ymin = round(ymin * height)\n",
    "        ymax = round(ymax * height)\n",
    "        record[\"file_name\"] = \"./Img/\" + info[\"Path\"]\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        objs = [\n",
    "            {\n",
    "                \"bbox\": [xmin,ymin,xmax,ymax],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"category_id\": 0,\n",
    "            }\n",
    "        ]\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"annotations\"] = objs\n",
    "        new_data.append(record)\n",
    "    np.random.shuffle(new_data)\n",
    "#     np.save(\"data.npy\", new_data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb92183d-6ced-44ec-9586-ed3ce8ce9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "labels = [\"Card\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de01b6ab-0060-4988-bea8-90145f494d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the data\n",
    "DatasetCatalog.register(\"data\", lambda: load_data())\n",
    "MetadataCatalog.get(\"data\").set(thing_classes=labels)\n",
    "metadata = MetadataCatalog.get(\"data\")\n",
    "DatasetCatalog.register(\"test\", lambda: load_data(test=True))\n",
    "MetadataCatalog.get(\"test\").set(thing_classes=labels)\n",
    "metadata_test = MetadataCatalog.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6fa0905-7359-47bb-82d1-7e46e01e98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"fast_rcnn_R_50_FPN_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_C4_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_C4_3x.yaml\",\n",
    "    \"faster_rcnn_R_50_DC5_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_DC5_3x.yaml\",\n",
    "    \"retinanet_R_50_FPN_1x.py\",\n",
    "    \"retinanet_R_50_FPN_1x.yaml\",\n",
    "    \"retinanet_R_50_FPN_3x.yaml\",\n",
    "    \"rpn_R_50_C4_1x.yaml\",\n",
    "    \"rpn_R_50_FPN_1x.yaml\"\n",
    "    \"faster_rcnn_R_50_FPN_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_FPN_3x.yaml\",\n",
    "    \"faster_rcnn_R_101_DC5_3x.yaml\",\n",
    "    \"faster_rcnn_R_101_FPN_3x.yaml\",\n",
    "    \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
    "]\n",
    "max_iters = [\n",
    "    50,100,125,250,500,1000,2000,2500,5000\n",
    "]\n",
    "base_lrs = [\n",
    "    0.1,0.01,0.001,0.0001,0.00001,0.000001\n",
    "]\n",
    "ims_per_batchs = [\n",
    "    1,2,3,4,5,6,7,8,9,10\n",
    "]\n",
    "batch_size_per_images = [\n",
    "    8,16,32,64,128,256,512\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce211722-cd2a-4392-a22d-e769ae8c5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_LR = 0.00025\n",
    "MAX_ITER = 500\n",
    "EVAL_PERIOD = 500\n",
    "IMS_PER_BATCH = 2\n",
    "BATCH_SIZE_PER_IMAGE = 16\n",
    "SCORE_THRESH_TEST = 0.625\n",
    "model = f\"COCO-Detection/\" + \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b60993-b010-4f8b-a9cc-ce7ff377dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2539e4-017c-4bbd-99bd-439f1712a127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mranuga-d\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2021-10-28 20:11:09.084698: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ranuga-d/Find-Card/runs/2jukfznr\" target=\"_blank\">test</a></strong> to <a href=\"https://wandb.ai/ranuga-d/Find-Card\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:11:17 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1853/1853 [01:51<00:00, 16.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:13:09 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1853 images left.\n",
      "\u001b[32m[10/28 20:13:09 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    Card    | 1853         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/28 20:13:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[10/28 20:13:09 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/28 20:13:09 d2.data.common]: \u001b[0mSerializing 1853 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/28 20:13:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-10-28 20:13:09.678164: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:13:13 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/indika/Sync/anaconda3/envs/detectron2/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:13:36 d2.utils.events]: \u001b[0m eta: 0:08:28  iter: 19  total_loss: 1.535  loss_cls: 0.6501  loss_box_reg: 0.8407  loss_rpn_cls: 0.03065  loss_rpn_loc: 0.005025  time: 1.1147  data_time: 0.0259  lr: 9.7405e-06  max_mem: 5849M\n",
      "\u001b[32m[10/28 20:13:59 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 39  total_loss: 1.463  loss_cls: 0.6092  loss_box_reg: 0.805  loss_rpn_cls: 0.01963  loss_rpn_loc: 0.008261  time: 1.1189  data_time: 0.0026  lr: 1.9731e-05  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:14:23 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 59  total_loss: 1.436  loss_cls: 0.5518  loss_box_reg: 0.8227  loss_rpn_cls: 0.02975  loss_rpn_loc: 0.006296  time: 1.1418  data_time: 0.0025  lr: 2.972e-05  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:14:43 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 79  total_loss: 1.426  loss_cls: 0.5197  loss_box_reg: 0.8356  loss_rpn_cls: 0.01727  loss_rpn_loc: 0.006172  time: 1.1054  data_time: 0.0027  lr: 3.9711e-05  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:15:02 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 99  total_loss: 1.374  loss_cls: 0.4657  loss_box_reg: 0.83  loss_rpn_cls: 0.03329  loss_rpn_loc: 0.007208  time: 1.0783  data_time: 0.0028  lr: 4.9701e-05  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:15:24 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 119  total_loss: 1.321  loss_cls: 0.4515  loss_box_reg: 0.7493  loss_rpn_cls: 0.03836  loss_rpn_loc: 0.006119  time: 1.0781  data_time: 0.0024  lr: 5.9691e-05  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:15:48 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 139  total_loss: 1.286  loss_cls: 0.4533  loss_box_reg: 0.7835  loss_rpn_cls: 0.04044  loss_rpn_loc: 0.007496  time: 1.0952  data_time: 0.0027  lr: 6.9681e-05  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:16:09 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 159  total_loss: 1.152  loss_cls: 0.4271  loss_box_reg: 0.6855  loss_rpn_cls: 0.01476  loss_rpn_loc: 0.006112  time: 1.0946  data_time: 0.0023  lr: 7.9671e-05  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:16:30 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 179  total_loss: 1.232  loss_cls: 0.4401  loss_box_reg: 0.7665  loss_rpn_cls: 0.02903  loss_rpn_loc: 0.006973  time: 1.0887  data_time: 0.0025  lr: 8.966e-05  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:16:53 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 199  total_loss: 1.267  loss_cls: 0.3896  loss_box_reg: 0.8387  loss_rpn_cls: 0.01676  loss_rpn_loc: 0.008994  time: 1.0919  data_time: 0.0025  lr: 9.9651e-05  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:17:15 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 219  total_loss: 1.286  loss_cls: 0.4225  loss_box_reg: 0.7659  loss_rpn_cls: 0.02721  loss_rpn_loc: 0.004732  time: 1.0944  data_time: 0.0026  lr: 0.00010964  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:17:37 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 239  total_loss: 1.17  loss_cls: 0.4279  loss_box_reg: 0.5677  loss_rpn_cls: 0.04804  loss_rpn_loc: 0.00845  time: 1.0960  data_time: 0.0025  lr: 0.00011963  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:18:00 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 259  total_loss: 1.09  loss_cls: 0.3451  loss_box_reg: 0.7291  loss_rpn_cls: 0.01593  loss_rpn_loc: 0.005633  time: 1.0991  data_time: 0.0025  lr: 0.00012962  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:18:22 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 279  total_loss: 1.226  loss_cls: 0.3738  loss_box_reg: 0.7748  loss_rpn_cls: 0.01202  loss_rpn_loc: 0.007309  time: 1.0988  data_time: 0.0024  lr: 0.00013961  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:18:45 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 299  total_loss: 1.166  loss_cls: 0.3772  loss_box_reg: 0.7213  loss_rpn_cls: 0.02017  loss_rpn_loc: 0.008634  time: 1.1035  data_time: 0.0023  lr: 0.0001496  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:19:07 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 319  total_loss: 1.142  loss_cls: 0.397  loss_box_reg: 0.7092  loss_rpn_cls: 0.02757  loss_rpn_loc: 0.007529  time: 1.1032  data_time: 0.0024  lr: 0.00015959  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:19:30 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 339  total_loss: 1.154  loss_cls: 0.345  loss_box_reg: 0.7614  loss_rpn_cls: 0.009385  loss_rpn_loc: 0.009088  time: 1.1041  data_time: 0.0024  lr: 0.00016958  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:19:51 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 359  total_loss: 0.9966  loss_cls: 0.3399  loss_box_reg: 0.5781  loss_rpn_cls: 0.02267  loss_rpn_loc: 0.007779  time: 1.1014  data_time: 0.0025  lr: 0.00017957  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:20:15 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 379  total_loss: 0.9412  loss_cls: 0.3625  loss_box_reg: 0.574  loss_rpn_cls: 0.01593  loss_rpn_loc: 0.008482  time: 1.1059  data_time: 0.0027  lr: 0.00018956  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:20:35 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 399  total_loss: 0.9219  loss_cls: 0.3092  loss_box_reg: 0.6028  loss_rpn_cls: 0.02741  loss_rpn_loc: 0.009134  time: 1.1016  data_time: 0.0026  lr: 0.00019955  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:20:58 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 419  total_loss: 0.8224  loss_cls: 0.3272  loss_box_reg: 0.4508  loss_rpn_cls: 0.01638  loss_rpn_loc: 0.009789  time: 1.1047  data_time: 0.0024  lr: 0.00020954  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:21:21 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 439  total_loss: 0.814  loss_cls: 0.2779  loss_box_reg: 0.5318  loss_rpn_cls: 0.01625  loss_rpn_loc: 0.005275  time: 1.1056  data_time: 0.0027  lr: 0.00021953  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:21:43 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 459  total_loss: 0.8332  loss_cls: 0.257  loss_box_reg: 0.5001  loss_rpn_cls: 0.01703  loss_rpn_loc: 0.004427  time: 1.1059  data_time: 0.0026  lr: 0.00022952  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:22:07 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 479  total_loss: 0.8354  loss_cls: 0.3279  loss_box_reg: 0.4915  loss_rpn_cls: 0.02325  loss_rpn_loc: 0.005287  time: 1.1100  data_time: 0.0023  lr: 0.00023951  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:22:30 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.8985  loss_cls: 0.3209  loss_box_reg: 0.5977  loss_rpn_cls: 0.02255  loss_rpn_loc: 0.006047  time: 1.1102  data_time: 0.0025  lr: 0.0002495  max_mem: 6042M\n",
      "\u001b[32m[10/28 20:22:30 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:09:12 (1.1102 s / it)\n",
      "\u001b[32m[10/28 20:22:30 d2.engine.hooks]: \u001b[0mTotal training time: 0:09:13 (0:00:00 on hooks)\n",
      "\u001b[32m[10/28 20:22:32 d2.evaluation.coco_evaluation]: \u001b[0m'test' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
      "\u001b[32m[10/28 20:22:32 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'test' to COCO format ...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1853/1853 [01:53<00:00, 16.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:24:26 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:24:26 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 1853, #annotations: 1853\n",
      "\u001b[32m[10/28 20:24:26 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/test_coco_format.json' ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1853/1853 [01:52<00:00, 16.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:26:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/28 20:26:19 d2.data.common]: \u001b[0mSerializing 1853 elements to byte tensors and concatenating them all ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/28 20:26:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/28 20:26:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 1853 batches\n",
      "\u001b[32m[10/28 20:26:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/1853. Dataloading: 0.0006 s/iter. Inference: 0.1486 s/iter. Eval: 0.0001 s/iter. Total: 0.1494 s/iter. ETA=0:04:35\n",
      "\u001b[32m[10/28 20:26:27 d2.evaluation.evaluator]: \u001b[0mInference done 39/1853. Dataloading: 0.0013 s/iter. Inference: 0.1747 s/iter. Eval: 0.0001 s/iter. Total: 0.1763 s/iter. ETA=0:05:19\n",
      "\u001b[32m[10/28 20:26:32 d2.evaluation.evaluator]: \u001b[0mInference done 66/1853. Dataloading: 0.0024 s/iter. Inference: 0.1808 s/iter. Eval: 0.0001 s/iter. Total: 0.1834 s/iter. ETA=0:05:27\n",
      "\u001b[32m[10/28 20:26:37 d2.evaluation.evaluator]: \u001b[0mInference done 94/1853. Dataloading: 0.0048 s/iter. Inference: 0.1776 s/iter. Eval: 0.0001 s/iter. Total: 0.1826 s/iter. ETA=0:05:21\n",
      "\u001b[32m[10/28 20:26:42 d2.evaluation.evaluator]: \u001b[0mInference done 122/1853. Dataloading: 0.0038 s/iter. Inference: 0.1785 s/iter. Eval: 0.0001 s/iter. Total: 0.1826 s/iter. ETA=0:05:16\n",
      "\u001b[32m[10/28 20:26:47 d2.evaluation.evaluator]: \u001b[0mInference done 149/1853. Dataloading: 0.0043 s/iter. Inference: 0.1793 s/iter. Eval: 0.0001 s/iter. Total: 0.1839 s/iter. ETA=0:05:13\n",
      "\u001b[32m[10/28 20:26:52 d2.evaluation.evaluator]: \u001b[0mInference done 177/1853. Dataloading: 0.0038 s/iter. Inference: 0.1797 s/iter. Eval: 0.0001 s/iter. Total: 0.1837 s/iter. ETA=0:05:07\n",
      "\u001b[32m[10/28 20:26:57 d2.evaluation.evaluator]: \u001b[0mInference done 203/1853. Dataloading: 0.0057 s/iter. Inference: 0.1792 s/iter. Eval: 0.0001 s/iter. Total: 0.1851 s/iter. ETA=0:05:05\n",
      "\u001b[32m[10/28 20:27:03 d2.evaluation.evaluator]: \u001b[0mInference done 231/1853. Dataloading: 0.0051 s/iter. Inference: 0.1791 s/iter. Eval: 0.0001 s/iter. Total: 0.1844 s/iter. ETA=0:04:59\n",
      "\u001b[32m[10/28 20:27:08 d2.evaluation.evaluator]: \u001b[0mInference done 260/1853. Dataloading: 0.0046 s/iter. Inference: 0.1787 s/iter. Eval: 0.0001 s/iter. Total: 0.1836 s/iter. ETA=0:04:52\n",
      "\u001b[32m[10/28 20:27:13 d2.evaluation.evaluator]: \u001b[0mInference done 287/1853. Dataloading: 0.0043 s/iter. Inference: 0.1796 s/iter. Eval: 0.0001 s/iter. Total: 0.1840 s/iter. ETA=0:04:48\n",
      "\u001b[32m[10/28 20:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 315/1853. Dataloading: 0.0040 s/iter. Inference: 0.1799 s/iter. Eval: 0.0001 s/iter. Total: 0.1841 s/iter. ETA=0:04:43\n",
      "\u001b[32m[10/28 20:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 342/1853. Dataloading: 0.0037 s/iter. Inference: 0.1803 s/iter. Eval: 0.0001 s/iter. Total: 0.1842 s/iter. ETA=0:04:38\n",
      "\u001b[32m[10/28 20:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 369/1853. Dataloading: 0.0035 s/iter. Inference: 0.1809 s/iter. Eval: 0.0001 s/iter. Total: 0.1846 s/iter. ETA=0:04:33\n",
      "\u001b[32m[10/28 20:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 396/1853. Dataloading: 0.0033 s/iter. Inference: 0.1814 s/iter. Eval: 0.0001 s/iter. Total: 0.1850 s/iter. ETA=0:04:29\n",
      "\u001b[32m[10/28 20:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 424/1853. Dataloading: 0.0033 s/iter. Inference: 0.1812 s/iter. Eval: 0.0001 s/iter. Total: 0.1847 s/iter. ETA=0:04:23\n",
      "\u001b[32m[10/28 20:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 451/1853. Dataloading: 0.0036 s/iter. Inference: 0.1811 s/iter. Eval: 0.0001 s/iter. Total: 0.1849 s/iter. ETA=0:04:19\n",
      "\u001b[32m[10/28 20:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 479/1853. Dataloading: 0.0035 s/iter. Inference: 0.1810 s/iter. Eval: 0.0001 s/iter. Total: 0.1847 s/iter. ETA=0:04:13\n",
      "\u001b[32m[10/28 20:27:54 d2.evaluation.evaluator]: \u001b[0mInference done 507/1853. Dataloading: 0.0033 s/iter. Inference: 0.1811 s/iter. Eval: 0.0001 s/iter. Total: 0.1846 s/iter. ETA=0:04:08\n",
      "\u001b[32m[10/28 20:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 535/1853. Dataloading: 0.0032 s/iter. Inference: 0.1810 s/iter. Eval: 0.0001 s/iter. Total: 0.1844 s/iter. ETA=0:04:03\n",
      "\u001b[32m[10/28 20:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 563/1853. Dataloading: 0.0031 s/iter. Inference: 0.1809 s/iter. Eval: 0.0001 s/iter. Total: 0.1841 s/iter. ETA=0:03:57\n",
      "\u001b[32m[10/28 20:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 592/1853. Dataloading: 0.0030 s/iter. Inference: 0.1807 s/iter. Eval: 0.0001 s/iter. Total: 0.1839 s/iter. ETA=0:03:51\n",
      "\u001b[32m[10/28 20:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 620/1853. Dataloading: 0.0030 s/iter. Inference: 0.1808 s/iter. Eval: 0.0001 s/iter. Total: 0.1840 s/iter. ETA=0:03:46\n",
      "\u001b[32m[10/28 20:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 647/1853. Dataloading: 0.0032 s/iter. Inference: 0.1808 s/iter. Eval: 0.0001 s/iter. Total: 0.1841 s/iter. ETA=0:03:42\n",
      "\u001b[32m[10/28 20:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 674/1853. Dataloading: 0.0031 s/iter. Inference: 0.1809 s/iter. Eval: 0.0001 s/iter. Total: 0.1842 s/iter. ETA=0:03:37\n",
      "\u001b[32m[10/28 20:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 702/1853. Dataloading: 0.0030 s/iter. Inference: 0.1809 s/iter. Eval: 0.0001 s/iter. Total: 0.1841 s/iter. ETA=0:03:31\n",
      "\u001b[32m[10/28 20:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 728/1853. Dataloading: 0.0034 s/iter. Inference: 0.1808 s/iter. Eval: 0.0001 s/iter. Total: 0.1844 s/iter. ETA=0:03:27\n",
      "\u001b[32m[10/28 20:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 755/1853. Dataloading: 0.0033 s/iter. Inference: 0.1810 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:03:22\n",
      "\u001b[32m[10/28 20:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 783/1853. Dataloading: 0.0034 s/iter. Inference: 0.1810 s/iter. Eval: 0.0001 s/iter. Total: 0.1846 s/iter. ETA=0:03:17\n",
      "\u001b[32m[10/28 20:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 811/1853. Dataloading: 0.0036 s/iter. Inference: 0.1808 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:03:12\n",
      "\u001b[32m[10/28 20:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 839/1853. Dataloading: 0.0035 s/iter. Inference: 0.1808 s/iter. Eval: 0.0001 s/iter. Total: 0.1844 s/iter. ETA=0:03:07\n",
      "\u001b[32m[10/28 20:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 866/1853. Dataloading: 0.0034 s/iter. Inference: 0.1809 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:03:02\n",
      "\u001b[32m[10/28 20:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 894/1853. Dataloading: 0.0034 s/iter. Inference: 0.1809 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:02:56\n",
      "\u001b[32m[10/28 20:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 922/1853. Dataloading: 0.0033 s/iter. Inference: 0.1810 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:02:51\n",
      "\u001b[32m[10/28 20:29:15 d2.evaluation.evaluator]: \u001b[0mInference done 950/1853. Dataloading: 0.0032 s/iter. Inference: 0.1810 s/iter. Eval: 0.0001 s/iter. Total: 0.1844 s/iter. ETA=0:02:46\n",
      "\u001b[32m[10/28 20:29:20 d2.evaluation.evaluator]: \u001b[0mInference done 977/1853. Dataloading: 0.0032 s/iter. Inference: 0.1812 s/iter. Eval: 0.0001 s/iter. Total: 0.1845 s/iter. ETA=0:02:41\n",
      "\u001b[32m[10/28 20:29:25 d2.evaluation.evaluator]: \u001b[0mInference done 1004/1853. Dataloading: 0.0032 s/iter. Inference: 0.1813 s/iter. Eval: 0.0001 s/iter. Total: 0.1847 s/iter. ETA=0:02:36\n",
      "\u001b[32m[10/28 20:29:31 d2.evaluation.evaluator]: \u001b[0mInference done 1031/1853. Dataloading: 0.0032 s/iter. Inference: 0.1814 s/iter. Eval: 0.0001 s/iter. Total: 0.1849 s/iter. ETA=0:02:31\n",
      "\u001b[32m[10/28 20:29:36 d2.evaluation.evaluator]: \u001b[0mInference done 1058/1853. Dataloading: 0.0032 s/iter. Inference: 0.1815 s/iter. Eval: 0.0001 s/iter. Total: 0.1849 s/iter. ETA=0:02:27\n",
      "\u001b[32m[10/28 20:29:41 d2.evaluation.evaluator]: \u001b[0mInference done 1086/1853. Dataloading: 0.0032 s/iter. Inference: 0.1815 s/iter. Eval: 0.0001 s/iter. Total: 0.1848 s/iter. ETA=0:02:21\n",
      "\u001b[32m[10/28 20:29:46 d2.evaluation.evaluator]: \u001b[0mInference done 1112/1853. Dataloading: 0.0032 s/iter. Inference: 0.1816 s/iter. Eval: 0.0001 s/iter. Total: 0.1851 s/iter. ETA=0:02:17\n"
     ]
    }
   ],
   "source": [
    "files_to_remove = os.listdir(\"./output/\")\n",
    "for file_to_remove in files_to_remove:\n",
    "    os.remove(f\"./output/{file_to_remove}\")\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "torch.cuda.empty_cache()\n",
    "wandb.init(project=\"Find-Card\", name=NAME,config={\n",
    "    'BASE_LR':BASE_LR,\n",
    "    'MAX_ITER':MAX_ITER,\n",
    "    'EVAL_PERIOD':EVAL_PERIOD,\n",
    "    'IMS_PER_BATCH':IMS_PER_BATCH,\n",
    "    'BATCH_SIZE_PER_IMAGE':BATCH_SIZE_PER_IMAGE,\n",
    "    'SCORE_THRESH_TEST':SCORE_THRESH_TEST,\n",
    "    'MODEL':model,\n",
    "    'NAME':NAME\n",
    "})\n",
    "torch.cuda.empty_cache()\n",
    "cfg = get_cfg()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
    "torch.cuda.empty_cache()\n",
    "cfg.DATASETS.TRAIN = (\"data\",)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.DATASETS.TEST = ()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "torch.cuda.empty_cache()\n",
    "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "cfg.SOLVER.BASE_LR = BASE_LR\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.STEPS = []\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = BATCH_SIZE_PER_IMAGE\n",
    "torch.cuda.empty_cache()\n",
    "trainer = DefaultTrainer(cfg)\n",
    "torch.cuda.empty_cache()\n",
    "trainer.resume_or_load(resume=False)\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "torch.cuda.empty_cache()\n",
    "predictor = DefaultPredictor(cfg)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"\n",
    "cfg.SOLVER.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"test\", output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"test\")\n",
    "metrics = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "wandb.log(metrics)\n",
    "torch.cuda.empty_cache()\n",
    "logs = open(\"./output/metrics.json\", \"r\").read().split(\"\\n\")\n",
    "for log in tqdm(range(len(logs))):\n",
    "    try:\n",
    "        res = ast.literal_eval(logs[log])\n",
    "        wandb.log(res)\n",
    "    except:\n",
    "        pass\n",
    "for img in os.listdir(\"./test_imgs/\"):\n",
    "    torch.cuda.empty_cache()\n",
    "    v = Visualizer(cv2.imread(f\"./test_imgs/{img}\")[:, :, ::-1], metadata=metadata)\n",
    "    torch.cuda.empty_cache()\n",
    "    v = v.draw_instance_predictions(\n",
    "        predictor(cv2.imread(f\"./test_imgs/{img}\"))[\"instances\"].to(\"cpu\")\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    v = v.get_image()[:, :, ::-1]\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.imshow(v)\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.savefig(f\"./preds/{img}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.close()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({f\"Img/{img}\": wandb.Image(cv2.imread(f\"./preds/{img}\"))})\n",
    "info = data.iloc[589]\n",
    "img = cv2.imread(\"./download/Img/\" + info[\"Path\"])\n",
    "height, width = cv2.imread(\"./download/Img/\" + info[\"Path\"]).shape[:2]\n",
    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "xmin = round(xmin * width)\n",
    "xmax = round(xmax * width)\n",
    "ymin = round(ymin * height)\n",
    "ymax = round(ymax * height)\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "preds = predictor(img)\n",
    "target = torch.tensor([xmin, ymin, xmax, ymax])\n",
    "lowest_rmse = 0\n",
    "r_mean_squared_error = MeanSquaredError(squared=False)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if r_mean_squared_error(pred.to(\"cpu\"), target) > lowest_rmse:\n",
    "        lowest_rmse = r_mean_squared_error(pred.to(\"cpu\"), target)\n",
    "lowest_mse = 0\n",
    "mean_squared_error = MeanSquaredError(squared=True)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if mean_squared_error(pred.to(\"cpu\"), target) > lowest_mse:\n",
    "        lowest_mse = mean_squared_error(pred.to(\"cpu\"), target)\n",
    "wandb.log({\"MSE\": lowest_mse})\n",
    "wandb.log({\"RMSE\": lowest_rmse})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24e0a3-96fa-424f-9741-a188f5f96532",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cfg,f'./models/cfg-{NAME}.pt')\n",
    "torch.save(cfg,f'./models/cfg-{NAME}.pth')\n",
    "torch.save(predictor,f'./models/predictor-{NAME}.pt')\n",
    "torch.save(predictor,f'./models/predictor-{NAME}.pth')\n",
    "torch.save(evaluator,f'./models/evaluator-{NAME}.pt')\n",
    "torch.save(evaluator,f'./models/evaluator-{NAME}.pth')\n",
    "torch.save(model,f'./models/model-{NAME}.pt')\n",
    "torch.save(model,f'./models/model-{NAME}.pth')\n",
    "torch.save(labels,f'./models/labels-{NAME}.pt')\n",
    "torch.save(labels,f'./models/labels-{NAME}.pth')\n",
    "torch.save(metrics,f'./models/metrics-{NAME}.pt')\n",
    "torch.save(metrics,f'./models/metrics-{NAME}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76b61b-ac9c-418f-8462-6b1deee60162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('detectron2': conda)",
   "language": "python",
   "name": "python3812jvsc74a57bd0585e9a5027b519a27e411109b09a66bc779a1bba36bd86b08fdb64645f8a2c5a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
