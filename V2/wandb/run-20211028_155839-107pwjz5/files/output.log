
  1%|â–‰                                                                 | 27/1853 [00:01<01:43, 17.67it/s]
[32m[10/28 15:58:51 d2.engine.defaults]: [39mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )






















































 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1825/1853 [01:50<00:01, 17.60it/s]
[32m[10/28 16:00:43 d2.data.build]: [39mRemoved 0 images with no usable annotations. 1853 images left.
[32m[10/28 16:00:43 d2.data.build]: [39mDistribution of instances among all 1 categories:
[36m|  category  | #instances   |
[36m|:----------:|:-------------|
[36m|    Card    | 1853         |
[36m|            |              |
[32m[10/28 16:00:43 d2.data.dataset_mapper]: [39m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[10/28 16:00:43 d2.data.build]: [39mUsing training sampler TrainingSampler
[32m[10/28 16:00:43 d2.data.common]: [39mSerializing 1853 elements to byte tensors and concatenating them all ...

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1853/1853 [01:51<00:00, 16.56it/s]
2021-10-28 16:00:44.218735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[32m[10/28 16:00:47 d2.engine.train_loop]: [39mStarting training from iteration 0
Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.
Some model parameters or buffers are not found in the checkpoint:
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}
[34mroi_heads.box_predictor.cls_score.{bias, weight}
The checkpoint state_dict contains keys that are not used by the model:
  [35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}
/media/indika/Sync/anaconda3/envs/detectron2/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
[32m[10/28 16:00:57 d2.utils.events]: [39m eta: 0:40:59  iter: 19  total_loss: 1.539  loss_cls: 0.6054  loss_box_reg: 0.8722  loss_rpn_cls: 0.01883  loss_rpn_loc: 0.0051  time: 0.4913  data_time: 0.0143  lr: 1.9981e-06  max_mem: 3469M
[32m[10/28 16:01:07 d2.utils.events]: [39m eta: 0:40:26  iter: 39  total_loss: 1.369  loss_cls: 0.5806  loss_box_reg: 0.7001  loss_rpn_cls: 0.01123  loss_rpn_loc: 0.005434  time: 0.4767  data_time: 0.0014  lr: 3.9961e-06  max_mem: 3601M
[32m[10/28 16:01:16 d2.utils.events]: [39m eta: 0:39:57  iter: 59  total_loss: 1.59  loss_cls: 0.5752  loss_box_reg: 0.8971  loss_rpn_cls: 0.01181  loss_rpn_loc: 0.006894  time: 0.4698  data_time: 0.0014  lr: 5.9941e-06  max_mem: 3601M
[32m[10/28 16:01:25 d2.utils.events]: [39m eta: 0:39:02  iter: 79  total_loss: 1.423  loss_cls: 0.5544  loss_box_reg: 0.8334  loss_rpn_cls: 0.0198  loss_rpn_loc: 0.008207  time: 0.4653  data_time: 0.0014  lr: 7.9921e-06  max_mem: 3601M
[32m[10/28 16:01:34 d2.utils.events]: [39m eta: 0:38:24  iter: 99  total_loss: 1.482  loss_cls: 0.545  loss_box_reg: 0.9083  loss_rpn_cls: 0.009694  loss_rpn_loc: 0.006421  time: 0.4656  data_time: 0.0014  lr: 9.9901e-06  max_mem: 3601M
[32m[10/28 16:01:43 d2.utils.events]: [39m eta: 0:37:55  iter: 119  total_loss: 1.402  loss_cls: 0.5266  loss_box_reg: 0.8657  loss_rpn_cls: 0.009305  loss_rpn_loc: 0.004154  time: 0.4596  data_time: 0.0014  lr: 1.1988e-05  max_mem: 3601M
[32m[10/28 16:01:51 d2.utils.events]: [39m eta: 0:37:05  iter: 139  total_loss: 1.404  loss_cls: 0.5058  loss_box_reg: 0.8179  loss_rpn_cls: 0.03353  loss_rpn_loc: 0.006946  time: 0.4523  data_time: 0.0014  lr: 1.3986e-05  max_mem: 3601M
[32m[10/28 16:02:00 d2.utils.events]: [39m eta: 0:36:56  iter: 159  total_loss: 1.448  loss_cls: 0.4955  loss_box_reg: 0.9069  loss_rpn_cls: 0.004715  loss_rpn_loc: 0.005885  time: 0.4540  data_time: 0.0014  lr: 1.5984e-05  max_mem: 3601M
[32m[10/28 16:02:09 d2.utils.events]: [39m eta: 0:36:43  iter: 179  total_loss: 1.445  loss_cls: 0.4748  loss_box_reg: 0.8839  loss_rpn_cls: 0.007015  loss_rpn_loc: 0.0059  time: 0.4531  data_time: 0.0014  lr: 1.7982e-05  max_mem: 3601M
[32m[10/28 16:02:18 d2.utils.events]: [39m eta: 0:36:34  iter: 199  total_loss: 1.395  loss_cls: 0.4911  loss_box_reg: 0.8804  loss_rpn_cls: 0.01243  loss_rpn_loc: 0.007178  time: 0.4521  data_time: 0.0014  lr: 1.998e-05  max_mem: 3601M
[32m[10/28 16:02:27 d2.utils.events]: [39m eta: 0:36:01  iter: 219  total_loss: 1.291  loss_cls: 0.4462  loss_box_reg: 0.7998  loss_rpn_cls: 0.02647  loss_rpn_loc: 0.007114  time: 0.4510  data_time: 0.0015  lr: 2.1978e-05  max_mem: 3601M
[32m[10/28 16:02:36 d2.utils.events]: [39m eta: 0:35:52  iter: 239  total_loss: 1.124  loss_cls: 0.4261  loss_box_reg: 0.559  loss_rpn_cls: 0.05635  loss_rpn_loc: 0.01011  time: 0.4513  data_time: 0.0014  lr: 2.3976e-05  max_mem: 3601M
[32m[10/28 16:02:44 d2.utils.events]: [39m eta: 0:35:39  iter: 259  total_loss: 1.323  loss_cls: 0.4644  loss_box_reg: 0.8658  loss_rpn_cls: 0.01241  loss_rpn_loc: 0.005244  time: 0.4485  data_time: 0.0014  lr: 2.5974e-05  max_mem: 3601M
[32m[10/28 16:02:53 d2.utils.events]: [39m eta: 0:35:22  iter: 279  total_loss: 1.362  loss_cls: 0.4462  loss_box_reg: 0.865  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.007567  time: 0.4474  data_time: 0.0014  lr: 2.7972e-05  max_mem: 3601M
[32m[10/28 16:03:02 d2.utils.events]: [39m eta: 0:35:11  iter: 299  total_loss: 1.353  loss_cls: 0.4552  loss_box_reg: 0.8646  loss_rpn_cls: 0.03704  loss_rpn_loc: 0.004874  time: 0.4474  data_time: 0.0013  lr: 2.997e-05  max_mem: 3601M
[32m[10/28 16:03:11 d2.utils.events]: [39m eta: 0:34:44  iter: 319  total_loss: 1.357  loss_cls: 0.4551  loss_box_reg: 0.7652  loss_rpn_cls: 0.03512  loss_rpn_loc: 0.007718  time: 0.4462  data_time: 0.0013  lr: 3.1968e-05  max_mem: 3601M
[32m[10/28 16:03:19 d2.utils.events]: [39m eta: 0:34:33  iter: 339  total_loss: 1.276  loss_cls: 0.4477  loss_box_reg: 0.8009  loss_rpn_cls: 0.00818  loss_rpn_loc: 0.004218  time: 0.4454  data_time: 0.0014  lr: 3.3966e-05  max_mem: 3601M
[32m[10/28 16:03:28 d2.utils.events]: [39m eta: 0:34:17  iter: 359  total_loss: 1.37  loss_cls: 0.4179  loss_box_reg: 0.904  loss_rpn_cls: 0.02079  loss_rpn_loc: 0.004552  time: 0.4437  data_time: 0.0014  lr: 3.5964e-05  max_mem: 3601M
[32m[10/28 16:03:37 d2.utils.events]: [39m eta: 0:34:16  iter: 379  total_loss: 1.25  loss_cls: 0.4022  loss_box_reg: 0.8663  loss_rpn_cls: 0.005494  loss_rpn_loc: 0.005171  time: 0.4453  data_time: 0.0013  lr: 3.7962e-05  max_mem: 3601M
[32m[10/28 16:03:46 d2.utils.events]: [39m eta: 0:34:07  iter: 399  total_loss: 1.268  loss_cls: 0.3722  loss_box_reg: 0.8266  loss_rpn_cls: 0.01239  loss_rpn_loc: 0.008973  time: 0.4452  data_time: 0.0013  lr: 3.996e-05  max_mem: 3601M
[32m[10/28 16:03:55 d2.utils.events]: [39m eta: 0:34:00  iter: 419  total_loss: 1.303  loss_cls: 0.3687  loss_box_reg: 0.8873  loss_rpn_cls: 0.003764  loss_rpn_loc: 0.006032  time: 0.4463  data_time: 0.0014  lr: 4.1958e-05  max_mem: 3691M
[32m[10/28 16:04:04 d2.utils.events]: [39m eta: 0:33:56  iter: 439  total_loss: 1.305  loss_cls: 0.3896  loss_box_reg: 0.8449  loss_rpn_cls: 0.03065  loss_rpn_loc: 0.004507  time: 0.4458  data_time: 0.0014  lr: 4.3956e-05  max_mem: 3691M
[32m[10/28 16:04:13 d2.utils.events]: [39m eta: 0:33:44  iter: 459  total_loss: 1.244  loss_cls: 0.3183  loss_box_reg: 0.8204  loss_rpn_cls: 0.005385  loss_rpn_loc: 0.008031  time: 0.4452  data_time: 0.0015  lr: 4.5954e-05  max_mem: 3691M
[32m[10/28 16:04:22 d2.utils.events]: [39m eta: 0:33:45  iter: 479  total_loss: 1.309  loss_cls: 0.3637  loss_box_reg: 0.8841  loss_rpn_cls: 0.01265  loss_rpn_loc: 0.006734  time: 0.4465  data_time: 0.0015  lr: 4.7952e-05  max_mem: 3691M
[32m[10/28 16:04:32 d2.utils.events]: [39m eta: 0:33:45  iter: 499  total_loss: 1.17  loss_cls: 0.3817  loss_box_reg: 0.7712  loss_rpn_cls: 0.02965  loss_rpn_loc: 0.005426  time: 0.4481  data_time: 0.0015  lr: 4.995e-05  max_mem: 3691M
[32m[10/28 16:04:41 d2.utils.events]: [39m eta: 0:33:41  iter: 519  total_loss: 1.19  loss_cls: 0.3667  loss_box_reg: 0.7683  loss_rpn_cls: 0.01452  loss_rpn_loc: 0.006873  time: 0.4486  data_time: 0.0014  lr: 5.1948e-05  max_mem: 3691M
[32m[10/28 16:04:51 d2.utils.events]: [39m eta: 0:33:36  iter: 539  total_loss: 1.237  loss_cls: 0.3702  loss_box_reg: 0.8391  loss_rpn_cls: 0.006916  loss_rpn_loc: 0.006563  time: 0.4496  data_time: 0.0015  lr: 5.3946e-05  max_mem: 3691M
[32m[10/28 16:05:00 d2.utils.events]: [39m eta: 0:33:25  iter: 559  total_loss: 1.16  loss_cls: 0.3194  loss_box_reg: 0.8798  loss_rpn_cls: 0.007458  loss_rpn_loc: 0.004941  time: 0.4495  data_time: 0.0014  lr: 5.5944e-05  max_mem: 3691M
[32m[10/28 16:05:08 d2.utils.events]: [39m eta: 0:33:12  iter: 579  total_loss: 1.266  loss_cls: 0.3727  loss_box_reg: 0.817  loss_rpn_cls: 0.01789  loss_rpn_loc: 0.008247  time: 0.4489  data_time: 0.0013  lr: 5.7942e-05  max_mem: 3691M
[32m[10/28 16:05:17 d2.utils.events]: [39m eta: 0:33:03  iter: 599  total_loss: 1.1  loss_cls: 0.3324  loss_box_reg: 0.6598  loss_rpn_cls: 0.02056  loss_rpn_loc: 0.007217  time: 0.4489  data_time: 0.0015  lr: 5.994e-05  max_mem: 3691M
[32m[10/28 16:05:26 d2.utils.events]: [39m eta: 0:32:47  iter: 619  total_loss: 1.015  loss_cls: 0.3596  loss_box_reg: 0.7043  loss_rpn_cls: 0.03183  loss_rpn_loc: 0.003958  time: 0.4483  data_time: 0.0013  lr: 6.1938e-05  max_mem: 3691M
[32m[10/28 16:05:36 d2.utils.events]: [39m eta: 0:32:46  iter: 639  total_loss: 1.071  loss_cls: 0.3879  loss_box_reg: 0.7159  loss_rpn_cls: 0.004408  loss_rpn_loc: 0.00372  time: 0.4496  data_time: 0.0014  lr: 6.3936e-05  max_mem: 3691M
[32m[10/28 16:05:45 d2.utils.events]: [39m eta: 0:32:33  iter: 659  total_loss: 0.9462  loss_cls: 0.3693  loss_box_reg: 0.6404  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.004642  time: 0.4495  data_time: 0.0014  lr: 6.5934e-05  max_mem: 3691M
[32m[10/28 16:05:53 d2.utils.events]: [39m eta: 0:32:18  iter: 679  total_loss: 0.8649  loss_cls: 0.3047  loss_box_reg: 0.5029  loss_rpn_cls: 0.02217  loss_rpn_loc: 0.009522  time: 0.4487  data_time: 0.0014  lr: 6.7932e-05  max_mem: 3691M
[32m[10/28 16:06:02 d2.utils.events]: [39m eta: 0:32:11  iter: 699  total_loss: 1.229  loss_cls: 0.4346  loss_box_reg: 0.7397  loss_rpn_cls: 0.01553  loss_rpn_loc: 0.005524  time: 0.4492  data_time: 0.0014  lr: 6.993e-05  max_mem: 3691M
[32m[10/28 16:06:12 d2.utils.events]: [39m eta: 0:32:09  iter: 719  total_loss: 1.019  loss_cls: 0.3255  loss_box_reg: 0.6734  loss_rpn_cls: 0.008367  loss_rpn_loc: 0.005076  time: 0.4502  data_time: 0.0017  lr: 7.1928e-05  max_mem: 3691M
[32m[10/28 16:06:21 d2.utils.events]: [39m eta: 0:32:05  iter: 739  total_loss: 0.8847  loss_cls: 0.2902  loss_box_reg: 0.5937  loss_rpn_cls: 0.007533  loss_rpn_loc: 0.007824  time: 0.4505  data_time: 0.0017  lr: 7.3926e-05  max_mem: 3691M
[32m[10/28 16:06:30 d2.utils.events]: [39m eta: 0:31:56  iter: 759  total_loss: 0.8702  loss_cls: 0.3163  loss_box_reg: 0.5852  loss_rpn_cls: 0.01471  loss_rpn_loc: 0.004217  time: 0.4505  data_time: 0.0013  lr: 7.5924e-05  max_mem: 3691M
[32m[10/28 16:06:39 d2.utils.events]: [39m eta: 0:31:44  iter: 779  total_loss: 0.83  loss_cls: 0.3014  loss_box_reg: 0.5287  loss_rpn_cls: 0.007165  loss_rpn_loc: 0.005141  time: 0.4498  data_time: 0.0017  lr: 7.7922e-05  max_mem: 3691M
[32m[10/28 16:06:48 d2.utils.events]: [39m eta: 0:31:26  iter: 799  total_loss: 0.85  loss_cls: 0.3003  loss_box_reg: 0.5344  loss_rpn_cls: 0.004302  loss_rpn_loc: 0.003706  time: 0.4493  data_time: 0.0014  lr: 7.992e-05  max_mem: 3691M
[32m[10/28 16:06:57 d2.utils.events]: [39m eta: 0:31:17  iter: 819  total_loss: 0.6851  loss_cls: 0.2611  loss_box_reg: 0.4218  loss_rpn_cls: 0.01603  loss_rpn_loc: 0.006895  time: 0.4495  data_time: 0.0014  lr: 8.1918e-05  max_mem: 3691M
[32m[10/28 16:07:06 d2.utils.events]: [39m eta: 0:31:08  iter: 839  total_loss: 0.7101  loss_cls: 0.2502  loss_box_reg: 0.4776  loss_rpn_cls: 0.009558  loss_rpn_loc: 0.007995  time: 0.4500  data_time: 0.0015  lr: 8.3916e-05  max_mem: 3691M
[32m[10/28 16:07:15 d2.utils.events]: [39m eta: 0:31:01  iter: 859  total_loss: 0.8549  loss_cls: 0.3354  loss_box_reg: 0.4931  loss_rpn_cls: 0.00703  loss_rpn_loc: 0.006055  time: 0.4500  data_time: 0.0015  lr: 8.5914e-05  max_mem: 3691M
[32m[10/28 16:07:24 d2.utils.events]: [39m eta: 0:30:48  iter: 879  total_loss: 0.9378  loss_cls: 0.2568  loss_box_reg: 0.6163  loss_rpn_cls: 0.006179  loss_rpn_loc: 0.01181  time: 0.4494  data_time: 0.0015  lr: 8.7912e-05  max_mem: 3691M
[32m[10/28 16:07:32 d2.utils.events]: [39m eta: 0:30:33  iter: 899  total_loss: 0.6231  loss_cls: 0.1862  loss_box_reg: 0.4299  loss_rpn_cls: 0.008769  loss_rpn_loc: 0.005313  time: 0.4486  data_time: 0.0015  lr: 8.991e-05  max_mem: 3691M
[32m[10/28 16:07:40 d2.utils.events]: [39m eta: 0:30:23  iter: 919  total_loss: 0.86  loss_cls: 0.2472  loss_box_reg: 0.5479  loss_rpn_cls: 0.005118  loss_rpn_loc: 0.008938  time: 0.4479  data_time: 0.0014  lr: 9.1908e-05  max_mem: 3691M
[32m[10/28 16:07:48 d2.utils.events]: [39m eta: 0:30:08  iter: 939  total_loss: 0.5974  loss_cls: 0.2143  loss_box_reg: 0.3622  loss_rpn_cls: 0.006616  loss_rpn_loc: 0.004694  time: 0.4462  data_time: 0.0014  lr: 9.3906e-05  max_mem: 3691M
[32m[10/28 16:07:56 d2.utils.events]: [39m eta: 0:29:59  iter: 959  total_loss: 0.9178  loss_cls: 0.3509  loss_box_reg: 0.5535  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.01057  time: 0.4456  data_time: 0.0014  lr: 9.5904e-05  max_mem: 3691M
[32m[10/28 16:08:04 d2.utils.events]: [39m eta: 0:29:47  iter: 979  total_loss: 0.7655  loss_cls: 0.3037  loss_box_reg: 0.487  loss_rpn_cls: 0.01151  loss_rpn_loc: 0.008873  time: 0.4445  data_time: 0.0013  lr: 9.7902e-05  max_mem: 3691M
[32m[10/28 16:08:12 d2.utils.events]: [39m eta: 0:29:36  iter: 999  total_loss: 0.9559  loss_cls: 0.4052  loss_box_reg: 0.5392  loss_rpn_cls: 0.01712  loss_rpn_loc: 0.007402  time: 0.4438  data_time: 0.0014  lr: 9.99e-05  max_mem: 3691M
[32m[10/28 16:08:20 d2.utils.events]: [39m eta: 0:29:22  iter: 1019  total_loss: 0.7906  loss_cls: 0.3425  loss_box_reg: 0.4313  loss_rpn_cls: 0.01013  loss_rpn_loc: 0.006646  time: 0.4434  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:08:29 d2.utils.events]: [39m eta: 0:29:08  iter: 1039  total_loss: 0.7506  loss_cls: 0.3129  loss_box_reg: 0.3935  loss_rpn_cls: 0.01245  loss_rpn_loc: 0.006151  time: 0.4429  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:08:37 d2.utils.events]: [39m eta: 0:28:54  iter: 1059  total_loss: 0.7298  loss_cls: 0.3246  loss_box_reg: 0.3152  loss_rpn_cls: 0.02626  loss_rpn_loc: 0.008536  time: 0.4426  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:08:45 d2.utils.events]: [39m eta: 0:28:39  iter: 1079  total_loss: 0.8124  loss_cls: 0.2675  loss_box_reg: 0.4731  loss_rpn_cls: 0.01769  loss_rpn_loc: 0.005927  time: 0.4416  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:08:53 d2.utils.events]: [39m eta: 0:28:24  iter: 1099  total_loss: 0.6709  loss_cls: 0.2669  loss_box_reg: 0.4545  loss_rpn_cls: 0.01008  loss_rpn_loc: 0.00352  time: 0.4409  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:09:01 d2.utils.events]: [39m eta: 0:28:11  iter: 1119  total_loss: 0.9109  loss_cls: 0.3843  loss_box_reg: 0.4749  loss_rpn_cls: 0.03287  loss_rpn_loc: 0.005882  time: 0.4401  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:09:09 d2.utils.events]: [39m eta: 0:27:57  iter: 1139  total_loss: 0.7106  loss_cls: 0.2394  loss_box_reg: 0.4532  loss_rpn_cls: 0.003607  loss_rpn_loc: 0.005562  time: 0.4390  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:09:16 d2.utils.events]: [39m eta: 0:27:41  iter: 1159  total_loss: 0.7453  loss_cls: 0.2794  loss_box_reg: 0.3759  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.00295  time: 0.4380  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:09:25 d2.utils.events]: [39m eta: 0:27:29  iter: 1179  total_loss: 0.8252  loss_cls: 0.2361  loss_box_reg: 0.6065  loss_rpn_cls: 0.01036  loss_rpn_loc: 0.00647  time: 0.4375  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:09:33 d2.utils.events]: [39m eta: 0:27:17  iter: 1199  total_loss: 0.4939  loss_cls: 0.238  loss_box_reg: 0.2723  loss_rpn_cls: 0.002181  loss_rpn_loc: 0.003156  time: 0.4369  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:09:40 d2.utils.events]: [39m eta: 0:27:01  iter: 1219  total_loss: 0.7246  loss_cls: 0.3404  loss_box_reg: 0.3623  loss_rpn_cls: 0.01136  loss_rpn_loc: 0.004602  time: 0.4362  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:09:49 d2.utils.events]: [39m eta: 0:26:49  iter: 1239  total_loss: 0.6303  loss_cls: 0.2727  loss_box_reg: 0.3043  loss_rpn_cls: 0.01391  loss_rpn_loc: 0.004765  time: 0.4358  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:09:57 d2.utils.events]: [39m eta: 0:26:37  iter: 1259  total_loss: 1.04  loss_cls: 0.2999  loss_box_reg: 0.7264  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.006593  time: 0.4353  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:10:05 d2.utils.events]: [39m eta: 0:26:25  iter: 1279  total_loss: 0.7822  loss_cls: 0.242  loss_box_reg: 0.4652  loss_rpn_cls: 0.004727  loss_rpn_loc: 0.006875  time: 0.4346  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:10:13 d2.utils.events]: [39m eta: 0:26:12  iter: 1299  total_loss: 0.8573  loss_cls: 0.3076  loss_box_reg: 0.5064  loss_rpn_cls: 0.004599  loss_rpn_loc: 0.006396  time: 0.4340  data_time: 0.0012  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:10:21 d2.utils.events]: [39m eta: 0:25:59  iter: 1319  total_loss: 0.6319  loss_cls: 0.2799  loss_box_reg: 0.3156  loss_rpn_cls: 0.01957  loss_rpn_loc: 0.005868  time: 0.4339  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:10:29 d2.utils.events]: [39m eta: 0:25:46  iter: 1339  total_loss: 0.7852  loss_cls: 0.332  loss_box_reg: 0.3702  loss_rpn_cls: 0.007176  loss_rpn_loc: 0.006972  time: 0.4333  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:10:37 d2.utils.events]: [39m eta: 0:25:37  iter: 1359  total_loss: 0.737  loss_cls: 0.325  loss_box_reg: 0.4096  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.005771  time: 0.4327  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:10:45 d2.utils.events]: [39m eta: 0:25:21  iter: 1379  total_loss: 0.6784  loss_cls: 0.2862  loss_box_reg: 0.3849  loss_rpn_cls: 0.007067  loss_rpn_loc: 0.007449  time: 0.4320  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:10:53 d2.utils.events]: [39m eta: 0:25:13  iter: 1399  total_loss: 0.7537  loss_cls: 0.2726  loss_box_reg: 0.5103  loss_rpn_cls: 0.006011  loss_rpn_loc: 0.003919  time: 0.4318  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:11:01 d2.utils.events]: [39m eta: 0:25:01  iter: 1419  total_loss: 0.5919  loss_cls: 0.2046  loss_box_reg: 0.3115  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.002956  time: 0.4314  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:11:09 d2.utils.events]: [39m eta: 0:24:48  iter: 1439  total_loss: 0.903  loss_cls: 0.3028  loss_box_reg: 0.5444  loss_rpn_cls: 0.01626  loss_rpn_loc: 0.007193  time: 0.4312  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:11:18 d2.utils.events]: [39m eta: 0:24:37  iter: 1459  total_loss: 0.8993  loss_cls: 0.2907  loss_box_reg: 0.5278  loss_rpn_cls: 0.00852  loss_rpn_loc: 0.006394  time: 0.4309  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:11:26 d2.utils.events]: [39m eta: 0:24:27  iter: 1479  total_loss: 0.8123  loss_cls: 0.3191  loss_box_reg: 0.4602  loss_rpn_cls: 0.01153  loss_rpn_loc: 0.00547  time: 0.4305  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:11:34 d2.utils.events]: [39m eta: 0:24:13  iter: 1499  total_loss: 0.7215  loss_cls: 0.2571  loss_box_reg: 0.5041  loss_rpn_cls: 0.01133  loss_rpn_loc: 0.0102  time: 0.4301  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:11:41 d2.utils.events]: [39m eta: 0:24:01  iter: 1519  total_loss: 0.7572  loss_cls: 0.2746  loss_box_reg: 0.4323  loss_rpn_cls: 0.01184  loss_rpn_loc: 0.005082  time: 0.4296  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:11:50 d2.utils.events]: [39m eta: 0:23:49  iter: 1539  total_loss: 0.5861  loss_cls: 0.2501  loss_box_reg: 0.3191  loss_rpn_cls: 0.003396  loss_rpn_loc: 0.002697  time: 0.4296  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:11:58 d2.utils.events]: [39m eta: 0:23:38  iter: 1559  total_loss: 0.5266  loss_cls: 0.1926  loss_box_reg: 0.3501  loss_rpn_cls: 0.007239  loss_rpn_loc: 0.004101  time: 0.4292  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:12:06 d2.utils.events]: [39m eta: 0:23:27  iter: 1579  total_loss: 0.6269  loss_cls: 0.229  loss_box_reg: 0.2866  loss_rpn_cls: 0.005277  loss_rpn_loc: 0.003978  time: 0.4287  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:12:14 d2.utils.events]: [39m eta: 0:23:18  iter: 1599  total_loss: 0.5722  loss_cls: 0.278  loss_box_reg: 0.3599  loss_rpn_cls: 0.02089  loss_rpn_loc: 0.006624  time: 0.4287  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:12:23 d2.utils.events]: [39m eta: 0:23:09  iter: 1619  total_loss: 0.6977  loss_cls: 0.2477  loss_box_reg: 0.4044  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.004514  time: 0.4285  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:12:31 d2.utils.events]: [39m eta: 0:22:59  iter: 1639  total_loss: 0.7638  loss_cls: 0.3048  loss_box_reg: 0.4093  loss_rpn_cls: 0.01181  loss_rpn_loc: 0.00355  time: 0.4285  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:12:40 d2.utils.events]: [39m eta: 0:22:49  iter: 1659  total_loss: 0.6432  loss_cls: 0.2655  loss_box_reg: 0.3567  loss_rpn_cls: 0.006649  loss_rpn_loc: 0.003348  time: 0.4284  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:12:49 d2.utils.events]: [39m eta: 0:22:44  iter: 1679  total_loss: 0.7807  loss_cls: 0.2319  loss_box_reg: 0.4006  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.004423  time: 0.4286  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:12:56 d2.utils.events]: [39m eta: 0:22:30  iter: 1699  total_loss: 0.7784  loss_cls: 0.2674  loss_box_reg: 0.3975  loss_rpn_cls: 0.009796  loss_rpn_loc: 0.0035  time: 0.4279  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:13:04 d2.utils.events]: [39m eta: 0:22:20  iter: 1719  total_loss: 0.642  loss_cls: 0.2413  loss_box_reg: 0.3756  loss_rpn_cls: 0.003367  loss_rpn_loc: 0.005022  time: 0.4278  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:13:12 d2.utils.events]: [39m eta: 0:22:10  iter: 1739  total_loss: 0.6747  loss_cls: 0.2148  loss_box_reg: 0.4293  loss_rpn_cls: 0.005142  loss_rpn_loc: 0.005054  time: 0.4274  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:13:20 d2.utils.events]: [39m eta: 0:21:59  iter: 1759  total_loss: 0.6758  loss_cls: 0.2945  loss_box_reg: 0.3899  loss_rpn_cls: 0.01892  loss_rpn_loc: 0.004105  time: 0.4271  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:13:28 d2.utils.events]: [39m eta: 0:21:51  iter: 1779  total_loss: 0.6774  loss_cls: 0.2505  loss_box_reg: 0.452  loss_rpn_cls: 0.006858  loss_rpn_loc: 0.008583  time: 0.4268  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:13:36 d2.utils.events]: [39m eta: 0:21:40  iter: 1799  total_loss: 0.7513  loss_cls: 0.256  loss_box_reg: 0.5216  loss_rpn_cls: 0.008077  loss_rpn_loc: 0.006663  time: 0.4265  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:13:45 d2.utils.events]: [39m eta: 0:21:29  iter: 1819  total_loss: 0.5214  loss_cls: 0.21  loss_box_reg: 0.3088  loss_rpn_cls: 0.006429  loss_rpn_loc: 0.00513  time: 0.4264  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:13:53 d2.utils.events]: [39m eta: 0:21:20  iter: 1839  total_loss: 0.5446  loss_cls: 0.2505  loss_box_reg: 0.3537  loss_rpn_cls: 0.008156  loss_rpn_loc: 0.003683  time: 0.4261  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:14:00 d2.utils.events]: [39m eta: 0:21:11  iter: 1859  total_loss: 0.6902  loss_cls: 0.2255  loss_box_reg: 0.4348  loss_rpn_cls: 0.002589  loss_rpn_loc: 0.005369  time: 0.4257  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:14:09 d2.utils.events]: [39m eta: 0:21:01  iter: 1879  total_loss: 0.8306  loss_cls: 0.335  loss_box_reg: 0.4708  loss_rpn_cls: 0.01972  loss_rpn_loc: 0.00405  time: 0.4255  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:14:18 d2.utils.events]: [39m eta: 0:20:55  iter: 1899  total_loss: 0.5024  loss_cls: 0.2306  loss_box_reg: 0.2309  loss_rpn_cls: 0.01092  loss_rpn_loc: 0.005828  time: 0.4258  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:14:26 d2.utils.events]: [39m eta: 0:20:48  iter: 1919  total_loss: 0.5745  loss_cls: 0.2592  loss_box_reg: 0.3587  loss_rpn_cls: 0.01017  loss_rpn_loc: 0.004785  time: 0.4258  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:14:35 d2.utils.events]: [39m eta: 0:20:41  iter: 1939  total_loss: 0.7891  loss_cls: 0.2885  loss_box_reg: 0.3075  loss_rpn_cls: 0.01445  loss_rpn_loc: 0.003896  time: 0.4258  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:14:44 d2.utils.events]: [39m eta: 0:20:34  iter: 1959  total_loss: 0.6031  loss_cls: 0.2613  loss_box_reg: 0.4031  loss_rpn_cls: 0.005068  loss_rpn_loc: 0.00502  time: 0.4260  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:14:53 d2.utils.events]: [39m eta: 0:20:29  iter: 1979  total_loss: 0.7226  loss_cls: 0.2654  loss_box_reg: 0.3937  loss_rpn_cls: 0.01723  loss_rpn_loc: 0.003494  time: 0.4264  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:15:02 d2.utils.events]: [39m eta: 0:20:23  iter: 1999  total_loss: 0.562  loss_cls: 0.2559  loss_box_reg: 0.2898  loss_rpn_cls: 0.01583  loss_rpn_loc: 0.003851  time: 0.4268  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:15:11 d2.utils.events]: [39m eta: 0:20:16  iter: 2019  total_loss: 0.6911  loss_cls: 0.2844  loss_box_reg: 0.4266  loss_rpn_cls: 0.01211  loss_rpn_loc: 0.005291  time: 0.4271  data_time: 0.0017  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:15:20 d2.utils.events]: [39m eta: 0:20:08  iter: 2039  total_loss: 0.7322  loss_cls: 0.3131  loss_box_reg: 0.3678  loss_rpn_cls: 0.002421  loss_rpn_loc: 0.003542  time: 0.4272  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:15:28 d2.utils.events]: [39m eta: 0:19:59  iter: 2059  total_loss: 0.6483  loss_cls: 0.2226  loss_box_reg: 0.4066  loss_rpn_cls: 0.003206  loss_rpn_loc: 0.003984  time: 0.4269  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:15:37 d2.utils.events]: [39m eta: 0:19:53  iter: 2079  total_loss: 0.6213  loss_cls: 0.2291  loss_box_reg: 0.4448  loss_rpn_cls: 0.01205  loss_rpn_loc: 0.004235  time: 0.4270  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:15:45 d2.utils.events]: [39m eta: 0:19:45  iter: 2099  total_loss: 0.4928  loss_cls: 0.2109  loss_box_reg: 0.3516  loss_rpn_cls: 0.006165  loss_rpn_loc: 0.004595  time: 0.4269  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:15:54 d2.utils.events]: [39m eta: 0:19:39  iter: 2119  total_loss: 0.7061  loss_cls: 0.2302  loss_box_reg: 0.3336  loss_rpn_cls: 0.01074  loss_rpn_loc: 0.00352  time: 0.4272  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:16:03 d2.utils.events]: [39m eta: 0:19:35  iter: 2139  total_loss: 0.53  loss_cls: 0.2437  loss_box_reg: 0.2743  loss_rpn_cls: 0.008058  loss_rpn_loc: 0.005223  time: 0.4274  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:16:12 d2.utils.events]: [39m eta: 0:19:29  iter: 2159  total_loss: 0.5157  loss_cls: 0.1775  loss_box_reg: 0.3293  loss_rpn_cls: 0.005005  loss_rpn_loc: 0.002958  time: 0.4274  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:16:20 d2.utils.events]: [39m eta: 0:19:22  iter: 2179  total_loss: 0.5915  loss_cls: 0.1781  loss_box_reg: 0.3093  loss_rpn_cls: 0.007794  loss_rpn_loc: 0.00302  time: 0.4273  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:16:29 d2.utils.events]: [39m eta: 0:19:16  iter: 2199  total_loss: 0.6545  loss_cls: 0.2526  loss_box_reg: 0.4375  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.004317  time: 0.4274  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:16:38 d2.utils.events]: [39m eta: 0:19:09  iter: 2219  total_loss: 0.5779  loss_cls: 0.2538  loss_box_reg: 0.2837  loss_rpn_cls: 0.002974  loss_rpn_loc: 0.002997  time: 0.4274  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:16:47 d2.utils.events]: [39m eta: 0:19:01  iter: 2239  total_loss: 0.6365  loss_cls: 0.2224  loss_box_reg: 0.3679  loss_rpn_cls: 0.006955  loss_rpn_loc: 0.004615  time: 0.4276  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:16:56 d2.utils.events]: [39m eta: 0:18:57  iter: 2259  total_loss: 0.7405  loss_cls: 0.2672  loss_box_reg: 0.4299  loss_rpn_cls: 0.0063  loss_rpn_loc: 0.007336  time: 0.4278  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:17:04 d2.utils.events]: [39m eta: 0:18:50  iter: 2279  total_loss: 0.6041  loss_cls: 0.2216  loss_box_reg: 0.3929  loss_rpn_cls: 0.004793  loss_rpn_loc: 0.004068  time: 0.4276  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:17:12 d2.utils.events]: [39m eta: 0:18:46  iter: 2299  total_loss: 0.4073  loss_cls: 0.1655  loss_box_reg: 0.2806  loss_rpn_cls: 0.002542  loss_rpn_loc: 0.004023  time: 0.4276  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:17:21 d2.utils.events]: [39m eta: 0:18:38  iter: 2319  total_loss: 0.6715  loss_cls: 0.2107  loss_box_reg: 0.382  loss_rpn_cls: 0.005051  loss_rpn_loc: 0.004126  time: 0.4277  data_time: 0.0017  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:17:30 d2.utils.events]: [39m eta: 0:18:33  iter: 2339  total_loss: 0.5194  loss_cls: 0.2399  loss_box_reg: 0.282  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.004497  time: 0.4279  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:17:40 d2.utils.events]: [39m eta: 0:18:26  iter: 2359  total_loss: 0.7123  loss_cls: 0.2369  loss_box_reg: 0.4017  loss_rpn_cls: 0.005187  loss_rpn_loc: 0.005211  time: 0.4283  data_time: 0.0018  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:17:49 d2.utils.events]: [39m eta: 0:18:20  iter: 2379  total_loss: 0.7146  loss_cls: 0.2489  loss_box_reg: 0.3956  loss_rpn_cls: 0.004439  loss_rpn_loc: 0.0048  time: 0.4284  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:17:57 d2.utils.events]: [39m eta: 0:18:12  iter: 2399  total_loss: 0.6683  loss_cls: 0.2188  loss_box_reg: 0.2615  loss_rpn_cls: 0.006694  loss_rpn_loc: 0.006157  time: 0.4285  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:18:06 d2.utils.events]: [39m eta: 0:18:06  iter: 2419  total_loss: 0.598  loss_cls: 0.268  loss_box_reg: 0.2796  loss_rpn_cls: 0.005216  loss_rpn_loc: 0.004052  time: 0.4287  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:18:15 d2.utils.events]: [39m eta: 0:18:00  iter: 2439  total_loss: 0.6132  loss_cls: 0.243  loss_box_reg: 0.381  loss_rpn_cls: 0.007409  loss_rpn_loc: 0.003648  time: 0.4288  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:18:24 d2.utils.events]: [39m eta: 0:17:53  iter: 2459  total_loss: 0.5341  loss_cls: 0.2538  loss_box_reg: 0.347  loss_rpn_cls: 0.01504  loss_rpn_loc: 0.003717  time: 0.4290  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:18:33 d2.utils.events]: [39m eta: 0:17:45  iter: 2479  total_loss: 0.7622  loss_cls: 0.3076  loss_box_reg: 0.4035  loss_rpn_cls: 0.01648  loss_rpn_loc: 0.003272  time: 0.4289  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:18:42 d2.utils.events]: [39m eta: 0:17:41  iter: 2499  total_loss: 0.5993  loss_cls: 0.1989  loss_box_reg: 0.2752  loss_rpn_cls: 0.007244  loss_rpn_loc: 0.003617  time: 0.4291  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:18:51 d2.utils.events]: [39m eta: 0:17:36  iter: 2519  total_loss: 0.6577  loss_cls: 0.235  loss_box_reg: 0.387  loss_rpn_cls: 0.005523  loss_rpn_loc: 0.003705  time: 0.4294  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:19:01 d2.utils.events]: [39m eta: 0:17:30  iter: 2539  total_loss: 0.6589  loss_cls: 0.2597  loss_box_reg: 0.3085  loss_rpn_cls: 0.001673  loss_rpn_loc: 0.004109  time: 0.4298  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:19:09 d2.utils.events]: [39m eta: 0:17:24  iter: 2559  total_loss: 0.6999  loss_cls: 0.2285  loss_box_reg: 0.394  loss_rpn_cls: 0.004646  loss_rpn_loc: 0.004231  time: 0.4297  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:19:18 d2.utils.events]: [39m eta: 0:17:18  iter: 2579  total_loss: 0.7196  loss_cls: 0.2986  loss_box_reg: 0.3961  loss_rpn_cls: 0.01098  loss_rpn_loc: 0.01016  time: 0.4300  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:19:27 d2.utils.events]: [39m eta: 0:17:10  iter: 2599  total_loss: 0.6714  loss_cls: 0.1866  loss_box_reg: 0.3137  loss_rpn_cls: 0.001695  loss_rpn_loc: 0.007923  time: 0.4300  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:19:36 d2.utils.events]: [39m eta: 0:17:04  iter: 2619  total_loss: 0.8655  loss_cls: 0.2936  loss_box_reg: 0.4772  loss_rpn_cls: 0.007675  loss_rpn_loc: 0.005706  time: 0.4300  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:19:44 d2.utils.events]: [39m eta: 0:16:56  iter: 2639  total_loss: 0.6706  loss_cls: 0.1657  loss_box_reg: 0.4207  loss_rpn_cls: 0.002052  loss_rpn_loc: 0.004807  time: 0.4300  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:19:53 d2.utils.events]: [39m eta: 0:16:49  iter: 2659  total_loss: 0.7034  loss_cls: 0.2467  loss_box_reg: 0.3655  loss_rpn_cls: 0.008238  loss_rpn_loc: 0.006026  time: 0.4302  data_time: 0.0017  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:20:02 d2.utils.events]: [39m eta: 0:16:42  iter: 2679  total_loss: 0.7329  loss_cls: 0.2617  loss_box_reg: 0.2919  loss_rpn_cls: 0.006374  loss_rpn_loc: 0.007035  time: 0.4303  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:20:11 d2.utils.events]: [39m eta: 0:16:36  iter: 2699  total_loss: 0.4057  loss_cls: 0.1839  loss_box_reg: 0.2148  loss_rpn_cls: 0.002211  loss_rpn_loc: 0.003974  time: 0.4303  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:20:20 d2.utils.events]: [39m eta: 0:16:28  iter: 2719  total_loss: 0.9023  loss_cls: 0.3252  loss_box_reg: 0.5131  loss_rpn_cls: 0.004154  loss_rpn_loc: 0.005708  time: 0.4304  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:20:28 d2.utils.events]: [39m eta: 0:16:20  iter: 2739  total_loss: 0.4723  loss_cls: 0.199  loss_box_reg: 0.2562  loss_rpn_cls: 0.002397  loss_rpn_loc: 0.005676  time: 0.4302  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:20:37 d2.utils.events]: [39m eta: 0:16:17  iter: 2759  total_loss: 0.5175  loss_cls: 0.263  loss_box_reg: 0.2988  loss_rpn_cls: 0.0113  loss_rpn_loc: 0.003198  time: 0.4304  data_time: 0.0020  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:20:46 d2.utils.events]: [39m eta: 0:16:09  iter: 2779  total_loss: 0.5785  loss_cls: 0.2334  loss_box_reg: 0.345  loss_rpn_cls: 0.00623  loss_rpn_loc: 0.006302  time: 0.4306  data_time: 0.0017  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:20:55 d2.utils.events]: [39m eta: 0:16:02  iter: 2799  total_loss: 0.636  loss_cls: 0.3008  loss_box_reg: 0.3157  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.006336  time: 0.4307  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:21:04 d2.utils.events]: [39m eta: 0:15:56  iter: 2819  total_loss: 0.6968  loss_cls: 0.3048  loss_box_reg: 0.4292  loss_rpn_cls: 0.006653  loss_rpn_loc: 0.005211  time: 0.4309  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:21:14 d2.utils.events]: [39m eta: 0:15:49  iter: 2839  total_loss: 0.5638  loss_cls: 0.2214  loss_box_reg: 0.3628  loss_rpn_cls: 0.003668  loss_rpn_loc: 0.003984  time: 0.4312  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:21:23 d2.utils.events]: [39m eta: 0:15:43  iter: 2859  total_loss: 0.6286  loss_cls: 0.2777  loss_box_reg: 0.3433  loss_rpn_cls: 0.005111  loss_rpn_loc: 0.004445  time: 0.4313  data_time: 0.0017  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:21:32 d2.utils.events]: [39m eta: 0:15:36  iter: 2879  total_loss: 0.7774  loss_cls: 0.1703  loss_box_reg: 0.5296  loss_rpn_cls: 0.006523  loss_rpn_loc: 0.005931  time: 0.4314  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:21:41 d2.utils.events]: [39m eta: 0:15:27  iter: 2899  total_loss: 0.8579  loss_cls: 0.2317  loss_box_reg: 0.4778  loss_rpn_cls: 0.008796  loss_rpn_loc: 0.005782  time: 0.4315  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:21:49 d2.utils.events]: [39m eta: 0:15:19  iter: 2919  total_loss: 0.5574  loss_cls: 0.2575  loss_box_reg: 0.2918  loss_rpn_cls: 0.005188  loss_rpn_loc: 0.004029  time: 0.4315  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:21:58 d2.utils.events]: [39m eta: 0:15:11  iter: 2939  total_loss: 0.64  loss_cls: 0.327  loss_box_reg: 0.2905  loss_rpn_cls: 0.01344  loss_rpn_loc: 0.003997  time: 0.4317  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:22:08 d2.utils.events]: [39m eta: 0:15:03  iter: 2959  total_loss: 0.6259  loss_cls: 0.2241  loss_box_reg: 0.2986  loss_rpn_cls: 0.00597  loss_rpn_loc: 0.003652  time: 0.4319  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:22:17 d2.utils.events]: [39m eta: 0:14:54  iter: 2979  total_loss: 0.7206  loss_cls: 0.31  loss_box_reg: 0.3827  loss_rpn_cls: 0.02558  loss_rpn_loc: 0.006029  time: 0.4320  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:22:25 d2.utils.events]: [39m eta: 0:14:44  iter: 2999  total_loss: 0.4978  loss_cls: 0.2327  loss_box_reg: 0.249  loss_rpn_cls: 0.006694  loss_rpn_loc: 0.005191  time: 0.4319  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:22:34 d2.utils.events]: [39m eta: 0:14:35  iter: 3019  total_loss: 0.55  loss_cls: 0.2286  loss_box_reg: 0.2814  loss_rpn_cls: 0.005214  loss_rpn_loc: 0.004931  time: 0.4321  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:22:43 d2.utils.events]: [39m eta: 0:14:27  iter: 3039  total_loss: 0.8339  loss_cls: 0.2716  loss_box_reg: 0.4537  loss_rpn_cls: 0.01401  loss_rpn_loc: 0.004448  time: 0.4321  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:22:52 d2.utils.events]: [39m eta: 0:14:19  iter: 3059  total_loss: 0.4981  loss_cls: 0.2287  loss_box_reg: 0.3157  loss_rpn_cls: 0.005188  loss_rpn_loc: 0.005082  time: 0.4323  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:23:00 d2.utils.events]: [39m eta: 0:14:10  iter: 3079  total_loss: 0.601  loss_cls: 0.2838  loss_box_reg: 0.2711  loss_rpn_cls: 0.01757  loss_rpn_loc: 0.0054  time: 0.4322  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:23:10 d2.utils.events]: [39m eta: 0:14:02  iter: 3099  total_loss: 0.5661  loss_cls: 0.2539  loss_box_reg: 0.2858  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.002479  time: 0.4324  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:23:18 d2.utils.events]: [39m eta: 0:13:53  iter: 3119  total_loss: 0.4809  loss_cls: 0.2186  loss_box_reg: 0.2508  loss_rpn_cls: 0.006937  loss_rpn_loc: 0.002258  time: 0.4323  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:23:27 d2.utils.events]: [39m eta: 0:13:44  iter: 3139  total_loss: 0.5517  loss_cls: 0.1685  loss_box_reg: 0.3161  loss_rpn_cls: 0.00381  loss_rpn_loc: 0.004042  time: 0.4323  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:23:35 d2.utils.events]: [39m eta: 0:13:35  iter: 3159  total_loss: 0.5414  loss_cls: 0.2147  loss_box_reg: 0.2631  loss_rpn_cls: 0.008367  loss_rpn_loc: 0.004087  time: 0.4322  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:23:43 d2.utils.events]: [39m eta: 0:13:25  iter: 3179  total_loss: 0.6514  loss_cls: 0.2348  loss_box_reg: 0.4146  loss_rpn_cls: 0.007051  loss_rpn_loc: 0.005238  time: 0.4320  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:23:51 d2.utils.events]: [39m eta: 0:13:15  iter: 3199  total_loss: 0.4631  loss_cls: 0.1483  loss_box_reg: 0.262  loss_rpn_cls: 0.002727  loss_rpn_loc: 0.003302  time: 0.4319  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:24:00 d2.utils.events]: [39m eta: 0:13:06  iter: 3219  total_loss: 0.6631  loss_cls: 0.2505  loss_box_reg: 0.4186  loss_rpn_cls: 0.005651  loss_rpn_loc: 0.003074  time: 0.4317  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:24:07 d2.utils.events]: [39m eta: 0:12:57  iter: 3239  total_loss: 0.9399  loss_cls: 0.318  loss_box_reg: 0.6133  loss_rpn_cls: 0.008983  loss_rpn_loc: 0.006668  time: 0.4315  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:24:15 d2.utils.events]: [39m eta: 0:12:46  iter: 3259  total_loss: 0.7501  loss_cls: 0.2925  loss_box_reg: 0.404  loss_rpn_cls: 0.006369  loss_rpn_loc: 0.006025  time: 0.4313  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:24:23 d2.utils.events]: [39m eta: 0:12:35  iter: 3279  total_loss: 0.5979  loss_cls: 0.2373  loss_box_reg: 0.4237  loss_rpn_cls: 0.006628  loss_rpn_loc: 0.00462  time: 0.4309  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:24:31 d2.utils.events]: [39m eta: 0:12:27  iter: 3299  total_loss: 0.763  loss_cls: 0.2363  loss_box_reg: 0.431  loss_rpn_cls: 0.007968  loss_rpn_loc: 0.003947  time: 0.4308  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:24:40 d2.utils.events]: [39m eta: 0:12:18  iter: 3319  total_loss: 0.5849  loss_cls: 0.1794  loss_box_reg: 0.4176  loss_rpn_cls: 0.002788  loss_rpn_loc: 0.003335  time: 0.4308  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:24:48 d2.utils.events]: [39m eta: 0:12:08  iter: 3339  total_loss: 0.4212  loss_cls: 0.2294  loss_box_reg: 0.2658  loss_rpn_cls: 0.007001  loss_rpn_loc: 0.003632  time: 0.4307  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:24:56 d2.utils.events]: [39m eta: 0:11:56  iter: 3359  total_loss: 0.4182  loss_cls: 0.1889  loss_box_reg: 0.1996  loss_rpn_cls: 0.007323  loss_rpn_loc: 0.009885  time: 0.4306  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:25:04 d2.utils.events]: [39m eta: 0:11:44  iter: 3379  total_loss: 0.6619  loss_cls: 0.2048  loss_box_reg: 0.4315  loss_rpn_cls: 0.002037  loss_rpn_loc: 0.005676  time: 0.4303  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:25:12 d2.utils.events]: [39m eta: 0:11:34  iter: 3399  total_loss: 0.7794  loss_cls: 0.2787  loss_box_reg: 0.4304  loss_rpn_cls: 0.004957  loss_rpn_loc: 0.004658  time: 0.4303  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:25:20 d2.utils.events]: [39m eta: 0:11:24  iter: 3419  total_loss: 0.5874  loss_cls: 0.1909  loss_box_reg: 0.3344  loss_rpn_cls: 0.002267  loss_rpn_loc: 0.005138  time: 0.4299  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:25:28 d2.utils.events]: [39m eta: 0:11:16  iter: 3439  total_loss: 0.5365  loss_cls: 0.1929  loss_box_reg: 0.3993  loss_rpn_cls: 0.00554  loss_rpn_loc: 0.003625  time: 0.4299  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:25:36 d2.utils.events]: [39m eta: 0:11:05  iter: 3459  total_loss: 0.567  loss_cls: 0.2178  loss_box_reg: 0.3431  loss_rpn_cls: 0.005291  loss_rpn_loc: 0.005096  time: 0.4296  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:25:44 d2.utils.events]: [39m eta: 0:10:54  iter: 3479  total_loss: 0.7195  loss_cls: 0.3288  loss_box_reg: 0.3998  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.006294  time: 0.4295  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:25:52 d2.utils.events]: [39m eta: 0:10:45  iter: 3499  total_loss: 0.6847  loss_cls: 0.323  loss_box_reg: 0.2571  loss_rpn_cls: 0.01156  loss_rpn_loc: 0.002918  time: 0.4293  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:26:00 d2.utils.events]: [39m eta: 0:10:32  iter: 3519  total_loss: 0.7788  loss_cls: 0.2618  loss_box_reg: 0.3929  loss_rpn_cls: 0.008142  loss_rpn_loc: 0.005881  time: 0.4291  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:26:08 d2.utils.events]: [39m eta: 0:10:20  iter: 3539  total_loss: 0.5758  loss_cls: 0.1596  loss_box_reg: 0.3305  loss_rpn_cls: 0.002564  loss_rpn_loc: 0.002756  time: 0.4290  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:26:16 d2.utils.events]: [39m eta: 0:10:12  iter: 3559  total_loss: 0.6576  loss_cls: 0.1948  loss_box_reg: 0.3957  loss_rpn_cls: 0.001398  loss_rpn_loc: 0.004906  time: 0.4289  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:26:24 d2.utils.events]: [39m eta: 0:10:01  iter: 3579  total_loss: 0.6739  loss_cls: 0.2222  loss_box_reg: 0.483  loss_rpn_cls: 0.01064  loss_rpn_loc: 0.005876  time: 0.4287  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:26:33 d2.utils.events]: [39m eta: 0:09:52  iter: 3599  total_loss: 0.5888  loss_cls: 0.2622  loss_box_reg: 0.3937  loss_rpn_cls: 0.005856  loss_rpn_loc: 0.002796  time: 0.4287  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:26:41 d2.utils.events]: [39m eta: 0:09:42  iter: 3619  total_loss: 0.404  loss_cls: 0.1378  loss_box_reg: 0.2342  loss_rpn_cls: 0.002481  loss_rpn_loc: 0.003483  time: 0.4286  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:26:48 d2.utils.events]: [39m eta: 0:09:31  iter: 3639  total_loss: 0.3871  loss_cls: 0.1866  loss_box_reg: 0.2166  loss_rpn_cls: 0.004073  loss_rpn_loc: 0.005485  time: 0.4283  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:26:57 d2.utils.events]: [39m eta: 0:09:21  iter: 3659  total_loss: 0.6543  loss_cls: 0.2213  loss_box_reg: 0.4418  loss_rpn_cls: 0.001849  loss_rpn_loc: 0.00354  time: 0.4281  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:27:06 d2.utils.events]: [39m eta: 0:09:13  iter: 3679  total_loss: 0.4457  loss_cls: 0.2279  loss_box_reg: 0.2459  loss_rpn_cls: 0.004243  loss_rpn_loc: 0.002711  time: 0.4283  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:27:14 d2.utils.events]: [39m eta: 0:09:04  iter: 3699  total_loss: 0.3872  loss_cls: 0.1408  loss_box_reg: 0.2428  loss_rpn_cls: 0.004729  loss_rpn_loc: 0.006185  time: 0.4283  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:27:22 d2.utils.events]: [39m eta: 0:08:55  iter: 3719  total_loss: 0.585  loss_cls: 0.1989  loss_box_reg: 0.3277  loss_rpn_cls: 0.005906  loss_rpn_loc: 0.00458  time: 0.4282  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:27:31 d2.utils.events]: [39m eta: 0:08:47  iter: 3739  total_loss: 0.6811  loss_cls: 0.2  loss_box_reg: 0.3015  loss_rpn_cls: 0.001589  loss_rpn_loc: 0.004805  time: 0.4282  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:27:40 d2.utils.events]: [39m eta: 0:08:38  iter: 3759  total_loss: 0.6018  loss_cls: 0.3421  loss_box_reg: 0.2439  loss_rpn_cls: 0.004884  loss_rpn_loc: 0.00372  time: 0.4283  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:27:49 d2.utils.events]: [39m eta: 0:08:30  iter: 3779  total_loss: 0.5868  loss_cls: 0.1775  loss_box_reg: 0.2658  loss_rpn_cls: 0.005597  loss_rpn_loc: 0.003917  time: 0.4284  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:27:58 d2.utils.events]: [39m eta: 0:08:22  iter: 3799  total_loss: 0.7522  loss_cls: 0.2484  loss_box_reg: 0.4573  loss_rpn_cls: 0.007808  loss_rpn_loc: 0.004638  time: 0.4285  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:28:06 d2.utils.events]: [39m eta: 0:08:11  iter: 3819  total_loss: 0.5523  loss_cls: 0.2463  loss_box_reg: 0.3264  loss_rpn_cls: 0.002571  loss_rpn_loc: 0.003568  time: 0.4284  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:28:15 d2.utils.events]: [39m eta: 0:08:03  iter: 3839  total_loss: 0.5471  loss_cls: 0.1854  loss_box_reg: 0.3158  loss_rpn_cls: 0.004749  loss_rpn_loc: 0.003098  time: 0.4285  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:28:24 d2.utils.events]: [39m eta: 0:07:55  iter: 3859  total_loss: 0.8125  loss_cls: 0.3341  loss_box_reg: 0.3877  loss_rpn_cls: 0.007624  loss_rpn_loc: 0.004891  time: 0.4287  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:28:33 d2.utils.events]: [39m eta: 0:07:46  iter: 3879  total_loss: 0.4978  loss_cls: 0.2367  loss_box_reg: 0.2546  loss_rpn_cls: 0.006084  loss_rpn_loc: 0.00319  time: 0.4288  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:28:42 d2.utils.events]: [39m eta: 0:07:38  iter: 3899  total_loss: 0.5367  loss_cls: 0.1908  loss_box_reg: 0.2615  loss_rpn_cls: 0.003586  loss_rpn_loc: 0.002632  time: 0.4287  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:28:50 d2.utils.events]: [39m eta: 0:07:28  iter: 3919  total_loss: 0.4135  loss_cls: 0.1916  loss_box_reg: 0.2751  loss_rpn_cls: 0.006215  loss_rpn_loc: 0.002478  time: 0.4286  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:28:58 d2.utils.events]: [39m eta: 0:07:19  iter: 3939  total_loss: 0.3688  loss_cls: 0.1438  loss_box_reg: 0.1728  loss_rpn_cls: 0.001952  loss_rpn_loc: 0.003542  time: 0.4285  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:29:06 d2.utils.events]: [39m eta: 0:07:11  iter: 3959  total_loss: 0.5337  loss_cls: 0.2112  loss_box_reg: 0.3096  loss_rpn_cls: 0.005085  loss_rpn_loc: 0.004165  time: 0.4285  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:29:15 d2.utils.events]: [39m eta: 0:07:03  iter: 3979  total_loss: 0.509  loss_cls: 0.1768  loss_box_reg: 0.2583  loss_rpn_cls: 0.003317  loss_rpn_loc: 0.003143  time: 0.4284  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:29:24 d2.utils.events]: [39m eta: 0:06:54  iter: 3999  total_loss: 0.5769  loss_cls: 0.2358  loss_box_reg: 0.2778  loss_rpn_cls: 0.005387  loss_rpn_loc: 0.004412  time: 0.4285  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:29:32 d2.utils.events]: [39m eta: 0:06:45  iter: 4019  total_loss: 0.3287  loss_cls: 0.1382  loss_box_reg: 0.2014  loss_rpn_cls: 0.001105  loss_rpn_loc: 0.002894  time: 0.4285  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:29:41 d2.utils.events]: [39m eta: 0:06:36  iter: 4039  total_loss: 0.6147  loss_cls: 0.2437  loss_box_reg: 0.3314  loss_rpn_cls: 0.00653  loss_rpn_loc: 0.008657  time: 0.4284  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:29:49 d2.utils.events]: [39m eta: 0:06:26  iter: 4059  total_loss: 0.3887  loss_cls: 0.1422  loss_box_reg: 0.24  loss_rpn_cls: 0.006721  loss_rpn_loc: 0.00406  time: 0.4283  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:29:58 d2.utils.events]: [39m eta: 0:06:20  iter: 4079  total_loss: 0.7139  loss_cls: 0.2351  loss_box_reg: 0.5192  loss_rpn_cls: 0.003435  loss_rpn_loc: 0.003666  time: 0.4285  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:30:07 d2.utils.events]: [39m eta: 0:06:11  iter: 4099  total_loss: 0.4552  loss_cls: 0.1911  loss_box_reg: 0.2526  loss_rpn_cls: 0.004213  loss_rpn_loc: 0.005425  time: 0.4286  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:30:16 d2.utils.events]: [39m eta: 0:06:03  iter: 4119  total_loss: 0.6321  loss_cls: 0.2363  loss_box_reg: 0.3561  loss_rpn_cls: 0.003209  loss_rpn_loc: 0.003594  time: 0.4286  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:30:25 d2.utils.events]: [39m eta: 0:05:55  iter: 4139  total_loss: 0.441  loss_cls: 0.18  loss_box_reg: 0.2055  loss_rpn_cls: 0.002265  loss_rpn_loc: 0.002832  time: 0.4287  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:30:33 d2.utils.events]: [39m eta: 0:05:47  iter: 4159  total_loss: 0.5229  loss_cls: 0.1778  loss_box_reg: 0.2712  loss_rpn_cls: 0.001502  loss_rpn_loc: 0.005049  time: 0.4287  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:30:42 d2.utils.events]: [39m eta: 0:05:39  iter: 4179  total_loss: 0.6386  loss_cls: 0.2056  loss_box_reg: 0.3999  loss_rpn_cls: 0.008454  loss_rpn_loc: 0.006195  time: 0.4288  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:30:51 d2.utils.events]: [39m eta: 0:05:32  iter: 4199  total_loss: 0.623  loss_cls: 0.2027  loss_box_reg: 0.2634  loss_rpn_cls: 0.003647  loss_rpn_loc: 0.005032  time: 0.4288  data_time: 0.0017  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:30:59 d2.utils.events]: [39m eta: 0:05:23  iter: 4219  total_loss: 0.5654  loss_cls: 0.2279  loss_box_reg: 0.2752  loss_rpn_cls: 0.002034  loss_rpn_loc: 0.003834  time: 0.4287  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:31:08 d2.utils.events]: [39m eta: 0:05:15  iter: 4239  total_loss: 0.4208  loss_cls: 0.1351  loss_box_reg: 0.2458  loss_rpn_cls: 0.001957  loss_rpn_loc: 0.00283  time: 0.4287  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:31:16 d2.utils.events]: [39m eta: 0:05:08  iter: 4259  total_loss: 0.4853  loss_cls: 0.1666  loss_box_reg: 0.3139  loss_rpn_cls: 0.002708  loss_rpn_loc: 0.002883  time: 0.4288  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:31:25 d2.utils.events]: [39m eta: 0:05:00  iter: 4279  total_loss: 0.4898  loss_cls: 0.1816  loss_box_reg: 0.2246  loss_rpn_cls: 0.004535  loss_rpn_loc: 0.003206  time: 0.4287  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:31:34 d2.utils.events]: [39m eta: 0:04:52  iter: 4299  total_loss: 0.6234  loss_cls: 0.2192  loss_box_reg: 0.2924  loss_rpn_cls: 0.001565  loss_rpn_loc: 0.005224  time: 0.4289  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:31:42 d2.utils.events]: [39m eta: 0:04:43  iter: 4319  total_loss: 0.5196  loss_cls: 0.1747  loss_box_reg: 0.2609  loss_rpn_cls: 0.002491  loss_rpn_loc: 0.003847  time: 0.4288  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:31:51 d2.utils.events]: [39m eta: 0:04:35  iter: 4339  total_loss: 0.5224  loss_cls: 0.2364  loss_box_reg: 0.3331  loss_rpn_cls: 0.008242  loss_rpn_loc: 0.003675  time: 0.4288  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:32:00 d2.utils.events]: [39m eta: 0:04:27  iter: 4359  total_loss: 0.3724  loss_cls: 0.1512  loss_box_reg: 0.1803  loss_rpn_cls: 0.001253  loss_rpn_loc: 0.006209  time: 0.4289  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:32:08 d2.utils.events]: [39m eta: 0:04:19  iter: 4379  total_loss: 0.6166  loss_cls: 0.2753  loss_box_reg: 0.2776  loss_rpn_cls: 0.008275  loss_rpn_loc: 0.005363  time: 0.4288  data_time: 0.0017  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:32:16 d2.utils.events]: [39m eta: 0:04:11  iter: 4399  total_loss: 0.4325  loss_cls: 0.161  loss_box_reg: 0.2334  loss_rpn_cls: 0.004624  loss_rpn_loc: 0.003659  time: 0.4287  data_time: 0.0016  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:32:24 d2.utils.events]: [39m eta: 0:04:02  iter: 4419  total_loss: 0.3921  loss_cls: 0.189  loss_box_reg: 0.2468  loss_rpn_cls: 0.002818  loss_rpn_loc: 0.00266  time: 0.4285  data_time: 0.0021  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:32:32 d2.utils.events]: [39m eta: 0:03:54  iter: 4439  total_loss: 0.5782  loss_cls: 0.2757  loss_box_reg: 0.274  loss_rpn_cls: 0.006936  loss_rpn_loc: 0.003423  time: 0.4284  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:32:40 d2.utils.events]: [39m eta: 0:03:45  iter: 4459  total_loss: 0.6535  loss_cls: 0.3162  loss_box_reg: 0.3572  loss_rpn_cls: 0.00857  loss_rpn_loc: 0.003975  time: 0.4282  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:32:48 d2.utils.events]: [39m eta: 0:03:37  iter: 4479  total_loss: 0.5413  loss_cls: 0.205  loss_box_reg: 0.3143  loss_rpn_cls: 0.007048  loss_rpn_loc: 0.006468  time: 0.4281  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:32:56 d2.utils.events]: [39m eta: 0:03:29  iter: 4499  total_loss: 0.456  loss_cls: 0.2207  loss_box_reg: 0.2473  loss_rpn_cls: 0.00253  loss_rpn_loc: 0.006204  time: 0.4280  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:33:04 d2.utils.events]: [39m eta: 0:03:20  iter: 4519  total_loss: 0.5722  loss_cls: 0.2138  loss_box_reg: 0.212  loss_rpn_cls: 0.001765  loss_rpn_loc: 0.003362  time: 0.4279  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:33:12 d2.utils.events]: [39m eta: 0:03:12  iter: 4539  total_loss: 0.4861  loss_cls: 0.1817  loss_box_reg: 0.2177  loss_rpn_cls: 0.003455  loss_rpn_loc: 0.003394  time: 0.4278  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:33:21 d2.utils.events]: [39m eta: 0:03:04  iter: 4559  total_loss: 0.6404  loss_cls: 0.3044  loss_box_reg: 0.3835  loss_rpn_cls: 0.00768  loss_rpn_loc: 0.003593  time: 0.4277  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:33:29 d2.utils.events]: [39m eta: 0:02:55  iter: 4579  total_loss: 0.5374  loss_cls: 0.1419  loss_box_reg: 0.3423  loss_rpn_cls: 0.00147  loss_rpn_loc: 0.004175  time: 0.4276  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:33:37 d2.utils.events]: [39m eta: 0:02:48  iter: 4599  total_loss: 0.4828  loss_cls: 0.2516  loss_box_reg: 0.2026  loss_rpn_cls: 0.008614  loss_rpn_loc: 0.002304  time: 0.4276  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:33:45 d2.utils.events]: [39m eta: 0:02:39  iter: 4619  total_loss: 0.4047  loss_cls: 0.1762  loss_box_reg: 0.2025  loss_rpn_cls: 0.001652  loss_rpn_loc: 0.003311  time: 0.4275  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:33:53 d2.utils.events]: [39m eta: 0:02:32  iter: 4639  total_loss: 0.5372  loss_cls: 0.2349  loss_box_reg: 0.2724  loss_rpn_cls: 0.004772  loss_rpn_loc: 0.00349  time: 0.4274  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:34:01 d2.utils.events]: [39m eta: 0:02:23  iter: 4659  total_loss: 0.6005  loss_cls: 0.1697  loss_box_reg: 0.4039  loss_rpn_cls: 0.003359  loss_rpn_loc: 0.004917  time: 0.4273  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:34:09 d2.utils.events]: [39m eta: 0:02:14  iter: 4679  total_loss: 0.5701  loss_cls: 0.2356  loss_box_reg: 0.2279  loss_rpn_cls: 0.002469  loss_rpn_loc: 0.002563  time: 0.4272  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:34:17 d2.utils.events]: [39m eta: 0:02:05  iter: 4699  total_loss: 0.7683  loss_cls: 0.238  loss_box_reg: 0.4393  loss_rpn_cls: 0.009855  loss_rpn_loc: 0.004667  time: 0.4270  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:34:25 d2.utils.events]: [39m eta: 0:01:56  iter: 4719  total_loss: 0.7117  loss_cls: 0.3144  loss_box_reg: 0.3569  loss_rpn_cls: 0.005557  loss_rpn_loc: 0.005753  time: 0.4269  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:34:34 d2.utils.events]: [39m eta: 0:01:48  iter: 4739  total_loss: 0.3731  loss_cls: 0.1186  loss_box_reg: 0.2079  loss_rpn_cls: 0.002873  loss_rpn_loc: 0.004232  time: 0.4269  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:34:42 d2.utils.events]: [39m eta: 0:01:40  iter: 4759  total_loss: 0.5053  loss_cls: 0.1451  loss_box_reg: 0.2708  loss_rpn_cls: 0.001898  loss_rpn_loc: 0.006736  time: 0.4268  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:34:50 d2.utils.events]: [39m eta: 0:01:31  iter: 4779  total_loss: 0.589  loss_cls: 0.2127  loss_box_reg: 0.283  loss_rpn_cls: 0.006025  loss_rpn_loc: 0.002776  time: 0.4266  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:34:58 d2.utils.events]: [39m eta: 0:01:23  iter: 4799  total_loss: 0.5623  loss_cls: 0.2272  loss_box_reg: 0.2877  loss_rpn_cls: 0.011  loss_rpn_loc: 0.003336  time: 0.4266  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:35:06 d2.utils.events]: [39m eta: 0:01:14  iter: 4819  total_loss: 0.4726  loss_cls: 0.1798  loss_box_reg: 0.2365  loss_rpn_cls: 0.00474  loss_rpn_loc: 0.002638  time: 0.4264  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:35:14 d2.utils.events]: [39m eta: 0:01:06  iter: 4839  total_loss: 0.5164  loss_cls: 0.1624  loss_box_reg: 0.2735  loss_rpn_cls: 0.003421  loss_rpn_loc: 0.004199  time: 0.4263  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:35:22 d2.utils.events]: [39m eta: 0:00:57  iter: 4859  total_loss: 0.5497  loss_cls: 0.2292  loss_box_reg: 0.2384  loss_rpn_cls: 0.003359  loss_rpn_loc: 0.004599  time: 0.4263  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:35:30 d2.utils.events]: [39m eta: 0:00:49  iter: 4879  total_loss: 0.732  loss_cls: 0.2613  loss_box_reg: 0.3711  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.003937  time: 0.4262  data_time: 0.0015  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:35:39 d2.utils.events]: [39m eta: 0:00:41  iter: 4899  total_loss: 0.4551  loss_cls: 0.1804  loss_box_reg: 0.2617  loss_rpn_cls: 0.001203  loss_rpn_loc: 0.00209  time: 0.4262  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:35:46 d2.utils.events]: [39m eta: 0:00:33  iter: 4919  total_loss: 0.4386  loss_cls: 0.2696  loss_box_reg: 0.1831  loss_rpn_cls: 0.009856  loss_rpn_loc: 0.005623  time: 0.4260  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:35:55 d2.utils.events]: [39m eta: 0:00:24  iter: 4939  total_loss: 0.4417  loss_cls: 0.1694  loss_box_reg: 0.2174  loss_rpn_cls: 0.006027  loss_rpn_loc: 0.002575  time: 0.4260  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:36:03 d2.utils.events]: [39m eta: 0:00:16  iter: 4959  total_loss: 0.5264  loss_cls: 0.2394  loss_box_reg: 0.2419  loss_rpn_cls: 0.003663  loss_rpn_loc: 0.002707  time: 0.4260  data_time: 0.0014  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:36:12 d2.utils.events]: [39m eta: 0:00:08  iter: 4979  total_loss: 0.5323  loss_cls: 0.183  loss_box_reg: 0.2873  loss_rpn_cls: 0.003939  loss_rpn_loc: 0.003745  time: 0.4260  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:36:22 d2.utils.events]: [39m eta: 0:00:00  iter: 4999  total_loss: 0.7038  loss_cls: 0.2252  loss_box_reg: 0.3884  loss_rpn_cls: 0.004136  loss_rpn_loc: 0.003645  time: 0.4261  data_time: 0.0013  lr: 0.0001  max_mem: 3691M
[32m[10/28 16:36:22 d2.engine.hooks]: [39mOverall training speed: 4998 iterations in 0:35:29 (0.4261 s / it)
[32m[10/28 16:36:22 d2.engine.hooks]: [39mTotal training time: 0:35:32 (0:00:03 on hooks)
[32m[10/28 16:36:24 d2.evaluation.coco_evaluation]: [39m'test' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...
[32m[10/28 16:36:24 d2.data.datasets.coco]: [39mConverting annotations of dataset 'test' to COCO format ...)






















































100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1853/1853 [01:51<00:00, 16.63it/s]
  0%|                                                                                                                                                                                     | 0/1853 [00:00<?, ?it/s]
[32m[10/28 16:38:15 d2.data.datasets.coco]: [39mConverting dataset dicts into COCO format
[32m[10/28 16:38:16 d2.data.datasets.coco]: [39mConversion finished, #images: 1853, #annotations: 1853
























































100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1853/1853 [01:50<00:00, 16.76it/s]
[32m[10/28 16:40:06 d2.data.dataset_mapper]: [39m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[10/28 16:40:06 d2.data.common]: [39mSerializing 1853 elements to byte tensors and concatenating them all ...
[32m[10/28 16:40:07 d2.data.common]: [39mSerialized dataset takes 0.40 MiB
[32m[10/28 16:40:07 d2.evaluation.evaluator]: [39mStart inference on 1853 batches
[32m[10/28 16:40:10 d2.evaluation.evaluator]: [39mInference done 11/1853. Dataloading: 0.0006 s/iter. Inference: 0.1828 s/iter. Eval: 0.0001 s/iter. Total: 0.1836 s/iter. ETA=0:05:38
[32m[10/28 16:40:15 d2.evaluation.evaluator]: [39mInference done 37/1853. Dataloading: 0.0018 s/iter. Inference: 0.1897 s/iter. Eval: 0.0001 s/iter. Total: 0.1917 s/iter. ETA=0:05:48
[32m[10/28 16:40:20 d2.evaluation.evaluator]: [39mInference done 63/1853. Dataloading: 0.0031 s/iter. Inference: 0.1890 s/iter. Eval: 0.0001 s/iter. Total: 0.1922 s/iter. ETA=0:05:44
[32m[10/28 16:40:25 d2.evaluation.evaluator]: [39mInference done 91/1853. Dataloading: 0.0031 s/iter. Inference: 0.1850 s/iter. Eval: 0.0001 s/iter. Total: 0.1883 s/iter. ETA=0:05:31
[32m[10/28 16:40:30 d2.evaluation.evaluator]: [39mInference done 118/1853. Dataloading: 0.0026 s/iter. Inference: 0.1853 s/iter. Eval: 0.0001 s/iter. Total: 0.1881 s/iter. ETA=0:05:26
[32m[10/28 16:40:35 d2.evaluation.evaluator]: [39mInference done 144/1853. Dataloading: 0.0031 s/iter. Inference: 0.1857 s/iter. Eval: 0.0001 s/iter. Total: 0.1891 s/iter. ETA=0:05:23
[32m[10/28 16:40:41 d2.evaluation.evaluator]: [39mInference done 170/1853. Dataloading: 0.0028 s/iter. Inference: 0.1917 s/iter. Eval: 0.0002 s/iter. Total: 0.1948 s/iter. ETA=0:05:27
[32m[10/28 16:40:46 d2.evaluation.evaluator]: [39mInference done 197/1853. Dataloading: 0.0031 s/iter. Inference: 0.1905 s/iter. Eval: 0.0002 s/iter. Total: 0.1938 s/iter. ETA=0:05:20
[32m[10/28 16:40:51 d2.evaluation.evaluator]: [39mInference done 227/1853. Dataloading: 0.0028 s/iter. Inference: 0.1872 s/iter. Eval: 0.0002 s/iter. Total: 0.1903 s/iter. ETA=0:05:09
[32m[10/28 16:40:56 d2.evaluation.evaluator]: [39mInference done 256/1853. Dataloading: 0.0026 s/iter. Inference: 0.1855 s/iter. Eval: 0.0002 s/iter. Total: 0.1883 s/iter. ETA=0:05:00
[32m[10/28 16:41:01 d2.evaluation.evaluator]: [39mInference done 285/1853. Dataloading: 0.0024 s/iter. Inference: 0.1845 s/iter. Eval: 0.0002 s/iter. Total: 0.1871 s/iter. ETA=0:04:53
[32m[10/28 16:41:06 d2.evaluation.evaluator]: [39mInference done 314/1853. Dataloading: 0.0023 s/iter. Inference: 0.1837 s/iter. Eval: 0.0002 s/iter. Total: 0.1862 s/iter. ETA=0:04:46
[32m[10/28 16:41:12 d2.evaluation.evaluator]: [39mInference done 331/1853. Dataloading: 0.0032 s/iter. Inference: 0.1891 s/iter. Eval: 0.0002 s/iter. Total: 0.1926 s/iter. ETA=0:04:53
[32m[10/28 16:41:17 d2.evaluation.evaluator]: [39mInference done 360/1853. Dataloading: 0.0031 s/iter. Inference: 0.1879 s/iter. Eval: 0.0002 s/iter. Total: 0.1912 s/iter. ETA=0:04:45
[32m[10/28 16:41:22 d2.evaluation.evaluator]: [39mInference done 389/1853. Dataloading: 0.0029 s/iter. Inference: 0.1870 s/iter. Eval: 0.0002 s/iter. Total: 0.1902 s/iter. ETA=0:04:38
[32m[10/28 16:41:27 d2.evaluation.evaluator]: [39mInference done 418/1853. Dataloading: 0.0029 s/iter. Inference: 0.1861 s/iter. Eval: 0.0002 s/iter. Total: 0.1892 s/iter. ETA=0:04:31
[32m[10/28 16:41:32 d2.evaluation.evaluator]: [39mInference done 448/1853. Dataloading: 0.0028 s/iter. Inference: 0.1850 s/iter. Eval: 0.0002 s/iter. Total: 0.1880 s/iter. ETA=0:04:24
[32m[10/28 16:41:37 d2.evaluation.evaluator]: [39mInference done 477/1853. Dataloading: 0.0027 s/iter. Inference: 0.1842 s/iter. Eval: 0.0002 s/iter. Total: 0.1871 s/iter. ETA=0:04:17
[32m[10/28 16:41:42 d2.evaluation.evaluator]: [39mInference done 506/1853. Dataloading: 0.0028 s/iter. Inference: 0.1834 s/iter. Eval: 0.0002 s/iter. Total: 0.1865 s/iter. ETA=0:04:11
[32m[10/28 16:41:47 d2.evaluation.evaluator]: [39mInference done 536/1853. Dataloading: 0.0027 s/iter. Inference: 0.1827 s/iter. Eval: 0.0002 s/iter. Total: 0.1856 s/iter. ETA=0:04:04
[32m[10/28 16:41:52 d2.evaluation.evaluator]: [39mInference done 563/1853. Dataloading: 0.0026 s/iter. Inference: 0.1828 s/iter. Eval: 0.0002 s/iter. Total: 0.1857 s/iter. ETA=0:03:59
[32m[10/28 16:41:57 d2.evaluation.evaluator]: [39mInference done 592/1853. Dataloading: 0.0026 s/iter. Inference: 0.1824 s/iter. Eval: 0.0002 s/iter. Total: 0.1852 s/iter. ETA=0:03:53
[32m[10/28 16:42:03 d2.evaluation.evaluator]: [39mInference done 620/1853. Dataloading: 0.0028 s/iter. Inference: 0.1821 s/iter. Eval: 0.0002 s/iter. Total: 0.1852 s/iter. ETA=0:03:48
[32m[10/28 16:42:08 d2.evaluation.evaluator]: [39mInference done 649/1853. Dataloading: 0.0027 s/iter. Inference: 0.1819 s/iter. Eval: 0.0002 s/iter. Total: 0.1849 s/iter. ETA=0:03:42
[32m[10/28 16:42:13 d2.evaluation.evaluator]: [39mInference done 677/1853. Dataloading: 0.0031 s/iter. Inference: 0.1815 s/iter. Eval: 0.0002 s/iter. Total: 0.1848 s/iter. ETA=0:03:37
[32m[10/28 16:42:18 d2.evaluation.evaluator]: [39mInference done 706/1853. Dataloading: 0.0030 s/iter. Inference: 0.1812 s/iter. Eval: 0.0002 s/iter. Total: 0.1844 s/iter. ETA=0:03:31
[32m[10/28 16:42:23 d2.evaluation.evaluator]: [39mInference done 735/1853. Dataloading: 0.0030 s/iter. Inference: 0.1808 s/iter. Eval: 0.0002 s/iter. Total: 0.1840 s/iter. ETA=0:03:25
[32m[10/28 16:42:28 d2.evaluation.evaluator]: [39mInference done 764/1853. Dataloading: 0.0029 s/iter. Inference: 0.1805 s/iter. Eval: 0.0002 s/iter. Total: 0.1836 s/iter. ETA=0:03:19
[32m[10/28 16:42:33 d2.evaluation.evaluator]: [39mInference done 791/1853. Dataloading: 0.0034 s/iter. Inference: 0.1803 s/iter. Eval: 0.0002 s/iter. Total: 0.1838 s/iter. ETA=0:03:15
[32m[10/28 16:42:38 d2.evaluation.evaluator]: [39mInference done 815/1853. Dataloading: 0.0044 s/iter. Inference: 0.1802 s/iter. Eval: 0.0002 s/iter. Total: 0.1848 s/iter. ETA=0:03:11
[32m[10/28 16:42:44 d2.evaluation.evaluator]: [39mInference done 845/1853. Dataloading: 0.0042 s/iter. Inference: 0.1798 s/iter. Eval: 0.0002 s/iter. Total: 0.1843 s/iter. ETA=0:03:05
[32m[10/28 16:42:49 d2.evaluation.evaluator]: [39mInference done 874/1853. Dataloading: 0.0042 s/iter. Inference: 0.1796 s/iter. Eval: 0.0002 s/iter. Total: 0.1840 s/iter. ETA=0:03:00
[32m[10/28 16:42:54 d2.evaluation.evaluator]: [39mInference done 902/1853. Dataloading: 0.0044 s/iter. Inference: 0.1793 s/iter. Eval: 0.0002 s/iter. Total: 0.1839 s/iter. ETA=0:02:54
[32m[10/28 16:42:59 d2.evaluation.evaluator]: [39mInference done 925/1853. Dataloading: 0.0045 s/iter. Inference: 0.1800 s/iter. Eval: 0.0002 s/iter. Total: 0.1847 s/iter. ETA=0:02:51
[32m[10/28 16:43:04 d2.evaluation.evaluator]: [39mInference done 954/1853. Dataloading: 0.0045 s/iter. Inference: 0.1797 s/iter. Eval: 0.0002 s/iter. Total: 0.1844 s/iter. ETA=0:02:45
[32m[10/28 16:43:09 d2.evaluation.evaluator]: [39mInference done 984/1853. Dataloading: 0.0044 s/iter. Inference: 0.1793 s/iter. Eval: 0.0002 s/iter. Total: 0.1839 s/iter. ETA=0:02:39
[32m[10/28 16:43:14 d2.evaluation.evaluator]: [39mInference done 1013/1853. Dataloading: 0.0043 s/iter. Inference: 0.1791 s/iter. Eval: 0.0002 s/iter. Total: 0.1836 s/iter. ETA=0:02:34
[32m[10/28 16:43:19 d2.evaluation.evaluator]: [39mInference done 1043/1853. Dataloading: 0.0043 s/iter. Inference: 0.1787 s/iter. Eval: 0.0002 s/iter. Total: 0.1833 s/iter. ETA=0:02:28
[32m[10/28 16:43:24 d2.evaluation.evaluator]: [39mInference done 1070/1853. Dataloading: 0.0044 s/iter. Inference: 0.1787 s/iter. Eval: 0.0002 s/iter. Total: 0.1834 s/iter. ETA=0:02:23
[32m[10/28 16:43:29 d2.evaluation.evaluator]: [39mInference done 1099/1853. Dataloading: 0.0044 s/iter. Inference: 0.1786 s/iter. Eval: 0.0002 s/iter. Total: 0.1832 s/iter. ETA=0:02:18
[32m[10/28 16:43:34 d2.evaluation.evaluator]: [39mInference done 1128/1853. Dataloading: 0.0043 s/iter. Inference: 0.1784 s/iter. Eval: 0.0002 s/iter. Total: 0.1830 s/iter. ETA=0:02:12
[32m[10/28 16:43:39 d2.evaluation.evaluator]: [39mInference done 1158/1853. Dataloading: 0.0043 s/iter. Inference: 0.1781 s/iter. Eval: 0.0002 s/iter. Total: 0.1826 s/iter. ETA=0:02:06
[32m[10/28 16:43:44 d2.evaluation.evaluator]: [39mInference done 1187/1853. Dataloading: 0.0042 s/iter. Inference: 0.1781 s/iter. Eval: 0.0002 s/iter. Total: 0.1825 s/iter. ETA=0:02:01
[32m[10/28 16:43:49 d2.evaluation.evaluator]: [39mInference done 1214/1853. Dataloading: 0.0043 s/iter. Inference: 0.1780 s/iter. Eval: 0.0002 s/iter. Total: 0.1826 s/iter. ETA=0:01:56
[32m[10/28 16:43:55 d2.evaluation.evaluator]: [39mInference done 1242/1853. Dataloading: 0.0045 s/iter. Inference: 0.1779 s/iter. Eval: 0.0002 s/iter. Total: 0.1826 s/iter. ETA=0:01:51
[32m[10/28 16:44:00 d2.evaluation.evaluator]: [39mInference done 1271/1853. Dataloading: 0.0044 s/iter. Inference: 0.1778 s/iter. Eval: 0.0002 s/iter. Total: 0.1824 s/iter. ETA=0:01:46
[32m[10/28 16:44:05 d2.evaluation.evaluator]: [39mInference done 1301/1853. Dataloading: 0.0043 s/iter. Inference: 0.1776 s/iter. Eval: 0.0002 s/iter. Total: 0.1821 s/iter. ETA=0:01:40
[32m[10/28 16:44:10 d2.evaluation.evaluator]: [39mInference done 1329/1853. Dataloading: 0.0043 s/iter. Inference: 0.1776 s/iter. Eval: 0.0002 s/iter. Total: 0.1821 s/iter. ETA=0:01:35
[32m[10/28 16:44:15 d2.evaluation.evaluator]: [39mInference done 1358/1853. Dataloading: 0.0042 s/iter. Inference: 0.1775 s/iter. Eval: 0.0002 s/iter. Total: 0.1819 s/iter. ETA=0:01:30
[32m[10/28 16:44:20 d2.evaluation.evaluator]: [39mInference done 1386/1853. Dataloading: 0.0041 s/iter. Inference: 0.1776 s/iter. Eval: 0.0002 s/iter. Total: 0.1819 s/iter. ETA=0:01:24
[32m[10/28 16:44:25 d2.evaluation.evaluator]: [39mInference done 1416/1853. Dataloading: 0.0041 s/iter. Inference: 0.1773 s/iter. Eval: 0.0002 s/iter. Total: 0.1816 s/iter. ETA=0:01:19
[32m[10/28 16:44:30 d2.evaluation.evaluator]: [39mInference done 1446/1853. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0002 s/iter. Total: 0.1814 s/iter. ETA=0:01:13
[32m[10/28 16:44:35 d2.evaluation.evaluator]: [39mInference done 1477/1853. Dataloading: 0.0040 s/iter. Inference: 0.1769 s/iter. Eval: 0.0002 s/iter. Total: 0.1811 s/iter. ETA=0:01:08
[32m[10/28 16:44:40 d2.evaluation.evaluator]: [39mInference done 1503/1853. Dataloading: 0.0041 s/iter. Inference: 0.1770 s/iter. Eval: 0.0002 s/iter. Total: 0.1813 s/iter. ETA=0:01:03
[32m[10/28 16:44:45 d2.evaluation.evaluator]: [39mInference done 1532/1853. Dataloading: 0.0041 s/iter. Inference: 0.1770 s/iter. Eval: 0.0002 s/iter. Total: 0.1812 s/iter. ETA=0:00:58
[32m[10/28 16:44:51 d2.evaluation.evaluator]: [39mInference done 1560/1853. Dataloading: 0.0040 s/iter. Inference: 0.1770 s/iter. Eval: 0.0002 s/iter. Total: 0.1813 s/iter. ETA=0:00:53
[32m[10/28 16:44:56 d2.evaluation.evaluator]: [39mInference done 1588/1853. Dataloading: 0.0041 s/iter. Inference: 0.1770 s/iter. Eval: 0.0002 s/iter. Total: 0.1813 s/iter. ETA=0:00:48
[32m[10/28 16:45:01 d2.evaluation.evaluator]: [39mInference done 1616/1853. Dataloading: 0.0040 s/iter. Inference: 0.1770 s/iter. Eval: 0.0002 s/iter. Total: 0.1813 s/iter. ETA=0:00:42
[32m[10/28 16:45:06 d2.evaluation.evaluator]: [39mInference done 1646/1853. Dataloading: 0.0040 s/iter. Inference: 0.1769 s/iter. Eval: 0.0002 s/iter. Total: 0.1811 s/iter. ETA=0:00:37
[32m[10/28 16:45:11 d2.evaluation.evaluator]: [39mInference done 1675/1853. Dataloading: 0.0039 s/iter. Inference: 0.1769 s/iter. Eval: 0.0002 s/iter. Total: 0.1810 s/iter. ETA=0:00:32
[32m[10/28 16:45:16 d2.evaluation.evaluator]: [39mInference done 1704/1853. Dataloading: 0.0039 s/iter. Inference: 0.1768 s/iter. Eval: 0.0002 s/iter. Total: 0.1809 s/iter. ETA=0:00:26
[32m[10/28 16:45:21 d2.evaluation.evaluator]: [39mInference done 1732/1853. Dataloading: 0.0038 s/iter. Inference: 0.1769 s/iter. Eval: 0.0002 s/iter. Total: 0.1810 s/iter. ETA=0:00:21
[32m[10/28 16:45:26 d2.evaluation.evaluator]: [39mInference done 1761/1853. Dataloading: 0.0038 s/iter. Inference: 0.1769 s/iter. Eval: 0.0002 s/iter. Total: 0.1809 s/iter. ETA=0:00:16
[32m[10/28 16:45:31 d2.evaluation.evaluator]: [39mInference done 1790/1853. Dataloading: 0.0038 s/iter. Inference: 0.1768 s/iter. Eval: 0.0002 s/iter. Total: 0.1808 s/iter. ETA=0:00:11
[32m[10/28 16:45:37 d2.evaluation.evaluator]: [39mInference done 1818/1853. Dataloading: 0.0037 s/iter. Inference: 0.1769 s/iter. Eval: 0.0002 s/iter. Total: 0.1808 s/iter. ETA=0:00:06
[32m[10/28 16:45:42 d2.evaluation.evaluator]: [39mInference done 1846/1853. Dataloading: 0.0037 s/iter. Inference: 0.1769 s/iter. Eval: 0.0002 s/iter. Total: 0.1808 s/iter. ETA=0:00:01
[32m[10/28 16:45:43 d2.evaluation.evaluator]: [39mTotal inference time: 0:05:34.255764 (0.180874 s / iter per device, on 1 devices)
[32m[10/28 16:45:43 d2.evaluation.evaluator]: [39mTotal inference pure compute time: 0:05:26 (0.176946 s / iter per device, on 1 devices)
[32m[10/28 16:45:43 d2.evaluation.coco_evaluation]: [39mPreparing results for COCO format ...
[32m[10/28 16:45:43 d2.evaluation.coco_evaluation]: [39mSaving results to ./output/coco_instances_results.json
[32m[10/28 16:45:43 d2.evaluation.coco_evaluation]: [39mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[32m[10/28 16:45:43 d2.evaluation.fast_eval_api]: [39mEvaluate annotation type *bbox*
[32m[10/28 16:45:43 d2.evaluation.fast_eval_api]: [39mCOCOeval_opt.evaluate() finished in 0.12 seconds.
[32m[10/28 16:45:43 d2.evaluation.fast_eval_api]: [39mAccumulating evaluation results...
[32m[10/28 16:45:43 d2.evaluation.fast_eval_api]: [39mCOCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.368
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.307
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.140
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.302
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.257
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.690
[32m[10/28 16:45:43 d2.evaluation.coco_evaluation]: [39mEvaluation results for bbox:
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 27.730 | 36.802 | 30.744 | 5.580 | 13.965 | 30.242 |
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 251/251 [00:00<00:00, 3156.51it/s]