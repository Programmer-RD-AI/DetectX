{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0227183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "import torch, torchvision\n",
    "import detectron2\n",
    "import json\n",
    "import ast \n",
    "import tensorboard,os\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from tqdm import tqdm\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed1fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_remove = os.listdir('./output/')\n",
    "files_to_remove.remove('metrics.json')\n",
    "for file_to_remove in files_to_remove:\n",
    "    os.remove(f'./output/{file_to_remove}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9fd6877",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Data.csv\").sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c48137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_LR = 0.00025\n",
    "MAX_ITER = 500\n",
    "EVAL_PERIOD = 500\n",
    "IMS_PER_BATCH = 2\n",
    "BATCH_SIZE_PER_IMAGE = 16\n",
    "SCORE_THRESH_TEST = 0.625\n",
    "model = f\"COCO-Detection/\" + \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217333b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177d6150",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_remove = os.listdir(\"./output/\")\n",
    "for file_to_remove in files_to_remove:\n",
    "    os.remove(f\"./output/{file_to_remove}\")\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "torch.cuda.empty_cache()\n",
    "wandb.init(project=\"Find-Card\", name=NAME,config={\n",
    "    'BASE_LR':BASE_LR,\n",
    "    'MAX_ITER':MAX_ITER,\n",
    "    'EVAL_PERIOD':EVAL_PERIOD,\n",
    "    'IMS_PER_BATCH':IMS_PER_BATCH,\n",
    "    'BATCH_SIZE_PER_IMAGE':BATCH_SIZE_PER_IMAGE,\n",
    "    'SCORE_THRESH_TEST':SCORE_THRESH_TEST,\n",
    "    'MODEL':model\n",
    "    'NAME':NAME\n",
    "})\n",
    "torch.cuda.empty_cache()\n",
    "cfg = get_cfg()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
    "torch.cuda.empty_cache()\n",
    "cfg.DATASETS.TRAIN = (\"data\",)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.DATASETS.TEST = ()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "torch.cuda.empty_cache()\n",
    "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "cfg.SOLVER.BASE_LR = BASE_LR\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.STEPS = []\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = BATCH_SIZE_PER_IMAGE\n",
    "torch.cuda.empty_cache()\n",
    "trainer = DefaultTrainer(cfg)\n",
    "torch.cuda.empty_cache()\n",
    "trainer.resume_or_load(resume=False)\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "torch.cuda.empty_cache()\n",
    "predictor = DefaultPredictor(cfg)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"\n",
    "cfg.SOLVER.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"test\", output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"test\")\n",
    "metrics = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "wandb.log(metrics)\n",
    "torch.cuda.empty_cache()\n",
    "logs = open(\"./output/metrics.json\", \"r\").read().split(\"\\n\")\n",
    "for log in tqdm(range(len(logs))):\n",
    "    try:\n",
    "        res = ast.literal_eval(logs[log])\n",
    "        wandb.log(res)\n",
    "    except:\n",
    "        pass\n",
    "for img in os.listdir(\"./test_imgs/\"):\n",
    "    torch.cuda.empty_cache()\n",
    "    v = Visualizer(cv2.imread(f\"./test_imgs/{img}\")[:, :, ::-1], metadata=metadata)\n",
    "    torch.cuda.empty_cache()\n",
    "    v = v.draw_instance_predictions(\n",
    "        predictor(cv2.imread(f\"./test_imgs/{img}\"))[\"instances\"].to(\"cpu\")\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    v = v.get_image()[:, :, ::-1]\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.imshow(v)\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.savefig(f\"./preds/{img}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.close()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({f\"Img/{img}\": wandb.Image(cv2.imread(f\"./preds/{img}\"))})\n",
    "info = data.iloc[589]\n",
    "img = cv2.imread(\"./download/Img/\" + info[\"Path\"])\n",
    "height, width = cv2.imread(\"./download/Img/\" + info[\"Path\"]).shape[:2]\n",
    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "xmin = round(xmin * width)\n",
    "xmax = round(xmax * width)\n",
    "ymin = round(ymin * height)\n",
    "ymax = round(ymax * height)\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "preds = predictor(img)\n",
    "target = torch.tensor([xmin, ymin, xmax, ymax])\n",
    "lowest_rmse = 0\n",
    "r_mean_squared_error = MeanSquaredError(squared=False)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if r_mean_squared_error(pred.to(\"cpu\"), target) > lowest_rmse:\n",
    "        lowest_rmse = r_mean_squared_error(pred.to(\"cpu\"), target)\n",
    "lowest_mse = 0\n",
    "mean_squared_error = MeanSquaredError(squared=True)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if mean_squared_error(pred.to(\"cpu\"), target) > lowest_mse:\n",
    "        lowest_mse = mean_squared_error(pred.to(\"cpu\"), target)\n",
    "wandb.log({\"MSE\": lowest_mse})\n",
    "wandb.log({\"RMSE\": lowest_rmse})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f153a229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ranuga-d/Find-Card/runs/2dgc24mc\" target=\"_blank\">test</a></strong> to <a href=\"https://wandb.ai/ranuga-d/Find-Card\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files_to_remove = os.listdir(\"./output/\")\n",
    "for file_to_remove in files_to_remove:\n",
    "    os.remove(f\"./output/{file_to_remove}\")\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "torch.cuda.empty_cache()\n",
    "wandb.init(project=\"Find-Card\", name=NAME,config={\n",
    "    'BASE_LR':BASE_LR,\n",
    "    'MAX_ITER':MAX_ITER,\n",
    "    'EVAL_PERIOD':EVAL_PERIOD,\n",
    "    'IMS_PER_BATCH':IMS_PER_BATCH,\n",
    "    'BATCH_SIZE_PER_IMAGE':BATCH_SIZE_PER_IMAGE,\n",
    "    'SCORE_THRESH_TEST':SCORE_THRESH_TEST,\n",
    "    'MODEL':model,\n",
    "    'NAME':NAME\n",
    "})\n",
    "torch.cuda.empty_cache()\n",
    "cfg = get_cfg()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
    "torch.cuda.empty_cache()\n",
    "cfg.DATASETS.TRAIN = (\"data\",)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.DATASETS.TEST = ()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "torch.cuda.empty_cache()\n",
    "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "cfg.SOLVER.BASE_LR = BASE_LR\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.STEPS = []\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = BATCH_SIZE_PER_IMAGE\n",
    "torch.cuda.empty_cache()\n",
    "trainer = DefaultTrainer(cfg)\n",
    "torch.cuda.empty_cache()\n",
    "trainer.resume_or_load(resume=False)\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "torch.cuda.empty_cache()\n",
    "predictor = DefaultPredictor(cfg)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"\n",
    "cfg.SOLVER.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"test\", output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"test\")\n",
    "metrics = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "wandb.log(metrics)\n",
    "torch.cuda.empty_cache()\n",
    "logs = open(\"./output/metrics.json\", \"r\").read().split(\"\\n\")\n",
    "for log in tqdm(range(len(logs))):\n",
    "    try:\n",
    "        res = ast.literal_eval(logs[log])\n",
    "        wandb.log(res)\n",
    "    except:\n",
    "        pass\n",
    "for img in os.listdir(\"./test_imgs/\"):\n",
    "    torch.cuda.empty_cache()\n",
    "    v = Visualizer(cv2.imread(f\"./test_imgs/{img}\")[:, :, ::-1], metadata=metadata)\n",
    "    torch.cuda.empty_cache()\n",
    "    v = v.draw_instance_predictions(\n",
    "        predictor(cv2.imread(f\"./test_imgs/{img}\"))[\"instances\"].to(\"cpu\")\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    v = v.get_image()[:, :, ::-1]\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.imshow(v)\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.savefig(f\"./preds/{img}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.close()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({f\"Img/{img}\": wandb.Image(cv2.imread(f\"./preds/{img}\"))})\n",
    "info = data.iloc[589]\n",
    "img = cv2.imread(\"./download/Img/\" + info[\"Path\"])\n",
    "height, width = cv2.imread(\"./download/Img/\" + info[\"Path\"]).shape[:2]\n",
    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "xmin = round(xmin * width)\n",
    "xmax = round(xmax * width)\n",
    "ymin = round(ymin * height)\n",
    "ymax = round(ymax * height)\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "preds = predictor(img)\n",
    "target = torch.tensor([xmin, ymin, xmax, ymax])\n",
    "lowest_rmse = 0\n",
    "r_mean_squared_error = MeanSquaredError(squared=False)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if r_mean_squared_error(pred.to(\"cpu\"), target) > lowest_rmse:\n",
    "        lowest_rmse = r_mean_squared_error(pred.to(\"cpu\"), target)\n",
    "lowest_mse = 0\n",
    "mean_squared_error = MeanSquaredError(squared=True)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if mean_squared_error(pred.to(\"cpu\"), target) > lowest_mse:\n",
    "        lowest_mse = mean_squared_error(pred.to(\"cpu\"), target)\n",
    "wandb.log({\"MSE\": lowest_mse})\n",
    "wandb.log({\"RMSE\": lowest_rmse})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab867b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Data.csv\").sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c98b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "info = data.iloc[59]\n",
    "img = cv2.imread(f'./Img/{info[\"Path\"]}')\n",
    "height, width = cv2.imread(\"./Img/\" + info[\"Path\"]).shape[:2]\n",
    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "xmin = round(xmin * width)\n",
    "xmax = round(xmax * width)\n",
    "ymin = round(ymin * height)\n",
    "ymax = round(ymax * height)\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "x,y,w,h = round(x),round(y),round(w),round(h)\n",
    "cv2.imwrite('./output.png',img)\n",
    "roi=img[y:y+h,x:x+w]\n",
    "cv2.imwrite(str('crop') + '.jpg', roi)\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),10)\n",
    "cv2.imwrite(str('box') + '.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e31c6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "def load_data(data=data, test=False):\n",
    "    if test is True:\n",
    "        if \"data.npy\" in os.listdir(\"./\"):\n",
    "            data = np.load(\"./data.npy\", allow_pickle=True)\n",
    "            data = data[:325]\n",
    "            print(len(data))\n",
    "            return data\n",
    "    if \"data.npy\" in os.listdir(\"./\"):\n",
    "        data = np.load(\"./data.npy\", allow_pickle=True)\n",
    "        print(len(data))\n",
    "        return data\n",
    "    new_data = []\n",
    "    for idx in tqdm(range(len(data))):\n",
    "        record = {}\n",
    "        info = data.iloc[idx]\n",
    "        height, width = cv2.imread(\"./Img/\" + info[\"Path\"]).shape[:2]\n",
    "        xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "        xmin = round(xmin * width)\n",
    "        xmax = round(xmax * width)\n",
    "        ymin = round(ymin * height)\n",
    "        ymax = round(ymax * height)\n",
    "        record[\"file_name\"] = \"./Img/\" + info[\"Path\"]\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        record[\"cateogry_id\"] = 1\n",
    "        objs = [\n",
    "            {\n",
    "                \"bbox\": [xmin,ymin,xmax,ymax],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"category_id\": 1,\n",
    "            }\n",
    "        ]\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"annotations\"] = objs\n",
    "        new_data.append(record)\n",
    "    np.random.shuffle(new_data)\n",
    "#     np.save(\"data.npy\", new_data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0692498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "labels = [\"Card\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be3e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the data\n",
    "DatasetCatalog.register(\"data\", lambda: load_data())\n",
    "MetadataCatalog.get(\"data\").set(thing_classes=labels)\n",
    "metadata = MetadataCatalog.get(\"data\")\n",
    "DatasetCatalog.register(\"test\", lambda: load_data(test=True))\n",
    "MetadataCatalog.get(\"test\").set(thing_classes=labels)\n",
    "metadata_test = MetadataCatalog.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "784e3a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"fast_rcnn_R_50_FPN_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_C4_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_C4_3x.yaml\",\n",
    "    \"faster_rcnn_R_50_DC5_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_DC5_3x.yaml\",\n",
    "    \"retinanet_R_50_FPN_1x.py\",\n",
    "    \"retinanet_R_50_FPN_1x.yaml\",\n",
    "    \"retinanet_R_50_FPN_3x.yaml\",\n",
    "    \"rpn_R_50_C4_1x.yaml\",\n",
    "    \"rpn_R_50_FPN_1x.yaml\"\n",
    "    \"faster_rcnn_R_50_FPN_1x.yaml\",\n",
    "    \"faster_rcnn_R_50_FPN_3x.yaml\",\n",
    "    \"faster_rcnn_R_101_DC5_3x.yaml\",\n",
    "    \"faster_rcnn_R_101_FPN_3x.yaml\",\n",
    "    \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
    "]\n",
    "max_iters = [\n",
    "    50,100,125,250,500,1000,2000,2500,5000\n",
    "]\n",
    "base_lrs = [\n",
    "    0.1,0.01,0.001,0.0001,0.00001,0.000001\n",
    "]\n",
    "ims_per_batchs = [\n",
    "    1,2,3,4,5,6,7,8,9,10\n",
    "]\n",
    "batch_size_per_images = [\n",
    "    8,16,32,64,128,256,512\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc809e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_LR = 0.00025\n",
    "MAX_ITER = 500\n",
    "EVAL_PERIOD = 500\n",
    "IMS_PER_BATCH = 2\n",
    "BATCH_SIZE_PER_IMAGE = 16\n",
    "SCORE_THRESH_TEST = 0.625\n",
    "model = f\"COCO-Detection/\" + \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "decad373",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ecc54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_remove = os.listdir(\"./output/\")\n",
    "for file_to_remove in files_to_remove:\n",
    "    os.remove(f\"./output/{file_to_remove}\")\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "torch.cuda.empty_cache()\n",
    "wandb.init(project=\"Find-Card\", name=NAME,config={\n",
    "    'BASE_LR':BASE_LR,\n",
    "    'MAX_ITER':MAX_ITER,\n",
    "    'EVAL_PERIOD':EVAL_PERIOD,\n",
    "    'IMS_PER_BATCH':IMS_PER_BATCH,\n",
    "    'BATCH_SIZE_PER_IMAGE':BATCH_SIZE_PER_IMAGE,\n",
    "    'SCORE_THRESH_TEST':SCORE_THRESH_TEST,\n",
    "    'MODEL':model,\n",
    "    'NAME':NAME\n",
    "})\n",
    "torch.cuda.empty_cache()\n",
    "cfg = get_cfg()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
    "torch.cuda.empty_cache()\n",
    "cfg.DATASETS.TRAIN = (\"data\",)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.DATASETS.TEST = ()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "torch.cuda.empty_cache()\n",
    "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "cfg.SOLVER.BASE_LR = BASE_LR\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.STEPS = []\n",
    "torch.cuda.empty_cache()\n",
    "cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = BATCH_SIZE_PER_IMAGE\n",
    "torch.cuda.empty_cache()\n",
    "trainer = DefaultTrainer(cfg)\n",
    "torch.cuda.empty_cache()\n",
    "trainer.resume_or_load(resume=False)\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "torch.cuda.empty_cache()\n",
    "predictor = DefaultPredictor(cfg)\n",
    "torch.cuda.empty_cache()\n",
    "cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"\n",
    "cfg.SOLVER.SCORE_THRESH_TEST = SCORE_THRESH_TEST\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"test\", output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"test\")\n",
    "metrics = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "wandb.log(metrics)\n",
    "torch.cuda.empty_cache()\n",
    "logs = open(\"./output/metrics.json\", \"r\").read().split(\"\\n\")\n",
    "for log in tqdm(range(len(logs))):\n",
    "    try:\n",
    "        res = ast.literal_eval(logs[log])\n",
    "        wandb.log(res)\n",
    "    except:\n",
    "        pass\n",
    "for img in os.listdir(\"./test_imgs/\"):\n",
    "    torch.cuda.empty_cache()\n",
    "    v = Visualizer(cv2.imread(f\"./test_imgs/{img}\")[:, :, ::-1], metadata=metadata)\n",
    "    torch.cuda.empty_cache()\n",
    "    v = v.draw_instance_predictions(\n",
    "        predictor(cv2.imread(f\"./test_imgs/{img}\"))[\"instances\"].to(\"cpu\")\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    v = v.get_image()[:, :, ::-1]\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.imshow(v)\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.savefig(f\"./preds/{img}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.close()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({f\"Img/{img}\": wandb.Image(cv2.imread(f\"./preds/{img}\"))})\n",
    "info = data.iloc[589]\n",
    "img = cv2.imread(\"./download/Img/\" + info[\"Path\"])\n",
    "height, width = cv2.imread(\"./download/Img/\" + info[\"Path\"]).shape[:2]\n",
    "xmin, ymin, xmax, ymax = info[\"XMin\"], info[\"YMin\"], info[\"XMax\"], info[\"YMax\"]\n",
    "xmin = round(xmin * width)\n",
    "xmax = round(xmax * width)\n",
    "ymin = round(ymin * height)\n",
    "ymax = round(ymax * height)\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "preds = predictor(img)\n",
    "target = torch.tensor([xmin, ymin, xmax, ymax])\n",
    "lowest_rmse = 0\n",
    "r_mean_squared_error = MeanSquaredError(squared=False)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if r_mean_squared_error(pred.to(\"cpu\"), target) > lowest_rmse:\n",
    "        lowest_rmse = r_mean_squared_error(pred.to(\"cpu\"), target)\n",
    "lowest_mse = 0\n",
    "mean_squared_error = MeanSquaredError(squared=True)\n",
    "preds_new = preds[\"instances\"].__dict__[\"_fields\"][\"pred_boxes\"].__dict__[\"tensor\"]\n",
    "for pred_i in range(len(preds)):\n",
    "    pred = preds_new[pred_i]\n",
    "    if mean_squared_error(pred.to(\"cpu\"), target) > lowest_mse:\n",
    "        lowest_mse = mean_squared_error(pred.to(\"cpu\"), target)\n",
    "wandb.log({\"MSE\": lowest_mse})\n",
    "wandb.log({\"RMSE\": lowest_rmse})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
